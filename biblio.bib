@INPROCEEDINGS{WirelessXiangCai,
author={S. Xiang and L. Cai},
booktitle={2011 IEEE International Conference on Communications (ICC)},
title={Scalable Video Coding with Compressive Sensing for Wireless Videocast},
year={2011},
volume={},
number={},
pages={1-5},
abstract={Channel coding such as Reed-Solomon (RS) and convolutional codes has been widely used to protect video transmission in wireless networks. However, this type of channel coding can effectively correct error bits only if the error rate is smaller than a given threshold; when the bit error rate is underestimated, the effectiveness of channel coding drops dramatically and so does the decoded video quality. In this paper, we propose a low-complex, scalable video coding architecture based on compressive sensing (SVCCS) for wireless unicast and multicast transmissions. SVCCS achieves good scalability, error resilience and coding efficiency. SVCCS encoded bitstream is divided into base and enhancement layer. The layered structure provides quality and temporal scalability. While in the enhancement layer, the CS measurements provide fine granular quality scalability. In addition, we incorporate state-of-the-art technologies of compressive sensing to improve the coding efficiency. Experimental results show that SVCCS is more effective and efficient for wireless videocast than the existing solutions.},
keywords={channel coding;data compression;error statistics;image reconstruction;multicast communication;radio networks;telecommunication network reliability;video coding;video communication;compressive sensing;wireless videocast;channel coding;Reed-Solomon codes;convolutional codes;video transmission;wireless networks;bit error rate;video quality decoding;low-complex scalable video coding architecture;wireless unicast transmissions;wireless multicast transmissions;error resilience;coding efficiency;SVCCS encoded bitstream;enhancement layer;temporal scalability;granular quality scalability;Compressed sensing;Discrete cosine transforms;Encoding;Wireless communication;Wireless sensor networks;Loss measurement;Quantization},
doi={10.1109/icc.2011.5963359},
ISSN={1938-1883},
month={June},}

@ARTICLE{CandesSignalRecovery,
author={E. J. Candes and T. Tao},
journal={IEEE Transactions on Information Theory},
title={Near-Optimal Signal Recovery From Random Projections: Universal Encoding Strategies?},
year={2006},
volume={52},
number={12},
pages={5406-5425},
abstract={Suppose we are given a vector f in a class FsubeRopf<sup>N </sup>, e.g., a class of digital signals or digital images. How many linear measurements do we need to make about f to be able to recover f to within precision epsi in the Euclidean (lscr<sub>2</sub>) metric? This paper shows that if the objects of interest are sparse in a fixed basis or compressible, then it is possible to reconstruct f to within very high accuracy from a small number of random measurements by solving a simple linear program. More precisely, suppose that the nth largest entry of the vector |f| (or of its coefficients in a fixed basis) obeys |f|<sub>(n)</sub>lesRmiddotn<sup>-1</sup>p/, where R&gt;0 and p&gt;0. Suppose that we take measurements y<sub>k</sub>=langf<sup># </sup>,X<sub>k</sub>rang,k=1,...,K, where the X<sub>k</sub> are N-dimensional Gaussian vectors with independent standard normal entries. Then for each f obeying the decay estimate above for some 0&lt;p&lt;1 and with overwhelming probability, our reconstruction f<sup>t</sup>, defined as the solution to the constraints y<sub>k</sub>=langf<sup># </sup>,X<sub>k</sub>rang with minimal lscr<sub>1</sub> norm, obeys parf-f<sup>#</sup>par<sub>lscr2</sub>lesC<sub>p </sub>middotRmiddot(K/logN)<sup>-r</sup>, r=1/p-1/2. There is a sense in which this result is optimal; it is generally impossible to obtain a higher accuracy from any set of K measurements whatsoever. The methodology extends to various other random measurement ensembles; for example, we show that similar results hold if one observes a few randomly sampled Fourier coefficients of f. In fact, the results are quite general and require only two hypotheses on the measurement ensemble which are detailed},
keywords={encoding;linear programming;signal reconstruction;signal recovery;random projection;universal encoding strategy;linear measurement;linear program;signal reconstruction;N-dimensional Gaussian vector;Encoding;Vectors;Image reconstruction;Mathematics;Digital images;Image coding;Measurement standards;Linear programming;Geometry;Concrete;Concentration of measure;convex optimization;duality in optimization;linear programming;random matrices;random projections;signal recovery;singular values of random matrices;sparsity;trigonometric expansions;uncertainty principle},
doi={10.1109/TIT.2006.885507},
ISSN={0018-9448},
month={Dec},}

@ARTICLE{DonohoCS,
author={D. L. Donoho},
journal={IEEE Transactions on Information Theory},
title={Compressed sensing},
year={2006},
volume={52},
number={4},
pages={1289-1306},
abstract={Suppose x is an unknown vector in Ropf<sup>m</sup> (a digital image or signal); we plan to measure n general linear functionals of x and then reconstruct. If x is known to be compressible by transform coding with a known transform, and we reconstruct via the nonlinear procedure defined here, the number of measurements n can be dramatically smaller than the size m. Thus, certain natural classes of images with m pixels need only n=O(m<sup>1/4</sup>log<sup>5/2</sup>(m)) nonadaptive nonpixel samples for faithful recovery, as opposed to the usual m pixel samples. More specifically, suppose x has a sparse representation in some orthonormal basis (e.g., wavelet, Fourier) or tight frame (e.g., curvelet, Gabor)-so the coefficients belong to an lscr<sub>p</sub> ball for 0&lt;ples1. The N most important coefficients in that expansion allow reconstruction with lscr<sub>2</sub> error O(N<sup>1/2-1</sup>p/). It is possible to design n=O(Nlog(m)) nonadaptive measurements allowing reconstruction with accuracy comparable to that attainable with direct knowledge of the N most important coefficients. Moreover, a good approximation to those N important coefficients is extracted from the n measurements by solving a linear program-Basis Pursuit in signal processing. The nonadaptive measurements have the character of "random" linear combinations of basis/frame elements. Our results use the notions of optimal recovery, of n-widths, and information-based complexity. We estimate the Gel'fand n-widths of lscr<sub>p</sub> balls in high-dimensional Euclidean space in the case 0&lt;ples1, and give a criterion identifying near- optimal subspaces for Gel'fand n-widths. We show that "most" subspaces are near-optimal, and show that convex optimization (Basis Pursuit) is a near-optimal way to extract information derived from these near-optimal subspaces},
keywords={convex programming;data compression;image coding;image reconstruction;image sampling;image sensors;sparse matrices;transform coding;sensing compression;general linear functional measurement;transform coding;image reconstruction;nonadaptive nonpixel sampling;sparse representation;signal processing;Euclidean space;convex optimization;Compressed sensing;Image reconstruction;Pixel;Vectors;Digital images;Image coding;Transform coding;Size measurement;Signal processing;Data mining;Adaptive sampling;almost-spherical sections of Banach spaces;Basis Pursuit;eigenvalues of random matrices;Gel'fand;information-based complexity;integrated sensing and processing;minimum;optimal recovery;Quotient-of-a-Subspace theorem;sparse solution of linear equations},
doi={10.1109/TIT.2006.871582},
ISSN={0018-9448},
month={April},}

@ARTICLE{PudlewskiVideoWireless,
author={S. Pudlewski and A. Prasanna and T. Melodia},
journal={IEEE Transactions on Mobile Computing},
title={Compressed-Sensing-Enabled Video Streaming for Wireless Multimedia Sensor Networks},
year={2012},
volume={11},
number={6},
pages={1060-1072},
abstract={This paper presents the design of a networked system for joint compression, rate control and error correction of video over resource-constrained embedded devices based on the theory of Compressed Sensing (CS). The objective of this work is to design a cross-layer system that jointly controls the video encoding rate, the transmission rate, and the channel coding rate to maximize the received video quality. First, compressed sensing-based video encoding for transmission over Wireless Multimedia Sensor Networks (WMSNs) is studied. It is shown that compressed sensing can overcome many of the current problems of video over WMSNs, primarily encoder complexity and low resiliency to channel errors. A rate controller is then developed with the objective of maintaining fairness among different videos while maximizing the received video quality. It is shown that the rate of Compressed Sensed Video (CSV) can be predictably controlled by varying only the compressed sensing sampling rate. It is then shown that the developed rate controller can be interpreted as the iterative solution to a convex optimization problem representing the optimization of the rate allocation across the network. The error resiliency properties of compressed sensed images and videos are then studied, and an optimal error detection and correction scheme is presented for video transmission over lossy channels. Finally, the entire system is evaluated through simulation and test bed evaluation. The rate controller is shown to outperform existing TCP-friendly rate control schemes in terms of both fairness and received video quality. The test bed results show that the rates converge to stable values in real channels.},
keywords={compressed sensing;error correction;iterative methods;multimedia communication;telecommunication channels;telecommunication control;video coding;video streaming;wireless sensor networks;compressed-sensing-enabled video streaming;wireless multimedia sensor networks;joint compression;error correction;video over resource-constrained embedded devices;video encoding rate;transmission rate;channel coding rate;rate controller;iterative solution;rate allocation;compressed sensed images;compressed sensed videos;error detection;video transmission;TCP-friendly rate control schemes;Streaming media;Image coding;Compressed sensing;Encoding;Cameras;Vectors;Quantization;Compressed sensing;optimization;multimedia content;congestion control;sensor networks.},
doi={10.1109/TMC.2011.175},
ISSN={1536-1233},
month={June},}

@inproceedings{MairalOnlineDictLearn,
 author = {Mairal, Julien and Bach, Francis and Ponce, Jean and Sapiro, Guillermo},
 title = {Online Dictionary Learning for Sparse Coding},
 booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
 series = {ICML '09},
 year = {2009},
 isbn = {978-1-60558-516-1},
 location = {Montreal, Quebec, Canada},
 pages = {689--696},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/1553374.1553463},
 doi = {10.1145/1553374.1553463},
 acmid = {1553463},
 publisher = {ACM},
 address = {New York, NY, USA},
}

@article{RubinsteinKSVDOMPBatch,
author = {Rubinstein, Ron and Zibulevsky, Michael and Elad, Michael},
year = {2008},
month = {01},
pages = {},
title = {Efficient Implementation of the K-SVD Algorithm Using Batch Orthogonal Matching Pursuit},
volume = {40},
booktitle = {CS Technion}
}

@article{andrecutfastCUBLASMP,
  title={Fast GPU implementation of sparse signal recovery from random projections},
  author={Andrecut, Mircea},
  journal={arXiv preprint arXiv:0809.1833},
  year={2008}
}

@ARTICLE{FPGADCTCS,
author={G. Orchard and J. Zhang and Y. Suo and M. Dao and D. T. Nguyen and S. Chin and C. Posch and T. D. Tran and R. Etienne-Cummings},
journal={IEEE Journal on Emerging and Selected Topics in Circuits and Systems},
title={Real Time Compressive Sensing Video Reconstruction in Hardware},
year={2012},
volume={2},
number={3},
pages={604-615},
abstract={Compressive sensing has allowed for reconstruction of missing pixels in incomplete images with higher accuracy than was previously possible. Moreover, video data or sequences of images contain even more correlation, leading to a much sparser representation as demonstrated repeatedly in numerous digital video formats and international standards. Compressive sensing has inspired the design of a number of imagers which take advantage of the need to only subsample a scene, which reduces power consumption by requiring acquisition and transmission of fewer samples. In this paper, we show how missing pixels in a video sequence can be estimated using compressive sensing techniques. We present a real time implementation of our algorithm and show its application to an asynchronous time-based image sensor (ATIS) from the Austrian Institute of Technology. The ATIS only provides pixel intensity data when and where a change in pixel intensity is detected, however, noise randomly causes intensity changes to be falsely detected, thereby providing random samples of static regions of the scene. Unlike other compressive sensing imagers, which typically have pseudo-random sampling designed in at extra effort, the ATIS used here provides random samples as a side effect of circuit noise. Here, we describe and analyze a field-programmable gate array implementation of a matching pursuit (MP) algorithm for compressive sensing reconstruction capable of reconstructing over 1.9 million 8 × 8 pixel regions per second with a sparsity of 11 using a basis dictionary containing 64 elements. In our application to ATIS we achieve throughput of 28 frames per second at a resolution of 304 × 240 pixels with reconstruction accuracy comparable to that of state of the art algorithms evaluated offline.},
keywords={compressed sensing;field programmable gate arrays;image reconstruction;image sensors;iterative methods;power consumption;video signal processing;real time compressive sensing video reconstruction;hardware;incomplete images;pixels;video data;video sequences;sparser representation;international standards;digital video formats;power consumption;compressive sensing techniques;asynchronous time-based image sensor;ATIS;Austrian Institute of Technology;compressive sensing imagers;pseudo-random sampling;matching pursuit algorithm;field-programmable gate array;Compressed sensing;Image reconstruction;Matching pursuit algorithms;Sensors;Real-time systems;Noise measurements;Field programmable gate arrays;Video communication;Asynchronous;compressive imaging;field-programmable gate array (FPGA) and application-specific integrated circuit (ASIC);FPGA-based real-time video processing},
doi={10.1109/JETCAS.2012.2214614},
ISSN={2156-3357},
month={Sept},}

@article{chen2015compressed,
  title={Compressed sensing and dictionary learning},
  author={Chen, Guangliang and Needell, Deanna},
  journal={Preprint},
  volume={106},
  year={2015}
}

@article{CANDESDICTS,
title = "Compressed sensing with coherent and redundant dictionaries",
journal = "Applied and Computational Harmonic Analysis",
volume = "31",
number = "1",
pages = "59 - 73",
year = "2011",
issn = "1063-5203",
doi = "https://doi.org/10.1016/j.acha.2010.10.002",
url = "http://www.sciencedirect.com/science/article/pii/S1063520310001156",
author = "Emmanuel J. Candès and Yonina C. Eldar and Deanna Needell and Paige Randall",
keywords = "-minimization, Basis pursuit, Restricted isometry property, Redundant dictionaries, -analysis",
abstract = "This article presents novel results concerning the recovery of signals from undersampled data in the common situation where such signals are not sparse in an orthonormal basis or incoherent dictionary, but in a truly redundant dictionary. This work thus bridges a gap in the literature and shows not only that compressed sensing is viable in this context, but also that accurate recovery is possible via an ℓ1-analysis optimization problem. We introduce a condition on the measurement/sensing matrix, which is a natural generalization of the now well-known restricted isometry property, and which guarantees accurate recovery of signals that are nearly sparse in (possibly) highly overcomplete and coherent dictionaries. This condition imposes no incoherence restriction on the dictionary and our results may be the first of this kind. We discuss practical examples and the implications of our results on those applications, and complement our study by demonstrating the potential of ℓ1-analysis for such problems."
}