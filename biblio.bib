@INPROCEEDINGS{WirelessXiangCai,
author={S. Xiang and L. Cai},
booktitle={2011 IEEE International Conference on Communications (ICC)},
title={Scalable Video Coding with Compressive Sensing for Wireless Videocast},
year={2011},
volume={},
number={},
pages={1-5},
abstract={Channel coding such as Reed-Solomon (RS) and convolutional codes has been widely used to protect video transmission in wireless networks. However, this type of channel coding can effectively correct error bits only if the error rate is smaller than a given threshold; when the bit error rate is underestimated, the effectiveness of channel coding drops dramatically and so does the decoded video quality. In this paper, we propose a low-complex, scalable video coding architecture based on compressive sensing (SVCCS) for wireless unicast and multicast transmissions. SVCCS achieves good scalability, error resilience and coding efficiency. SVCCS encoded bitstream is divided into base and enhancement layer. The layered structure provides quality and temporal scalability. While in the enhancement layer, the CS measurements provide fine granular quality scalability. In addition, we incorporate state-of-the-art technologies of compressive sensing to improve the coding efficiency. Experimental results show that SVCCS is more effective and efficient for wireless videocast than the existing solutions.},
keywords={channel coding;data compression;error statistics;image reconstruction;multicast communication;radio networks;telecommunication network reliability;video coding;video communication;compressive sensing;wireless videocast;channel coding;Reed-Solomon codes;convolutional codes;video transmission;wireless networks;bit error rate;video quality decoding;low-complex scalable video coding architecture;wireless unicast transmissions;wireless multicast transmissions;error resilience;coding efficiency;SVCCS encoded bitstream;enhancement layer;temporal scalability;granular quality scalability;Compressed sensing;Discrete cosine transforms;Encoding;Wireless communication;Wireless sensor networks;Loss measurement;Quantization},
doi={10.1109/icc.2011.5963359},
ISSN={1938-1883},
month={June},}

@ARTICLE{CandesSignalRecovery,
author={E. J. Candes and T. Tao},
journal={IEEE Transactions on Information Theory},
title={Near-Optimal Signal Recovery From Random Projections: Universal Encoding Strategies?},
year={2006},
volume={52},
number={12},
pages={5406-5425},
abstract={Suppose we are given a vector f in a class FsubeRopf<sup>N </sup>, e.g., a class of digital signals or digital images. How many linear measurements do we need to make about f to be able to recover f to within precision epsi in the Euclidean (lscr<sub>2</sub>) metric? This paper shows that if the objects of interest are sparse in a fixed basis or compressible, then it is possible to reconstruct f to within very high accuracy from a small number of random measurements by solving a simple linear program. More precisely, suppose that the nth largest entry of the vector |f| (or of its coefficients in a fixed basis) obeys |f|<sub>(n)</sub>lesRmiddotn<sup>-1</sup>p/, where R&gt;0 and p&gt;0. Suppose that we take measurements y<sub>k</sub>=langf<sup># </sup>,X<sub>k</sub>rang,k=1,...,K, where the X<sub>k</sub> are N-dimensional Gaussian vectors with independent standard normal entries. Then for each f obeying the decay estimate above for some 0&lt;p&lt;1 and with overwhelming probability, our reconstruction f<sup>t</sup>, defined as the solution to the constraints y<sub>k</sub>=langf<sup># </sup>,X<sub>k</sub>rang with minimal lscr<sub>1</sub> norm, obeys parf-f<sup>#</sup>par<sub>lscr2</sub>lesC<sub>p </sub>middotRmiddot(K/logN)<sup>-r</sup>, r=1/p-1/2. There is a sense in which this result is optimal; it is generally impossible to obtain a higher accuracy from any set of K measurements whatsoever. The methodology extends to various other random measurement ensembles; for example, we show that similar results hold if one observes a few randomly sampled Fourier coefficients of f. In fact, the results are quite general and require only two hypotheses on the measurement ensemble which are detailed},
keywords={encoding;linear programming;signal reconstruction;signal recovery;random projection;universal encoding strategy;linear measurement;linear program;signal reconstruction;N-dimensional Gaussian vector;Encoding;Vectors;Image reconstruction;Mathematics;Digital images;Image coding;Measurement standards;Linear programming;Geometry;Concrete;Concentration of measure;convex optimization;duality in optimization;linear programming;random matrices;random projections;signal recovery;singular values of random matrices;sparsity;trigonometric expansions;uncertainty principle},
doi={10.1109/TIT.2006.885507},
ISSN={0018-9448},
month={Dec},}

@ARTICLE{CandesDecoLinear,
author={E. J. Candes and T. Tao},
journal={IEEE Transactions on Information Theory},
title={Decoding by linear programming},
year={2005},
volume={51},
number={12},
pages={4203-4215},
keywords={linear codes;decoding;linear programming;error correction codes;minimisation;convex programming;sparse matrices;random codes;indeterminancy;Gaussian processes;linear code decoding;linear programming;natural error correcting problem;minimization problem;simple convex optimization problem;sparse solution;uncertainty principle;basis pursuit;Gaussian random matrix;Decoding;Linear programming;Vectors;Linear code;Sparse matrices;Mathematics;Error correction;Equations;Error correction codes;Information theory;Basis pursuit;decoding of (random) linear codes;duality in optimization;Gaussian random matrices;linear codes;linear programming;principal angles;restricted orthonormality;singular values of random matrices;sparse solutions to underdetermined systems},
doi={10.1109/TIT.2005.858979},
ISSN={0018-9448},
month={Dec},}

@ARTICLE{GilbertOMP,
author={J. A. Tropp and A. C. Gilbert},
journal={IEEE Transactions on Information Theory},
title={Signal Recovery From Random Measurements Via Orthogonal Matching Pursuit},
year={2007},
volume={53},
number={12},
pages={4655-4666},
keywords={greedy algorithms;iterative methods;signal processing;time-frequency analysis;signal recovery;random linear measurements;orthogonal matching pursuit;greedy algorithm;basis pursuit;Matching pursuit algorithms;Testing;Performance evaluation;Mathematics;Signal processing;Vectors;Blood;Greedy algorithms;Reliability theory;Compressed sensing;Algorithms;approximation;basis pursuit;compressed sensing;group testing;orthogonal matching pursuit;signal recovery;sparse approximation},
doi={10.1109/TIT.2007.909108},
ISSN={0018-9448},
month={Dec},}

@ARTICLE{DonohoCS,
author={D. L. Donoho},
journal={IEEE Transactions on Information Theory},
title={Compressed sensing},
year={2006},
volume={52},
number={4},
pages={1289-1306},
abstract={Suppose x is an unknown vector in Ropf<sup>m</sup> (a digital image or signal); we plan to measure n general linear functionals of x and then reconstruct. If x is known to be compressible by transform coding with a known transform, and we reconstruct via the nonlinear procedure defined here, the number of measurements n can be dramatically smaller than the size m. Thus, certain natural classes of images with m pixels need only n=O(m<sup>1/4</sup>log<sup>5/2</sup>(m)) nonadaptive nonpixel samples for faithful recovery, as opposed to the usual m pixel samples. More specifically, suppose x has a sparse representation in some orthonormal basis (e.g., wavelet, Fourier) or tight frame (e.g., curvelet, Gabor)-so the coefficients belong to an lscr<sub>p</sub> ball for 0&lt;ples1. The N most important coefficients in that expansion allow reconstruction with lscr<sub>2</sub> error O(N<sup>1/2-1</sup>p/). It is possible to design n=O(Nlog(m)) nonadaptive measurements allowing reconstruction with accuracy comparable to that attainable with direct knowledge of the N most important coefficients. Moreover, a good approximation to those N important coefficients is extracted from the n measurements by solving a linear program-Basis Pursuit in signal processing. The nonadaptive measurements have the character of "random" linear combinations of basis/frame elements. Our results use the notions of optimal recovery, of n-widths, and information-based complexity. We estimate the Gel'fand n-widths of lscr<sub>p</sub> balls in high-dimensional Euclidean space in the case 0&lt;ples1, and give a criterion identifying near- optimal subspaces for Gel'fand n-widths. We show that "most" subspaces are near-optimal, and show that convex optimization (Basis Pursuit) is a near-optimal way to extract information derived from these near-optimal subspaces},
keywords={convex programming;data compression;image coding;image reconstruction;image sampling;image sensors;sparse matrices;transform coding;sensing compression;general linear functional measurement;transform coding;image reconstruction;nonadaptive nonpixel sampling;sparse representation;signal processing;Euclidean space;convex optimization;Compressed sensing;Image reconstruction;Pixel;Vectors;Digital images;Image coding;Transform coding;Size measurement;Signal processing;Data mining;Adaptive sampling;almost-spherical sections of Banach spaces;Basis Pursuit;eigenvalues of random matrices;Gel'fand;information-based complexity;integrated sensing and processing;minimum;optimal recovery;Quotient-of-a-Subspace theorem;sparse solution of linear equations},
doi={10.1109/TIT.2006.871582},
ISSN={0018-9448},
month={April},}

@ARTICLE{PudlewskiVideoWireless,
author={S. Pudlewski and A. Prasanna and T. Melodia},
journal={IEEE Transactions on Mobile Computing},
title={Compressed-Sensing-Enabled Video Streaming for Wireless Multimedia Sensor Networks},
year={2012},
volume={11},
number={6},
pages={1060-1072},
abstract={This paper presents the design of a networked system for joint compression, rate control and error correction of video over resource-constrained embedded devices based on the theory of Compressed Sensing (CS). The objective of this work is to design a cross-layer system that jointly controls the video encoding rate, the transmission rate, and the channel coding rate to maximize the received video quality. First, compressed sensing-based video encoding for transmission over Wireless Multimedia Sensor Networks (WMSNs) is studied. It is shown that compressed sensing can overcome many of the current problems of video over WMSNs, primarily encoder complexity and low resiliency to channel errors. A rate controller is then developed with the objective of maintaining fairness among different videos while maximizing the received video quality. It is shown that the rate of Compressed Sensed Video (CSV) can be predictably controlled by varying only the compressed sensing sampling rate. It is then shown that the developed rate controller can be interpreted as the iterative solution to a convex optimization problem representing the optimization of the rate allocation across the network. The error resiliency properties of compressed sensed images and videos are then studied, and an optimal error detection and correction scheme is presented for video transmission over lossy channels. Finally, the entire system is evaluated through simulation and test bed evaluation. The rate controller is shown to outperform existing TCP-friendly rate control schemes in terms of both fairness and received video quality. The test bed results show that the rates converge to stable values in real channels.},
keywords={compressed sensing;error correction;iterative methods;multimedia communication;telecommunication channels;telecommunication control;video coding;video streaming;wireless sensor networks;compressed-sensing-enabled video streaming;wireless multimedia sensor networks;joint compression;error correction;video over resource-constrained embedded devices;video encoding rate;transmission rate;channel coding rate;rate controller;iterative solution;rate allocation;compressed sensed images;compressed sensed videos;error detection;video transmission;TCP-friendly rate control schemes;Streaming media;Image coding;Compressed sensing;Encoding;Cameras;Vectors;Quantization;Compressed sensing;optimization;multimedia content;congestion control;sensor networks.},
doi={10.1109/TMC.2011.175},
ISSN={1536-1233},
month={June},}

@inproceedings{MairalOnlineDictLearn,
 author = {Mairal, Julien and Bach, Francis and Ponce, Jean and Sapiro, Guillermo},
 title = {Online Dictionary Learning for Sparse Coding},
 booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
 series = {ICML '09},
 year = {2009},
 isbn = {978-1-60558-516-1},
 location = {Montreal, Quebec, Canada},
 pages = {689--696},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/1553374.1553463},
 doi = {10.1145/1553374.1553463},
 acmid = {1553463},
 publisher = {ACM},
 address = {New York, NY, USA},
}

@article{RubinsteinKSVDOMPBatch,
author = {Rubinstein, Ron and Zibulevsky, Michael and Elad, Michael},
year = {2008},
month = {01},
pages = {},
title = {Efficient Implementation of the K-SVD Algorithm Using Batch Orthogonal Matching Pursuit},
volume = {40},
booktitle = {CS Technion}
}

@article{andrecutfastCUBLASMP,
  title={Fast GPU implementation of sparse signal recovery from random projections},
  author={Andrecut, Mircea},
  journal={arXiv preprint arXiv:0809.1833},
  year={2008}
}

@ARTICLE{FPGADCTCS,
author={G. Orchard and J. Zhang and Y. Suo and M. Dao and D. T. Nguyen and S. Chin and C. Posch and T. D. Tran and R. Etienne-Cummings},
journal={IEEE Journal on Emerging and Selected Topics in Circuits and Systems},
title={Real Time Compressive Sensing Video Reconstruction in Hardware},
year={2012},
volume={2},
number={3},
pages={604-615},
abstract={Compressive sensing has allowed for reconstruction of missing pixels in incomplete images with higher accuracy than was previously possible. Moreover, video data or sequences of images contain even more correlation, leading to a much sparser representation as demonstrated repeatedly in numerous digital video formats and international standards. Compressive sensing has inspired the design of a number of imagers which take advantage of the need to only subsample a scene, which reduces power consumption by requiring acquisition and transmission of fewer samples. In this paper, we show how missing pixels in a video sequence can be estimated using compressive sensing techniques. We present a real time implementation of our algorithm and show its application to an asynchronous time-based image sensor (ATIS) from the Austrian Institute of Technology. The ATIS only provides pixel intensity data when and where a change in pixel intensity is detected, however, noise randomly causes intensity changes to be falsely detected, thereby providing random samples of static regions of the scene. Unlike other compressive sensing imagers, which typically have pseudo-random sampling designed in at extra effort, the ATIS used here provides random samples as a side effect of circuit noise. Here, we describe and analyze a field-programmable gate array implementation of a matching pursuit (MP) algorithm for compressive sensing reconstruction capable of reconstructing over 1.9 million 8 × 8 pixel regions per second with a sparsity of 11 using a basis dictionary containing 64 elements. In our application to ATIS we achieve throughput of 28 frames per second at a resolution of 304 × 240 pixels with reconstruction accuracy comparable to that of state of the art algorithms evaluated offline.},
keywords={compressed sensing;field programmable gate arrays;image reconstruction;image sensors;iterative methods;power consumption;video signal processing;real time compressive sensing video reconstruction;hardware;incomplete images;pixels;video data;video sequences;sparser representation;international standards;digital video formats;power consumption;compressive sensing techniques;asynchronous time-based image sensor;ATIS;Austrian Institute of Technology;compressive sensing imagers;pseudo-random sampling;matching pursuit algorithm;field-programmable gate array;Compressed sensing;Image reconstruction;Matching pursuit algorithms;Sensors;Real-time systems;Noise measurements;Field programmable gate arrays;Video communication;Asynchronous;compressive imaging;field-programmable gate array (FPGA) and application-specific integrated circuit (ASIC);FPGA-based real-time video processing},
doi={10.1109/JETCAS.2012.2214614},
ISSN={2156-3357},
month={Sept},}

@article{chen2015compressed,
  title={Compressed sensing and dictionary learning},
  author={Chen, Guangliang and Needell, Deanna},
  journal={Preprint},
  volume={106},
  year={2015}
}

@article{CANDESDICTS,
title = "Compressed sensing with coherent and redundant dictionaries",
journal = "Applied and Computational Harmonic Analysis",
volume = "31",
number = "1",
pages = "59 - 73",
year = "2011",
issn = "1063-5203",
doi = "https://doi.org/10.1016/j.acha.2010.10.002",
url = "http://www.sciencedirect.com/science/article/pii/S1063520310001156",
author = "Emmanuel J. Candes and Yonina C. Eldar and Deanna Needell and Paige Randall",
keywords = "-minimization, Basis pursuit, Restricted isometry property, Redundant dictionaries, -analysis",
abstract = "This article presents novel results concerning the recovery of signals from undersampled data in the common situation where such signals are not sparse in an orthonormal basis or incoherent dictionary, but in a truly redundant dictionary. This work thus bridges a gap in the literature and shows not only that compressed sensing is viable in this context, but also that accurate recovery is possible via an ℓ1-analysis optimization problem. We introduce a condition on the measurement/sensing matrix, which is a natural generalization of the now well-known restricted isometry property, and which guarantees accurate recovery of signals that are nearly sparse in (possibly) highly overcomplete and coherent dictionaries. This condition imposes no incoherence restriction on the dictionary and our results may be the first of this kind. We discuss practical examples and the implications of our results on those applications, and complement our study by demonstrating the potential of ℓ1-analysis for such problems."
}

@article{Mut05,
url = {http://dx.doi.org/10.1561/0400000002},
year = {2005},
volume = {1},
journal = {Foundations and Trends® in Theoretical Computer Science},
title = {Data Streams: Algorithms and Applications},
doi = {10.1561/0400000002},
issn = {1551-305X},
number = {2},
pages = {117-236},
author = {S. Muthukrishnan}
}


@article{rudelson2008sparse,
  title={On sparse reconstruction from Fourier and Gaussian measurements},
  author={Rudelson, Mark and Vershynin, Roman},
  journal={Communications on Pure and Applied Mathematics: A Journal Issued by the Courant Institute of Mathematical Sciences},
  volume={61},
  number={8},
  pages={1025--1045},
  year={2008},
  publisher={Wiley Online Library}
}

@Article{Mendelson2008,
author="Mendelson, Shahar
and Pajor, Alain
and Tomczak-Jaegermann, Nicole",
title="Uniform Uncertainty Principle for Bernoulli and Subgaussian Ensembles",
journal="Constructive Approximation",
year="2008",
month="Dec",
day="01",
volume="28",
number="3",
pages="277--289",
abstract="The paper considers random matrices with independent subgaussian columns and provides a new elementary proof of the Uniform Uncertainty Principle for such matrices. The Principle was introduced by Candes, Romberg and Tao in 2004; for subgaussian random matrices it was carlier proved by the present authors, as a consequence of a general result based on a generic chaining method of Talagrand. The present proof combines a simple measure concentration and a covering argument, which are standard tools of high-dimensional convexity.",
issn="1432-0940",
doi="10.1007/s00365-007-9005-8",
url="https://doi.org/10.1007/s00365-007-9005-8"
}

@article{candes2006stable,
  title={Stable signal recovery from incomplete and inaccurate measurements},
  author={Candes, Emmanuel J and Romberg, Justin K and Tao, Terence},
  journal={Communications on Pure and Applied Mathematics: A Journal Issued by the Courant Institute of Mathematical Sciences},
  volume={59},
  number={8},
  pages={1207--1223},
  year={2006},
  publisher={Wiley Online Library}
}

@ARTICLE{CandesMRI,
author={E. J. Candes and J. Romberg and T. Tao},
journal={IEEE Transactions on Information Theory},
title={Robust uncertainty principles: exact signal reconstruction from highly incomplete frequency information},
year={2006},
volume={52},
number={2},
pages={489-509},
keywords={image reconstruction;linear programming;convex programming;minimisation;Fourier analysis;image sampling;piecewise constant techniques;probability;sparse matrices;indeterminancy;signal reconstruction;signal sampling;robust uncertainty principle;signal reconstruction;incomplete frequency information;discrete-time signal;Fourier coefficient;minimization problem;convex optimization;image reconstruction;linear programming;sparse random matrix;trigonometric expansion;nonlinear sampling theorem;piecewise constant object;probability value;Robustness;Uncertainty;Signal reconstruction;Frequency;Image reconstruction;Mathematics;Biomedical imaging;Sampling methods;Linear programming;Signal processing;Convex optimization;duality in optimization;free probability;image reconstruction;linear programming;random matrices;sparsity;total-variation minimization;trigonometric expansions;uncertainty principle},
doi={10.1109/TIT.2005.862083},
ISSN={0018-9448},
month={Feb},}

@article{NeedellCoSaMP,
title = "CoSaMP: Iterative signal recovery from incomplete and inaccurate samples",
journal = "Applied and Computational Harmonic Analysis",
volume = "26",
number = "3",
pages = "301 - 321",
year = "2009",
issn = "1063-5203",
doi = "https://doi.org/10.1016/j.acha.2008.07.002",
url = "http://www.sciencedirect.com/science/article/pii/S1063520308000638",
author = "D. Needell and J.A. Tropp",
keywords = "Algorithms, Approximation, Basis pursuit, Compressed sensing, Orthogonal matching pursuit, Restricted isometry property, Signal recovery, Sparse approximation, Uncertainty principle",
abstract = "Compressive sampling offers a new paradigm for acquiring signals that are compressible with respect to an orthonormal basis. The major algorithmic challenge in compressive sampling is to approximate a compressible signal from noisy samples. This paper describes a new iterative recovery algorithm called CoSaMP that delivers the same guarantees as the best optimization-based approaches. Moreover, this algorithm offers rigorous bounds on computational cost and storage. It is likely to be extremely efficient for practical problems because it requires only matrix–vector multiplies with the sampling matrix. For compressible signals, the running time is just O(Nlog2N), where N is the length of the signal."
}

@article{BLUMENSATHIHT,
title = "Iterative hard thresholding for compressed sensing",
journal = "Applied and Computational Harmonic Analysis",
volume = "27",
number = "3",
pages = "265 - 274",
year = "2009",
issn = "1063-5203",
doi = "https://doi.org/10.1016/j.acha.2009.04.002",
url = "http://www.sciencedirect.com/science/article/pii/S1063520309000384",
author = "Thomas Blumensath and Mike E. Davies",
keywords = "Algorithms, Compressed sensing, Sparse inverse problem, Signal recovery, Iterative hard thresholding",
abstract = "Compressed sensing is a technique to sample compressible signals below the Nyquist rate, whilst still allowing near optimal reconstruction of the signal. In this paper we present a theoretical analysis of the iterative hard thresholding algorithm when applied to the compressed sensing recovery problem. We show that the algorithm has the following properties (made more precise in the main text of the paper)•It gives near-optimal error guarantees.•It is robust to observation noise.•It succeeds with a minimum number of observations.•It can be used with any sampling operator for which the operator and its adjoint can be computed.•The memory requirement is linear in the problem size.•Its computational complexity per iteration is of the same order as the application of the measurement operator or its adjoint.•It requires a fixed number of iterations depending only on the logarithm of a form of signal to noise ratio of the signal.•Its performance guarantees are uniform in that they only depend on properties of the sampling operator and signal sparsity."
}

@article{aharon2006k,
  title={K-SVD: An algorithm for designing overcomplete dictionaries for sparse representation},
  author={Aharon, Michal and Elad, Michael and Bruckstein, Alfred and others},
  journal={IEEE Transactions on signal processing},
  volume={54},
  number={11},
  pages={4311},
  year={2006},
  publisher={IEEE INSTITUTE OF ELECTRICAL AND ELECTRONICS}
}

@ARTICLE{EladDenoising,
author={M. Elad and M. Aharon},
journal={IEEE Transactions on Image Processing},
title={Image Denoising Via Sparse and Redundant Representations Over Learned Dictionaries},
year={2006},
volume={15},
number={12},
pages={3736-3745},
keywords={AWGN;Bayes methods;image denoising;singular value decomposition;visual databases;image denoising;sparse-redundant representations;dictionary learning;zero-mean white noise;homogeneous Gaussian additive noise;K-SVD algorithm;image database;Bayesian treatment;Image denoising;Dictionaries;Noise reduction;Matching pursuit algorithms;Additive noise;Bayesian methods;Discrete cosine transforms;Noise measurement;Inverse problems;Image processing;Bayesian reconstruction;dictionary learning;discrete cosine transform (DCT);image denoising;K-SVD;matching pursuit;maximum a posteriori (MAP) estimation;redundancy;sparse representations;Algorithms;Artifacts;Image Enhancement;Image Interpretation, Computer-Assisted;Information Storage and Retrieval;Reproducibility of Results;Sensitivity and Specificity;Subtraction Technique},
doi={10.1109/TIP.2006.881969},
ISSN={1057-7149},
month={Dec},}

@article{MairalSparse,
 author = {Mairal, Julien and Bach, Francis and Ponce, Jean},
 title = {Sparse Modeling for Image and Vision Processing},
 journal = {Found. Trends. Comput. Graph. Vis.},
 issue_date = {12 2014},
 volume = {8},
 number = {2-3},
 month = dec,
 year = {2014},
 issn = {1572-2740},
 pages = {85--283},
 numpages = {199},
 url = {http://dx.doi.org/10.1561/0600000058},
 doi = {10.1561/0600000058},
 acmid = {2747301},
 publisher = {Now Publishers Inc.},
 address = {Hanover, MA, USA},
} 

@article{BRYTFACEKSVD,
title = "Compression of facial images using the K-SVD algorithm",
journal = "Journal of Visual Communication and Image Representation",
volume = "19",
number = "4",
pages = "270 - 282",
year = "2008",
issn = "1047-3203",
doi = "https://doi.org/10.1016/j.jvcir.2008.03.001",
url = "http://www.sciencedirect.com/science/article/pii/S1047320308000254",
author = "Ori Bryt and Michael Elad",
keywords = "Image compression, Sparse representations, Redundancy, K-SVD, OMP, Facial images, PCA, JPEG, JPEG2000, VQ",
abstract = "The use of sparse representations in signal and image processing is gradually increasing in the past several years. Obtaining an overcomplete dictionary from a set of signals allows us to represent them as a sparse linear combination of dictionary atoms. Pursuit algorithms are then used for signal decomposition. A recent work introduced the K-SVD algorithm, which is a novel method for training overcomplete dictionaries that lead to sparse signal representation. In this work we propose a new method for compressing facial images, based on the K-SVD algorithm. We train K-SVD dictionaries for predefined image patches, and compress each new image according to these dictionaries. The encoding is based on sparse coding of each image patch using the relevant trained dictionary, and the decoding is a simple reconstruction of the patches by linear combination of atoms. An essential pre-process stage for this method is an image alignment procedure, where several facial features are detected and geometrically warped into a canonical spatial location. We present this new method, analyze its results and compare it to several competing compression techniques."
}

@misc{SPAMS,
  author = {Mairal, Julien},
  title = "SPArse Modeling Software",
  year = 2009,
  url = {http://spams-devel.gforge.inria.fr/index.html},
  urldate = {2018-11-10}
}

@INPROCEEDINGS{NebotDVC,
author={J. Prades-Nebot and Yi Ma and T. Huang},
booktitle={2009 Picture Coding Symposium},
title={Distributed Video Coding using Compressive Sampling},
year={2009},
volume={},
number={},
pages={1-4},
keywords={data compression;decoding;distributed algorithms;image sampling;video coding;distributed video coding algorithm;compressive sampling;encoding algorithm;decoding;Video coding;Sampling methods;Decoding;Video compression;Encoding;Signal processing;Turbo codes;Parity check codes;Proposals;Educational programs;Compressive sampling;Wyner-Ziv video coding;distributed video coding;sparse representations},
doi={10.1109/PCS.2009.5167431},
ISSN={},
month={May},}

@INPROCEEDINGS{DoDISCOS,
author={T. T. Do and Yi Chen and D. T. Nguyen and N. Nguyen and L. Gan and T. D. Tran},
booktitle={2009 43rd Annual Conference on Information Sciences and Systems},
title={Distributed Compressed Video Sensing},
year={2009},
volume={},
number={},
pages={1-2},
keywords={data compression;decoding;distributed sensors;video coding;distributed compressed video sensing;DISCOS;distributed video coding;DVC;compressed sensing theory;encoder;interframe sparsity model;intraframe-decoding;Video compression;Decoding;Video coding;Compressed sensing;Design engineering;Encoding;Analog-digital conversion;Optical imaging;Technological innovation;Predictive models;distributed video coding;Wyner-Ziv coding;compressed sensing;compressive sensing;sparse recovery with decoder side information;structurally random matrices},
doi={10.1109/CISS.2009.5054678},
ISSN={},
month={March},}

@INPROCEEDINGS{ZhangVideoCS,
author={Yifu Zhang and Shunliang Mei and Quqing Chen and Zhibo Chen},
booktitle={2008 IEEE International Conference on Acoustics, Speech and Signal Processing},
title={A novel image/video coding method based on Compressed Sensing theory},
year={2008},
volume={},
number={},
pages={1361-1364},
keywords={data compression;discrete cosine transforms;optimisation;video coding;image coding;video coding;compressed sensing theory;signal compression;signal recovery;discrete cosine transform;spatial sparse signal;JPEG;H.264/AVC coding framework;rate-distortion optimization;adaptive selection;Video coding;Compressed sensing;Image coding;Discrete cosine transforms;Transform coding;Image reconstruction;Video compression;Automatic voltage control;Rate-distortion;Linear programming;compressed sensing;discrete cosine transform;rate-distortion optimization;image/video coding},
doi={10.1109/ICASSP.2008.4517871},
ISSN={1520-6149},
month={March},}

@inproceedings{chen2010dictionary,
  title={Dictionary learning-based distributed compressive video sensing},
  author={Chen, Hung-Wei and Kang, Li-Wei and Lu, Chun-Shien},
  booktitle={Picture Coding Symposium (PCS), 2010},
  pages={210--213},
  year={2010},
  organization={Citeseer}
}

@article{lima2012codificaccao,
  title={Codificação de vídeo baseada em fractais e representações esparsas},
  author={Lima, Vitor de and others},
  year={2012},
  publisher={[sn]}
}

@ARTICLE{SullivanH264,
author={G. J. Sullivan and T. Wiegand},
journal={Proceedings of the IEEE},
title={Video Compression - From Concepts to the H.264/AVC Standard},
year={2005},
volume={93},
number={1},
pages={18-31},
keywords={video coding;rate distortion theory;code standards;video codecs;source coding;transform coding;motion compensation;digital video compression;H.264/AVC standard;visual information;rate-distortion performance;motion representation techniques;intra-picture prediction techniques;waveform coding;video codec design;international standards;transform coding;Video compression;Automatic voltage control;Delay;Video codecs;Video coding;Bit rate;Code standards;Wireless application protocol;Source coding;Decoding;Advanced Video Coding (AVC);compression;H.264;H.26x;Joint Video Team (JVT);Moving Picture Experts Group (MPEG);MPEG-4;standards;video;video coding;video compression;Video Coding Experts Group (VCEG)},
doi={10.1109/JPROC.2004.839617},
ISSN={0018-9219},
month={Jan},}

@ARTICLE{WiegangH264,
author={T. Wiegand and G. J. Sullivan and G. Bjontegaard and A. Luthra},
journal={IEEE Transactions on Circuits and Systems for Video Technology},
title={Overview of the H.264/AVC video coding standard},
year={2003},
volume={13},
number={7},
pages={560-576},
keywords={code standards;IEC standards;ISO standards;telecommunication standards;data compression;video coding;rate distortion theory;standardisation;H.264/AVC video coding standard;ITU-T Video Coding Experts Group;ISO/IEC Moving Picture Experts Group;H.264/AVC standardization;compression performance;video representation;video telephony;video storage;video broadcast;video streaming;rate-distortion efficiency;standardization history;Automatic voltage control;Video coding;IEC standards;ISO standards;Standardization;Video compression;MPEG standards;Telephony;Multimedia communication;Broadcasting},
doi={10.1109/TCSVT.2003.815165},
ISSN={1051-8215},
month={July},}

@book{haykin2001sinais,
  title={Sinais e sistemas},
  author={Haykin, Simon S and Van Veen, Barry},
  year={2001},
  publisher={Bookman}
}

@ARTICLE{NyquistSampling,
author={H. Nyquist},
journal={Transactions of the American Institute of Electrical Engineers},
title={Certain Topics in Telegraph Transmission Theory},
year={1928},
volume={47},
number={2},
pages={617-644},
keywords={Telegraphy;Steady-state;Frequency conversion;Circuits;Costs;Distortion;Shape;Interference;Equalizers;Telephony},
doi={10.1109/T-AIEE.1928.5055024},
ISSN={0096-3860},
month={April},}

@ARTICLE{HuffmanCoding,
author={D. A. Huffman},
journal={Proceedings of the IRE},
title={A Method for the Construction of Minimum-Redundancy Codes},
year={1952},
volume={40},
number={9},
pages={1098-1101},
keywords={Transmitters},
doi={10.1109/JRPROC.1952.273898},
ISSN={0096-8390},
month={Sept},}

@misc{VideoMarketing,
  author = {McCue, TJ},
  title = "Video Marketing In 2018 Continues To Explode As Way To Reach Customers",
  year = 2018,
  url = {https://www.forbes.com/sites/tjmccue/2018/06/22/video-marketing-2018-trends-continues-to-explode-as-the-way-to-reach-customers/#9d77d9e598dc},
  urldate = {2018-11-18}
}

@misc{CUBLAS,
  author = {Nvidia},
  title = "Dense Linear Algebra on GPUs",
  year = 2018,
  url = {https://developer.nvidia.com/cublas},
  urldate = {2018-11-19}
}

@misc{CUDAMAIN,
  author = {Nvidia},
  title = "CUDA Zone",
  year = 2018,
  url = {https://developer.nvidia.com/cuda-zone},
  urldate = {2018-11-19}
}

@misc{CUDACGUIDE,
  author = {Nvidia},
  title = "CUDA C Programming Guide",
  year = 2018,
  url = {https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html},
  urldate = {2018-11-19}
}

@misc{FFmpeg,
  author = {FFmpeg},
  title = "FFmpeg",
  year = 2018,
  url = {https://www.ffmpeg.org/},
  urldate = {2018-11-17}
}

@misc{Boost,
  author = {Boost},
  title = "Gzip Filters",
  year = 2018,
  url = {https://www.boost.org/doc/libs/1_68_0/libs/iostreams/doc/classes/gzip.html},
  urldate = {2018-11-15}
}

@misc{OpenCV,
  author = {OpenCV},
  title = "OpenCV (Open Source Computer Vision Library)",
  year = 2018,
  url = {https://opencv.org/},
  urldate = {2018-11-19}
}

@misc{Eigen,
  author = {Eigen},
  title = "Eigen Overview",
  year = 2018,
  url = {http://eigen.tuxfamily.org/index.php?title=Main_Page},
  urldate = {2018-11-19}
}

@article{mitchell1992digital,
  title={Digital compression and coding of continuous-tone still images: Requirements and guidelines},
  author={Mitchell, J},
  journal={ITU-T Recommendation T},
  volume={81},
  year={1992}
}