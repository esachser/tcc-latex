% 
% exemplo genérico de uso da classe iiufrgs.cls
% $Id: iiufrgs.tex,v 1.1.1.1 2005/01/18 23:54:42 avila Exp $
% 
% This is an example file and is hereby explicitly put in the
% public domain.
% 
\documentclass[cic,tc]{iiufrgs}
% Para usar o modelo, deve-se informar o programa e o tipo de documento.
% Programas :
% * cic       -- Graduação em Ciência da Computação
% * ecp       -- Graduação em Ciência da Computação
% * ppgc      -- Programa de Pós Graduação em Computação
% * pgmigro   -- Programa de Pós Graduação em Microeletrônica
% 
% Tipos de Documento:
% * tc                -- Trabalhos de Conclusão (apenas cic e ecp)
% * diss ou mestrado  -- Dissertações de Mestrado (ppgc e pgmicro)
% * tese ou doutorado -- Teses de Doutorado (ppgc e pgmicro)
% * ti                -- Trabalho Individual (ppgc e pgmicro)
% 
% Outras Opções:
% * english    -- para textos em inglês
% * openright  -- Força início de capítulos em páginas ímpares (padrão da
% biblioteca)
% * oneside    -- Desliga frente-e-verso
% * nominatalocal -- Lê os dados da nominata do arquivo nominatalocal.def


% Use unicode
\usepackage[utf8]{inputenc}   % pacote para acentuação

% Necessário para incluir figuras
\usepackage{graphicx}         % pacote para importar figuras

\usepackage{times}            % pacote para usar fonte Adobe Times
% \usepackage{palatino}
% \usepackage{mathptmx}       % p/ usar fonte Adobe Times nas fórmulas
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{bm}
\usepackage{amsthm}      % Teoremas
\usepackage{thmtools}    % Front end para amsthm (\declaretheorem)
\usepackage{icomma}
\usepackage{listings}
\usepackage{tcolorbox}
\usepackage{hyperref}
\usepackage{multirow}

\newcommand{\lstfont}[1]{\color{#1}\scriptsize\ttfamily}

\declaretheorem[style=definition,name=Definição,parent=chapter,qed=\textemdash]{definicao}
\declaretheorem[style=plain,name=Teorema,qed=\textnormal{\textemdash}]{teorema}
\declaretheorem[style=plain,name=Axioma,qed=\textnormal{\textemdash}]{axioma}

\usepackage[alf,abnt-emphasize=bf]{abntex2cite}	% pacote para usar citações abnt

\usepackage[portuguese,ruled,vlined,boxed]{algorithm2e}
\renewcommand{\algorithmautorefname}{Algoritmo}% para utilizar \autoref

\def\SPSB#1#2{\rlap{\textsuperscript{#1}}\SB{#2}}
\def\SP#1{\textsuperscript{#1}}
\def\SB#1{\textsubscript{#1}}

\renewcommand{\vec}[1]{\bm{#1}}
\newcommand{\mat}[1]{\bm{#1}}
\newcommand{\reg}{\textsuperscript{\textregistered}}

\usepackage{mathtools}
\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}
\DeclarePairedDelimiter{\floor}{\lfloor}{\rfloor}


\lstset{
    language=[ANSI]C++,
    showstringspaces=false,
    backgroundcolor=\color{white},
    basicstyle=\lstfont{black},
    identifierstyle=\lstfont{black},
    keywordstyle=\lstfont{blue!95},
    numberstyle=\lstfont{black},
    stringstyle=\lstfont{cyan},
    commentstyle=\lstfont{green!90},
    emph={
        cudaMalloc, cudaFree,
        __global__, __shared__, __device__, __host__,
        __syncthreads,
    },
    emphstyle={\lstfont{green!60!black}}
}


% 
% Informações gerais
% 
\title{Aplicação de técnicas de compressed sensing e aprendizado de dicionários para codificação de vídeos em tempo real}

\author{Sachser}{Eduardo}
% alguns documentos podem ter varios autores:
% \author{Flaumann}{Frida Gutenberg}
% \author{Flaumann}{Klaus Gutenberg}

% orientador e co-orientador são opcionais (não diga isso pra eles :))
\advisor[Prof.~Dr.]{Oliveira Neto}{Manuel Menezes de }
% \coadvisor[Prof.~Dr.]{Knuth}{Donald Ervin}

% a data deve ser a da defesa; se nao especificada, são gerados
% mes e ano correntes
% \date{maio}{2001}

% o local de realização do trabalho pode ser especificado (ex. para TCs)
% com o comando \location:
% \location{Itaquaquecetuba}{SP}

% itens individuais da nominata podem ser redefinidos com os comandos
% abaixo:
% \renewcommand{\nominataReit}{Prof\textsuperscript{a}.~Wrana Maria Panizzi}
% \renewcommand{\nominataReitname}{Reitora}
% \renewcommand{\nominataPRE}{Prof.~Jos{\'e} Carlos Ferraz Hennemann}
% \renewcommand{\nominataPREname}{Pr{\'o}-Reitor de Ensino}
\renewcommand{\nominataPRAPG}{Prof.~Vladimir Pinheiro do Nascimento}
% \renewcommand{\nominataPRAPGname}{Pr{\'o}-Reitora Adjunta de P{\'o}s-Gradua{\c{c}}{\~a}o}
% \renewcommand{\nominataDir}{Prof.~Philippe Olivier Alexandre Navaux}
% \renewcommand{\nominataDirname}{Diretor do Instituto de Inform{\'a}tica}
\renewcommand{\nominataCoord}{Prof.~Sérgio Luis Cechin}
% \renewcommand{\nominataCoordname}{Coordenador do PPGC}
% \renewcommand{\nominataBibchefe}{Beatriz Regina Bastos Haro}
% \renewcommand{\nominataBibchefename}{Bibliotec{\'a}ria-chefe do Instituto de Inform{\'a}tica}
% \renewcommand{\nominataChefeINA}{Prof.~Jos{\'e} Valdeni de Lima}
% \renewcommand{\nominataChefeINAname}{Chefe do \deptINA}
% \renewcommand{\nominataChefeINT}{Prof.~Leila Ribeiro}
% \renewcommand{\nominataChefeINTname}{Chefe do \deptINT}

% A seguir são apresentados comandos específicos para alguns
% tipos de documentos.

% Relatório de Pesquisa [rp]:
% \rp{123}             % numero do rp
% \financ{CNPq, CAPES} % orgaos financiadores

% Trabalho Individual [ti]:
% \ti{123}     % numero do TI
% \ti[II]{456} % no caso de ser o segundo TI

% Monografias de Especialização [espec]:
% \espec{Redes e Sistemas Distribuídos}      % nome do curso
% \coord[Profa.~Dra.]{Weber}{Taisy da Silva} % coordenador do curso
% \dept{INA}                                 % departamento relacionado

% 
% palavras-chave
% iniciar todas com letras minúsculas, exceto no caso de abreviaturas
% 
\keyword{compressed sensing}
\keyword{compressive sampling}
\keyword{aprendizado de dicionários}
\keyword{tempo real}
\keyword{video}
\keyword{UFRGS}

%\settowidth{\seclen}{1.10~}

% 
% inicio do documento
% 
\begin{document}

% folha de rosto
% às vezes é necessário redefinir algum comando logo antes de produzir
% a folha de rosto:
% \renewcommand{\coordname}{Coordenadora do Curso}
\maketitle

% dedicatoria
% \clearpage
% \begin{flushright}
%     \mbox{}\vfill
%     {\sffamily\itshape
%       ``If I have seen farther than others,\\
%       it is because I stood on the shoulders of giants.''\\}
%     --- \textsc{Sir~Isaac Newton}
% \end{flushright}

% agradecimentos
%\chapter*{Agradecimentos}
%Agradeço ao \LaTeX\ por não ter vírus de macro\ldots



% resumo na língua do documento
\begin{abstract}
    Milhões de vídeos circulam pela \emph{internet} diariamente.
    Para que isso seja possível, é necessário que existam e sejam 
    desenvolvidos métodos de codificação capazes de comprimir vídeos, 
    aliando compressibilidade a qualidade na representação.
    Este trabalho propõe uma metodologia para codificação e decodificação de 
    vídeos em tempo real, utilizando técnicas de \emph{compressed sensing} e aprendizado 
    de dicionários, além de quantização e compressão utilizando codificação de Huffman.
    % apresentando parametrizações possíveis e resultados alcançados 
    % a partir da variação dos parâmetros, gerando recomendações de parâmetros 
    % padrão que podem ser utilizados.
    Do ponto de vista teórico, o trabalho apresenta os conceitos fundamentais de representação
    de sinais, além 
    de aprofundar os assuntos de \emph{compressed sensing} e aprendizado de dicionários,
    mostrando alguns resultados alcançados e técnicas aplicadas a cada um dos assuntos.
    Também são abrangidos outros trabalhos que têm relação com a proposta,
    sobre os quais são discutidas as ideias principais, bem como resultados alcançados, e de que 
    maneira se relacionam com o trabalho proposto.
    Nos experimentos realizados, são discutidas as parametrizações possíveis do 
    codec proposto, apresentando resultados experimentais alcançados e recomendações 
    relativas ao uso do codec.
    O trabalho ainda compara o amplamente utilizado padrão de codificação e decodificação 
    de vídeos H.264
    com a proposta, através das métricas de bitrate e PSNR.
    Os resultados obtidos são inferiores ao padrão H.264 quando comparado o PSNR alcançado por ambos
    para um mesmo bitrate.
    O trabalho permite a compreensão dos assuntos
    de \emph{compressed sensing} e aprendizado de dicionários,
    aplicados ao problema de codificação de vídeos.
\end{abstract}

% resumo na outra língua
% como parametros devem ser passados o titulo e as palavras-chave
% na outra língua, separadas por vírgulas
% \title{Aplicação de técnicas de compressed sensing e aprendizado de dicionários para codificação de vídeos em tempo real}
\begin{englishabstract}{An application of compressed sensing and dictionary learning techniques for real-time video coding and decoding}
    {compressed sensing. compressive sampling. dictionary learning. real-time. UFRGS}
    Millions of videos run through the internet every day.
    To make this possible, coding methods must be developed, this ones capable of compress 
    video data, combining compressibility and quality of representation.
    This work proposes a method for real-time video coding and decoding,
    using compressed sensing and dictionary learning techniques, besides of quantization 
    and compression based on Huffman coding.
    From a theoretical point of view, this work introduces the fundamental concepts of 
    signal representation, in addition to deepening the subjects of compressed sensing 
    and dictionary learning, showing some achieved results and techniques applied to each of the subjects.
    Also are covered works related to the proposal,
    on which the main ideas are discussed, as well the achieved results, 
    and how they relate to the proposed work.
    In the experimentation are discussed the possible parameterizations of 
    the proposed codec, showing achieved experimental results and recomendations 
    related to the manner of using the codec.
    The work also compares the widely used video coding and decoding standard H.264
    with the proposal, through bitrate and PSNR metrics.
    The obtained results are lower than the H.264 standard when compared the achieved PSNR by the both 
    with same bitrates.
    This work allows to comprehend the subjects of compressed sensing and dictionary learning, 
    applying to video coding.
\end{englishabstract}

% lista de figuras
\listoffigures

% lista de tabelas
\listoftables

% lista de abreviaturas e siglas
% o parametro deve ser a abreviatura mais longa
\begin{listofabbrv}{CoSaMP}
    \item[CoDec] Coding and Decoding  
    \item[CoSaMP] Compressive Sampling Matching Pursuit 
    \item[CS] Compressed Sensing
    \item[DCT] Discrete Cosine Transform 
    \item[FPS] Frames por segundo
    \item[GPU] Graphical Processing Unit
    \item[ODL] Online Dictionary Learning 
    \item[OMP] Orthogonal Matching Pursuit
    \item[PSNR] Peak signal-noise ratio 
    \item[RIP] Restricted Isometric Property
\end{listofabbrv}

% idem para a lista de símbolos
% \begin{listofsymbols}{$\alpha\beta\pi\omega$}
%     \item[$\sum{\frac{a}{b}}$] Somatório do produtório
%     \item[$\alpha\beta\pi\omega$] Fator de inconstância do resultado
% \end{listofsymbols}

% sumario
\tableofcontents

% aqui comeca o texto propriamente dito

% introducao
\chapter{Introdução}
% O processo de globalização vem acontecendo em todo mundo, 
% e uma grande aliada desse processo é a internet.
% Essa jovem e promissora tecnologia tem transformado a vida das pessoas.
% Em especial, a internet trouxe novas formas de comunicação.

% Hoje em dia é possível comunicar-se mesmo em longas distâncias, 
% através da internet.
% Reuniões podem ser feitas através de videoconferências, transmissões 
% em tempo real de eventos, streaming de vídeo e áudio passam por 
% inúmeros dispositivos conectados a grande rede.
% Tais dispositivos vão desde grandes datacenters, passando por computadores 
% pessoais, laptops, smartphones, e até câmeras de monitoramento instaladas
% em cidades, todos com a capacidade de receber e enviar informações 
% pela internet.

Segundo a revista Forbes \cite{VideoMarketing}, mais de 500 milhões de horas de vídeos são assistidos 
diariamente no Youtube. 
Ainda segundo a revista, até 2021, 17.000 horas de conteúdo de vídeo passarão 
pela \emph{internet}, por segundo.
Isso somente é possível graças a eficiência 
dos padrões de compressão e transmissão de vídeo e áudio criados ao longo dos anos, 
e ainda sendo estudados e melhorados.
Diversos padrões foram criados, e com o avanço tecnológico, mais tecnologias
são possíveis de serem aplicadas a novos padrões, permitindo que mais informação
trafegue na rede com menor quantidade de dados sendo necessários.

Dentro desse contexto, este trabalho explora o uso de \emph{compressed sensing} e aprendizado de 
dicionários (\emph{dictionary learning}), para 
codificação de vídeos em tempo real.
O trabalho também avalia o desempenho da técnica implementada, comparando-o com o do codificador H.264. 

\section{Objetivos}
Este trabalho tem os seguintes objetivos:
\begin{itemize}
    \item Apresentar uma proposta de codificação de decodificação de vídeos
    em tempo real baseada em técnicas de \emph{compressed sensing} e aprendizado de 
    dicionários;
    \item Realizar medidas comparativas entre as diversas possibilidades 
    de parametrização do objeto do trabalho proposto;
    \item Realizar medidas comparativas com outros padrões conhecidos de 
    codecs de vídeo;
    \item Aprofundar o conhecimento da área de \emph{compressed sensing} e aprendizado 
    de dicionários através aplicação de técnicas relacionadas a tais assuntos.
\end{itemize}

\section{Notações Utilizadas}
Algumas notações serão utilizadas ao longo de todo o trabalho.
Para representar matrizes, serão utilizadas letras gregas ou romanas, 
maiúsculas e em negrito, por exemplo $\mat{X}$.
As colunas de $\mat{X}$ serão representadas pela letra correspondente 
minúscula em negrito, com o indexador da coluna, $\vec{x_i}$, também em negrito.
Outra forma possível de representar partes de uma matriz é $\mat{X_{:,i}}$,
que representa todas as linhas da coluna $i$, e $\mat{X_{i,:}}$, que representa 
todas as colunas da linha $i$.
% Melhorar o exemplo
Um valor qualquer da matriz é descrito como $\mat{X_{i,j}}$.
Letras minúsculas em negrito representarão vetores.
A indexação de vetores acontecerá no formato $x_i$, não utilizando negrito. % Revisar todo o texto

%Apresentar normas e (t)
Alguns algoritmos calculam variáveis relacionadas a uma determinada iteração $t$.
Nesses algoritmos, seguindo as notações anteriormente apresentadas, $\mat{X_{(t)}}$ 
representa a matriz $\mat{X}$ na t-ésima iteração.
O mesmo acontece com vetores, por exemplo, $\vec{x_{(t)}}$.

% A cada iteração t o valor de X é alterado, na iteração.
Além dessas definições, é utilizado o conceito de produto interno 
de dois vetores $\vec{x}, \vec{y} \in \mathbb{R}^m$, 
conforme a seguinte notação:
\begin{equation*}
    \langle \vec{x}, \vec{y} \rangle = \sum_{i=1}^m {x_i y_i}.
\end{equation*}

Por fim, vale lembrar a definição da norma $\ell_p$ para um vetor $\vec{x} \in \mathbb{R}^m$:
\begin{equation*}
    \lVert \vec{x} \rVert_p = 
    \left( \sum_{i=1}^m {|x_i|^p} \right)^{\frac{1}{p}}, 
\end{equation*}
podendo escrever, portanto, a norma $\ell_2$, por exemplo, como:
\begin{equation*}
    \lVert \vec{x} \rVert_2 = 
    \sqrt{\sum_{i=1}^m {x_i^2}},
\end{equation*}
e a norma $\ell_1$:
\begin{equation*}
    \lVert \vec{x} \rVert_1 = 
    \sum_{i=1}^m {|x_i|}.
\end{equation*}

As normas acima apresentadas, bem como as notações, serão amplamente utilizadas
em todo o texto. 
Outras definições serão agregadas ao longo do texto, somando-se as atuais, 
que foram apresentadas por serem aplicadas em toda a extensão do trabalho.

\section{Estrutura do Trabalho}
O Capítulo \ref{cap:ref} apresenta os conceitos fundamentais que serviram de base
para a elaboração da proposta do trabalho,
abordando assuntos relativos a processamento de sinais, \emph{compressed sensing} e 
aprendizado de dicionários.
No Capítulo \ref{cap:relacionados} discutem-se alguns trabalhos que inspiraram a 
proposta ou que apresentam diferentes óticas para o mesmo problema.
A seguir, será detalhada a proposta. 
Baseando-se na mesma, serão apresentados alguns resultados de experimentos 
aplicados ao objeto do trabalho, encerrando com conclusões tiradas com 
base na proposta, nos trabalhos relacionados, e nos experimentos executadas.

\chapter{Conceitos Fundamentais}
\label{cap:ref}

\section{Introdução a Sinais e Sistemas}
O trabalho apresenta uma metodologia para compressão de vídeos.
Porém, vídeos são, particularmente, uma sequência de imagens.
Já imagens, por sua vez, são um exemplo de sinais bidimensionais.
Vídeos, portanto, sinais tridimensionais.
Fica claro, a partir do posto acima, que há a necessidade de observar-se 
o que é um sinal e alguns resultados importantes, primeiramente, para 
em seguida aprimorarem-se os estudos acerca de outros conceitos.

"Um sinal é formalmente definido como uma função de uma ou mais variáveis, 
a qual veicula informações sobre a natureza de um fenômeno físico"~ \cite{haykin2001sinais}.
Também segundo \citet{haykin2001sinais}, os sinais são chamados unidimensionais quando
dependem de apenas uma variável, e multidimensionais quando dependem de mais que uma.
Como exemplo de sinais unidimensionais existem os sinais de som, dependentes apenas da variável tempo.
Já exemplos de sinais multidimensionais foram citadas anteriormente, imagens e vídeos. 

Além disso, deve-se definir o conceito de "sistema". 
Segundo \citet{haykin2001sinais}, "Um sistema é definido como uma entidade que manipula
um ou mais sinais para realizar uma função, produzindo novos sinais".
Um exemplo simples poderia ser o controle de volume de um aparelho de som,
que gera um novo sinal proporcional ao sinal de entrada.
Podemos considerar sistemas bem mais complexos também, como um reconhecedor 
de faces, que precisa tomar como sinais as faces já conhecidas e a que se 
deseja reconhecer, e fornece como saída o nome ou as informações da face reconhecida.

Sinais podem ser contínuos - ou analógicos - e digitais.
Na verdade, em geral, sinais da natureza são contínuos, mas são digitalizados 
para que seja possível armazená-los, enviá-los e transmiti-los por meios digitais.
Dessa forma, \citet{haykin2001sinais} apresentam os passos geralmente executados 
para digitalizar sinais analógicos:
\begin{enumerate}
    \item \emph{Amostragem:} O sinal analógico é amostrado com determinada taxa de amostragem;
    \item \emph{Quantização:} Cada uma das amostras é transformada para um valor digital em um intervalo definido;
    \item \emph{Codificação:} Os valores quantizados são salvos de alguma forma;
    \item \emph{Redundância:} Podem ser geradas informações de redundância para armazenamento do sinal.
\end{enumerate} 

De uma forma geral, a aquisição ou até mesmo a transmissão de um sinal podem conter ruído.
Dessa forma, pode-se imaginar que um sinal amostrado é composto pelo próprio sinal somado ao ruído,
$\vec{f} = \vec{y} + \vec{e}$, no qual $\vec{f}$ é a amostragem, $\vec{y}$ é o sinal real, 
e $\vec{e}$ é o erro.

Uma definição importante para o prosseguimento do trabalho é a de energia $E$ de um sinal $\vec{f} \in \mathbb{R}^m$, como segue:
\begin{equation}
    E = \sum_{i=1}^m f_i^2 = \lVert \vec{f} \rVert_2^2,
\end{equation}
onde $f_i$ representa a i-ésima componente do vetor $\vec{f}$.

Por fim, um resultado clássico sobre amostragem de sinais no domínio tempo, o teorema de Nyquist.
\begin{teorema}
    \cite{NyquistSampling}.
    Um sinal contínuo pode ser apropriadamente amostrado somente se a máxima frequência $f_{max}$ contida 
    no sinal for menor que metade da taxa de amostragem $f_s$:
    \begin{equation*}
        f_{max} < \frac{f_s}{2}.
    \end{equation*}
    \label{teo:nyquist}
\end{teorema}

% A partir desse pequeno resumo focado em amostragem de sinais digitais,
% as próximas seções utilizarão os conceitos apresentados para formularem outros novos.

\section{Compressed Sensing}
% \subsection{O modelo de Compressed Sensing}
\textit{Compressed Sensing (CS)} ou \textit{Compressive Sampling} é um campo de estudo de sinais cujos
primeiros trabalhos surgiram a partir de 2006, a partir da análise de amostragens executadas em imagens de 
ressonância magnética. Essas amostragens eram de muito menor dimensionalidade do que a da imagem, o que 
fez com que os métodos conhecidos de processamento de sinais não tivessem boa acurácia.

"Muitos sinais de interesse possuem menos informação do que a dimensão do ambiente sugere"
\footnote{"Many signals of interest contain far less information than their ambient dimension suggests"}
(\citeauthor{chen2015compressed}, \citeyear{chen2015compressed}, p. 2, tradução livre).
As formas tradicionais de aquisição de sinais baseadas no teorema de Nyquist (\ref{teo:nyquist}) 
geram informação redundante.
% acabam por causar o descarte de boa parte da informação coletada durante a etapa de compressão. 
Tal fato traz a tona a pergunta: existe 
uma forma de aquisição de sinais na qual as amostras comprimidas são obtidas diretamente? \cite{chen2015compressed}.
Em diversas situações, na verdade, o que se tem em mãos são somente as medidas que foram executadas, 
e conhecida a forma na qual a amostragem foi feita, além do conhecimento de que existe uma representação
esparsa do sinal em determinada base.
Em especial para essas situações o \emph{compressed sensing} é bastante adequado.

O modelo de \emph{compressed sensing} surgiu com esse intuito \cite{DonohoCS}. Trabalhos na área mostram que, para certas classes
de sinais, poucas amostras são necessárias para representar o sinal com acurácia \cite{chen2015compressed}.
% Ou seja, \emph{compressed sensing} busca encontrar quais tipos
% de sinais podem ser amostrados de forma já comprimida e respostas de como fazê-lo.

De acordo com o modelo, para um dado sinal $ \vec{f} \in \mathbb{C}^d $, 
amostragens são executadas na seguinte forma, utilizando produto interno:
\begin{equation}
    y_i = \langle \vec{\phi_i}, \vec{f} \rangle \text{ para } i=1,2,...,m, 
\end{equation}
na qual $m \ll d$. Os vetores $\vec{\phi_i} \in \mathbb{R}^d$ são linhas de uma matriz $\mathbf{\Phi} \in \mathbb{R}^{m \times d}$, chamada matriz 
de amostragem. Assim, pode-se reescrever o vetor de amostragem como $\vec{y} = \mathbf{\Phi} \vec{f}$. Fica claro que, 
se $ m \ll d$, reconstruir $\vec{f}$ a partir de $\vec{y}$, sem assumir nada a mais, é um problema 
com infinitas soluções \cite{chen2015compressed}.

Uma importante consideração que CS faz é a de que os sinais de interesse possuem menos informação do que sugere a 
dimensão $d$. 
Uma forma de quantificar essa noção é a esparsidade.
Considere-se a quantidade de valores não
nulos $s$ de um sinal $\vec{f} \in \mathbb{C}^d$, também conhecida como norma $\ell_0$:
\begin{equation}
    \lVert \vec{f} \rVert_0 = s.
\end{equation}
Considerando o mesmo sinal $\vec{f}$, diz-se que este é \textit{s-esparso}, quando, para dado um um valor $s$, $\vec{f}$
satisfaz a seguinte inequação:
\begin{equation}
    \label{eq:f0less}
    \lVert \vec{f} \rVert_0 \le s \ll d.
\end{equation} 

Na prática, sinais não são usualmente encontrados esparsos, o que leva a definição de \textit{sinais compressíveis},
que são aqueles que obedecem à seguinte lei de decaimento exponencial \cite{chen2015compressed}:
\begin{equation}
    \label{eq:compressiblesignal}
    | f\SPSB{*}{k} | < R k^{-\frac{1}{q}},  
\end{equation}
tal que $\vec{f}^* $ é o rearranjo decrescente de $\vec{f}$, ou seja, o vetor $\vec{f}$ reorganizado de forma que o maior 
coeficiente em magnitude seja $f_1^*$, o segundo maior, $f_2^*$, e assim por diante. $R$ é uma constante positiva e $0< q < 1$. 
Para ilustrar essa ideia, o gráfico abaixo apresenta curvas geradas variando $q$, usando $R=1,0$
e no eixo x a variação de $k$.
Um sinal compressível é aquele que cada coeficiente $f_k^*$ fica abaixo da curva apresentada,
para algum $q$. 
\begin{figure}[H]
    \caption{Curvas de limite superior para sinais compressíveis com $R=1,0$, $k$ no eixo x e valores 
    diferentes valores de $q$.}
    \begin{center}
        \includegraphics[width=\textwidth]{img/rkq.png}
    \end{center}
    \legend{Fonte: O Autor.}
\end{figure}

Percebe-se que para valores bem pequenos de $q$ a compressibilidade se torna praticamente o mesmo que esparsidade.
% Fazer gráfico para ilustrar, aí fica mais fácil de dizer isso. OK
Segundo \citet{chen2015compressed}, se considerar-se 
$\vec{f_s}$ o vetor com os $s$ maiores valores de $\vec{f}$ em magnitude, temos que, para sinais compressíveis $\vec{f}$ e 
$\vec{f_s}$:
\begin{equation}
    \lVert \vec{f} - \vec{f_s} \rVert_2 \le Rs^{\frac{1}{2} - \frac{1}{q}} \hspace{1em} \text{ e } \hspace{1em}
    \lVert \vec{f} - \vec{f_s} \rVert_1 \le Rs^{1 - \frac{1}{q}}.
\end{equation} 

Por fim, a definição \eqref{eq:f0less} exige que $\vec{f}$ seja esparso, ou seja, tenha $s$ coeficientes não nulos
no máximo. 
Por outro lado, $\vec{f}$ pode ser esparso em alguma outra base ortonormal $\mathbf{D}$, aqui referida como 
\textit{sparsifying basis} \cite{CandesDecoLinear}. Nesse caso, considera-se $\vec{f}$ s-esparso se:
\begin{equation}
    \vec{f} = \mathbf{D}\vec{x} \hspace{1em} \text{dado que} \hspace{1em} \lVert \vec{x} \rVert_0 \le s \ll d.
\end{equation}


\subsection{Mecanismos de Amostragem}
A partir das definições básicas do modelo, pode-se formular o problema básico de CS da seguinte forma.
Tomando um operador de amostragem $\mathbf{\Phi}$, o mapeamento linear de $\mathbb{C}^d$ para algum espaço de dimensão 
$\mathbb{C}^m$, para recuperarmos um sinal $\vec{f}$ a partir de suas medidas $\vec{y} = \mathbf{\Phi} \vec{f}$,
pode ser descrito como um problema de minimização:
\begin{equation}
    \label{eq:problem}
    \vec{f}' = \underset{\vec{g} \in \mathbb{C}^d}{\text{argmin}} \lVert \vec{g} \rVert_0 \hspace{1em} \text{sujeito a} \hspace{1em}
    \mathbf{\Phi} \vec{g} = \vec{y}.
\end{equation}

Se $\mathbf{\Phi}$ não mapeia 2 vetores esparsos quaisquer para o mesmo valor de $\vec{y}$, ou seja,
se $\vec{f} \ne \vec{g} \rightarrow \mathbf{\Phi}\vec{f} \ne \mathbf{\Phi}\vec{g} $, então a solução $\vec{f}'$ recupera
$\vec{f}$, $\vec{f}' = \vec{f}$ \cite{chen2015compressed}. Esse problema, por outro lado, é intratável, e, em geral,
NP-difícil \cite{Mut05}.
Para que o operador de amostragem forneça o resultado anterior, ele deve ser \textit{incoerente}.
Dado um operador $\mathbf{\Phi}$ de colunas $\{ \vec{\phi_i} \}$  com norma unitária, define-se a sua coerência $\mu$
como a maior correlação entre suas colunas:
\begin{equation}
    \label{eq:coerence}
    \mu = \underset{i \ne j}{max}\langle \vec{\phi_i} , \vec{\phi_j} \rangle.
\end{equation}

Fica definido, portanto, que um operador de amostragem é \textit{incoerente} quando a sua coerência $\mu$ é 
suficientemente pequena. Por exemplo, um operador de amostragem que seja uma base ortonormal é incoerente.
% Outro exemplo de operador de amostragem incoerente é 
% Melhorar o exemplo
bem como operadores que sejam aproximadamente ortonormais para vetores esparsos.
Nesse segundo caso, pode-se imaginar, por exemplo, que o conjunto de vetores esparsos utiliza 
somente os índices $i$, $j$ e $k$.
Dessa forma, apenas as colunas de $\mat{\Phi}$ correspondentes a $i$, $j$ e $k$ precisam ser 
ortonormais entre si, ou com baixa coerência entre essas mesmas colunas.

Uma propriedade que captura a mesma ideia que o referido acima foi desenvolvida por \citet{CandesSignalRecovery}, chamada 
\textit{restricted isometry property} (RIP). A constante de isometria restrita 
$\delta_s$ é o menor valor tal que:
\begin{equation}
    \label{eq:rip}
    (1 - \delta_s)\lVert \vec{f} \rVert\SPSB{2}{2} \le \lVert \mathbf{\Phi} \vec{f} \rVert \SPSB{2}{2} \le 
    (1 + \delta_s)\lVert \vec{f} \rVert\SPSB{2}{2} \hspace{1em} \text{para todo vetor s-esparso } \vec{f}.
\end{equation}

Diz-se que um operador de amostragem $\mathbf{\Phi}$ satisfaz a RIP de ordem $s$ quando $\delta_s$ é suficientemente
pequeno. %, por exemplo, $\delta_s \le 0,1$.
A questão importante da RIP é descobrir qual o número de amostras $m$ é necessária e quais são as 
classes de matrizes que possuem a propriedade. Dois importantes exemplos de matrizes que satisfazem a RIP são
as seguintes \cite{chen2015compressed}: 
\begin{itemize}
    \item \textbf{Matrizes subgaussianas}: uma variável randômica $\mat{X}$ é subgaussiana se 
    $\mathbb{P}(|\mat{X}| > t) \le C_1e^{-vt^2}$ para todo $t>0$ e constantes positivas $C_1$ e $v$. Ou seja,
    variáveis subgaussianas possuem distribuição de média aproximadamente $0$, e a maior parte dos valores
    próximos a média. Exemplos dessa distribuição são a própria distribuição Gaussiana e a matrizes de 
    Bernoulli, que possuem coeficientes $-1$ e $+1$ distribuídos com média $0$. \citet{Mendelson2008} provaram que
    se $\mat{\Phi} \in \mathbb{R}^{m\times d}$ é subgaussiana, então, com alta probabilidade, $\frac{1}{\sqrt{m}}\mat{\Phi}$
    satisfaz a RIP de ordem $s$ quando $m$ está na ordem de $s\log{d}$.
    \item \textbf{Matrizes parcialmente ortogonais limitadas}: dada uma matriz ortogonal $\mat{\Psi}$ com dimensões $d\times d$
    cujos coeficientes são limitados por $\frac{C_2}{\sqrt{d}}$ para uma constante $C_2$. Uma matriz parcialmente
    ortogonal limitada $\mat{\Phi}$ pode ser obtida escolhendo $m$ colunas de $\mat{\Psi}$ randomicamente.
    Por exemplo, a matriz da transformada discreta de Fourier tem coeficientes limitados em $\frac{1}{\sqrt{d}}$.
    Logo, escolhendo-se $m$ linhas randomicamente tem-se uma matriz parcialmente ortogonal limitada.
    \citet{rudelson2008sparse} provaram que essas matrizes satisfazem RIP com alta probabilidade quando
    o número de medidas $m$ é na ordem de $s\log^4{d}$.
\end{itemize}


\subsection{Algoritmos aplicados ao modelo de Compressive Sensing}
\label{sec:csalgo}
Ao considerar-se a formulação do problema geral de CS apresentada na seção anterior, um dos resultados também apresentados
é de que o problema é NP-difícil. Sob essa ótica, diversas soluções alternativas foram desenvolvidas com 
o intuito de, através da solução de algum outro problema relacionado, ou do uso de alguma estratégia diferente, fosse possível 
chegar a uma solução ótima para a formulação de CS. 

Inicialmente, é necessário levar em consideração que nem sempre as amostras coletadas estão completamente corretas.
Dessa forma, tem-se um novo vetor de medidas, $\vec{y} = \mathbf{\Phi} \vec{f} + \vec{e}$, que considera o ruído de amostragem, 
ou vetor de erro, $\vec{e}$.

Além disso, é essencial definir as propriedades ideais de um método de recuperação
baseado em CS. Segundo \citet{chen2015compressed}, as propriedades são as seguintes:
\begin{itemize}
    \item \textbf{Amostragem não adaptativa:} Os operadoes de amostragem não devem ser dependentes do sinal. 
          Operadores que possuem RIP também possuem essa propriedade.
    \item \textbf{Número ótimo de amostras:} O número de amostras necessárias deve ser mínimo.
    \item \textbf{Garatia de uniformidade:} Um único operador de amostragem deve ser suficiente para qualquer sinal.
    \item \textbf{Robustez:} O método deve ser estável e robusto em relação ao ruído, e possuir garantias 
          quanto ao erro.
    \item \textbf{Complexidade:} O algoritmo deve ser computacionalmente eficiente.
\end{itemize}

Buscando obedecer o maior número das propriedades citadas acima, alguns métodos e algoritmos surgiram. 
Nas subseções seguintes serão descritas duas metodologias que foram utilizadas para tal.

\subsubsection{Métodos baseados em otimização}
Essa metodologia, utilizada pelos primeiros trabalhos na área, utiliza uma relaxação convexa como forma
de chegar a solução do problema \eqref{eq:problem}. 
Ou seja, utiliza a norma $\ell_1$ ao invés da norma $\ell_0$,
de forma que o problema se torne convexo e solúvel através de métodos de programação linear.

Dessa forma, o problema relaxado para a norma $\ell_1$ fica como segue:
\begin{equation}
    \label{eq:probleml1}
    \vec{f'} = \underset{\vec{g} \in \mathbb{C}^d}{\text{argmin}} \lVert \vec{g} \rVert_1 \hspace{1em} \text{sujeito a} \hspace{1em}
    \lVert \mathbf{\Phi} \vec{g} - \vec{y} \rVert_2 \le \epsilon,
\end{equation}
tal que $\lVert \vec{e} \rVert_2 \le \epsilon $.

A geometria da norma $\ell_1$ permite esparsidade, como pode-se ver no exemplo a seguir. Imaginando-se 
que a reta em verde retrata todas as possíveis soluções para um sinal $\vec{f} \in \mathbb{R}^2$, os pontos
mais esparsos da reta são $A=(0;1)$ e $B=(-1,66;0)$. A região em azul limita todos os pontos 
nos quais $\lVert\vec{p}\rVert_1 \le 1,0$, tal que $\vec{p} \in \mathbb{R}^2$. Nesse caso, o ponto $A$ é o 
de menor norma $\ell_1$ da reta, sendo essa a solução do problema \eqref{eq:probleml1} e, ao mesmo tempo, 
uma das possíveis soluções do problema \eqref{eq:problem}.
\begin{figure}[h]
    \caption{Minimização $\ell_1$ nos pontos da reta.}
    \begin{center}
        \includegraphics[width=0.9\textwidth]{img/l1ball}
    \end{center}
    \legend{Fonte: O Autor.}
    \label{fig:l1ball}
\end{figure}

\citet{candes2006stable} chegaram a resultados quanto a garantias para os limites de erro, baseado na 
intensidade do ruído, como segue.
\begin{teorema}
    \cite{candes2006stable}. 
    Dado um operador de amostragem $\mathbf{\Phi}$ que satisfaz a RIP.
    Então, para qualquer sinal $\vec{f}$ e sua amostragem ruidosa $\vec{y} = \mathbf{\Phi}\vec{f} + \vec{e}$, 
    tal que $\lVert \vec{e} \rVert_2 \le \epsilon$, a solução $\vec{f}'$ de \eqref{eq:probleml1} satisfaz:
    \begin{equation*}
        \lVert \vec{f}' - \vec{f} \rVert_2 \le C_3 \left[ \epsilon + \frac{\lVert \vec{f} - \vec{f_s} \rVert_1}{\sqrt{s}} \right],
    \end{equation*}
    tal que $\vec{f_s}$ denota o vetor com os $s$ maiores coeficientes em magnitude de $\vec{f}$ e $C_3$ é uma
    constante tal que $C_3 \ge 0$.
\end{teorema}

\subsubsection{Métodos utilizando algoritmos gulosos}
\label{sec:greedy}
Depois da formalização do problema de CS, gerando a demanda para uma solução,
surgiram os primeiros algoritmos que, de forma iterativa, resolvem o problema \eqref{eq:problem}. 
Um dos principais algoritmos é o \textit{Orthogonal Matching Pursuit (OMP)}, analisado por Gilbert e Tropp \cite{GilbertOMP}.
Segundo \citet{GilbertOMP}, o algoritmo do OMP é o que segue:
\vspace{1em}

\begin{algorithm}[H]
\label{algo:omp}
\caption{\textit{Orthogonal Matching Pursuit (OMP)}.}
\Entrada{Matriz de amostragem $m \times d$ $\mathbf{\Phi}$, 
Vetor de $m$ medidas $\vec{y} = \mat{\Phi}\vec{f} $, 
parâmetro de esparsidade $s$}
\Saida{Estimativa do sinal ideal $\vec{f'} \in \mathbb{R}^d$}
$\vec{r_{(0)}} \leftarrow \vec{y}$\;
$t \leftarrow 1$\;
$\Lambda_{(0)} \leftarrow \emptyset$\;
$\mat{\Phi_{(0)}} \leftarrow []$\;
$\vec{f'} \leftarrow \vec{0}$\;
\While{$t \le s$}{
    // Retorna o primeiro índice $j$ que possui o maior produto interno.\\
    $\lambda_{(t)} = \underset{j=1,...,d}{argmax}|\langle\vec{r_{(t-1)}}, \vec{\phi_j}\rangle|$\; 
    $\Lambda_{(t)} = \Lambda_{(t-1)} \cup \left\{\lambda_{(t)}\right\}$\;
    $\mathbf{\Phi_{(t)}} = \left[ \mathbf{\Phi_{(t-1)}} \hspace{0.5em} \vec{\phi_{\lambda_{(t)}}} \right]$\;
    Resolver problema de mínimos quadrados: $\vec{x_{(t)}} = \underset{\vec{x}}{argmin} \lVert \vec{y} - \mathbf{\Phi_{(t)}} \vec{x} \rVert^2$\;
    $\vec{a_{(t)}} \leftarrow \mathbf{\Phi_{(t)}} \vec{x_{(t)}}$\;
    $\vec{r_{(t)}} \leftarrow \vec{y} - \vec{a_{(t)}}$\;
    $t \leftarrow t + 1$\;
}
$\vec{f'}_{\Lambda_{(t-1)}} \leftarrow \vec{x_{(t-1)}}$\;
\end{algorithm}
\vspace{1em}

Uma importante observação relativa ao sucesso do algoritmo OMP é que, dado que a matriz $\mathbf{\Phi}$ é incoerente,
seu conjugado transposto multiplicado por si mesmo é próximo à identidade, ou seja, 
$\vec{u} = \mathbf{\Phi}^* \vec{y} = \mathbf{\Phi}^* \mathbf{\Phi} \vec{f}$ 
é muito próximo a $\vec{f}$. 
Logo, o algoritmo OMP considera que o mais alto coeficiente de 
$\vec{u}$ é um dos coeficientes esparsos de $\vec{f}$ \cite{chen2015compressed}.
\citet{GilbertOMP} ainda apresentam um teorema sobre o algoritmo.
\begin{teorema}
    \cite{GilbertOMP}.
    Dada uma matriz $\mathbf{\Phi}$ de dimensões $m \times d$ subgaussiana de medidas tal que $m \ge C s \log{d}$, e
    $\vec{f}$ um sinal s-esparso em $\mathbb{R}^d$.
    Então, com alta probabilidade, OMP reconstrui corretamente o sinal $\vec{f}$ a partir de suas
    medidas $\vec{y} = \mathbf{\Phi}\vec{f}$.
\end{teorema}
Sem nenhuma modificação, o OMP não é reconhecidamente robusto a ruído, nem oferece garantias de uniformidade (vide \autoref{sec:csalgo}).
Porém, esse algoritmo possui um baixo custo computacional e boa eficiência, tendo complexidade 
$O(s m d)$ \cite{chen2015compressed}. 
Algo que fica claro, observando-se o pseudo-código e a complexidade, é que o OMP tem desempenho inversamente
proporcional à esparsidade da solução, ou seja, a cada nova iteração no \textit{loop} principal, um 
novo coeficiente da solução é calculado.

Outros algoritmos de estratégia gulosa oferecem garantias de uniformidade, além de robustez a ruído, com 
limites demonstrados, bem como número de iterações e medidas. Dois principais destes algoritmos são o 
\textit{CoSaMP (Compressive Sampling Matching Pursuit)} \cite{NeedellCoSaMP}, e o 
\textit{IHT (Iterative Hard Thresholding)} \cite{BLUMENSATHIHT}.

\subsubsection{Métodos utilizando \textit{Total Variation}}
Em diversas aplicações, os sinais de interesse são imagens. Imagens naturais normalmente são compressíveis
em determinada base, como por exemplo Wavelets. 
Porém, a utilização dos métodos anteriores para recuperação 
destas imagens gera, algumas vezes, artefatos de alta frequência, que se tornam desagradáveis a
visualização \cite{chen2015compressed}.
Tal fato levou ao desenvolvimento de outro método de minimização, baseado em \textit{Total Variation},
ou seja, na minimização da norma $\ell_1$ do gradiente da imagem.

Para simplificar a definição, considere-se uma imagem em tons de cinza $\mat{X}$ de tamanho $n\times n$.
Por definição, a \textit{total variation norm} (TV) de uma imagem $\mat{X}$ é:
\begin{equation}
    \lVert \mat{X} \rVert_{TV} = \sum_{j,k}
    \sqrt{\left( \mat{X_{j+1,k}} - \mat{X_{j,k}} \right)^2 + \left( \mat{X_{j,k+1}} - \mat{X_{j,k}} \right)^2} = 
    \sum_{j,k} |\mat{(\nabla X)}_{j,k} |,
\end{equation}
no qual $\mat{\nabla X}$ é o gradiente da imagem (discreta) $\mat{X}$. O gradiente pode ser definido da 
seguinte forma:
\begin{align*}
    \mat{(X_x)}_{j,k} = \mat{X_{j+1,k}} - \mat{X_{j,k}} \\
    \mat{(X_y)}_{j,k} = \mat{X_{j,k+1}} - \mat{X_{j,k}},
\end{align*}
resultando, por fim, em:
\begin{equation}
    \mat{\nabla X} = 
    \begin{cases}
        \left( \mat{(X_x)}_{j,k}, \mat{(X_y)}_{j,k} \right), \hspace{0.5em} 1 \le j \le n-1, \hspace{0.5em} 1 \le k \le n-1 \\
        \left( 0, \mat{(X_y)}_{j,k} \right), \hspace{0.5em} j=n, \hspace{0.5em} 1 \le k \le n-1 \\
        \left( \mat{(X_x)}_{j,k}, 0 \right), \hspace{0.5em} 1 \le j \le n-1, \hspace{0.5em} k=n \\
        \left(0,0\right), \hspace{0.5em} j = n, \hspace{0.5em} k=n
    \end{cases}
\end{equation}

Após definidas essas bases, pode-se considerar a minimização a seguir, utilizando a norma TV \cite{chen2015compressed}.
\begin{equation}
    \mat{X'} = \underset{\mat{M} \in \mathbb{R}^{n\times n}}{argmin} \lVert \mat{M} \rVert_{TV} 
    \hspace{1em} \text{sujeito a} \hspace{1em}
    \lVert \vec{y} - A(\mat{M}) \rVert_2 \le \epsilon,
\end{equation}
tal que $A$ é uma função que realiza a vetorização da imagem, 
e em seguida amostragem de alguns coeficientes.
$\vec{y} = A(\mat{X}) + \vec{e}$ são as medidas com ruído $\vec{e}$,
sendo que $\lVert \vec{e} \rVert_2 \le \epsilon$.

O ganho na representação de imagens se dá pelo fato de que não se cria uma representação esparsa da imagem
diretamente, mas sim do gradiente da imagem, o que torna a mesma mais suave e remove artefatos com alta
frequência.
A norma TV foi utilizada em diversos trabalhos.
Por exemplo, entre os primeiros resultados que motivaram o surgimento dessa área de estudo está
o trabalho proposto por \citet{CandesMRI}, no qual, possuindo aproximadamente $5\%$ das medidas de imagens de
ressonância magnética, foi possível recuperar toda a imagem, como é possível visualizar na figura 
abaixo.
\begin{figure}[H]
    \caption{Exemplo de recuperação de imagem de ressonância magnética utilizando a norma TV.
    (a) A imagem final correta desejada.
    (b) Amostragem que se possuía no domínio frequência.
    (c) Reconstrução via \textit{Filtered BackProjection}.
    (d) Reconstrução utilizando a norma TV.}
    \begin{center}
        \includegraphics[width=0.6\textwidth]{img/candesmri}
    \end{center}
    \legend{Fonte: \citet{CandesMRI}}
    \label{fig:l1ball}
\end{figure}

\subsection{Resultados com dicionários coerentes}
A partir dessa seção, ao se tratar das matrizes de amostragem, se utilizará 
o termo dicionários, que representam uma transformação do sinal, 
não necessariamente uma transformação de domínio conhecida,
podendo esta ser aprendida utilizando métodos que serão apresentados na seção \ref{sec:diclearn}.
A utilização de matrizes de amostragens incoerentes, ou dicionários incoerentes, 
limita a aplicação de ,
\emph{compressed sensing} para áreas cuja base de solução dos mesmos é baseada
em dicionários incoerentes.
Porém existem áreas com soluções baseadas em dicionários coerentes, que utilizam, 
por exemplo, dicionários supercompletos, com mais colunas que linhas. 
"Coerência é, de certa forma, uma propriedade natural para \emph{compressed sensing}, 
porque se duas colunas são muito correlatas, será impossível em geral distinguir se a energia do sinal
vem de uma ou da outra" 
\footnote{"Coherence is in some sense a natural property in the \emph{compressed sensing} quadrowork, for if two
columns are closely correlated, it will be impossible in general to distinguish whether the energy in 
the signal comes from one or the other"}
(\citeauthor{CANDESDICTS}, \citeyear{CANDESDICTS}, tradução livre).

Porém, em alguns casos, não precisa-se recuperar os coeficientes originais do sinal, o que com dicionários 
coerentes não é possível, mas sim o próprio sinal já transportado para uma nova base.
Matematicamente falando, imagine-se um sinal $\vec{f} = \mathbf{D}\vec{x}$, no qual suas medidas são
$\vec{y} = \mathbf{\Phi}\vec{f} = \mathbf{\Phi}\mathbf{D}\vec{x}$. 
Se o dicionário $\mathbf{D}$ for
coerente, não é possível recuperar os coeficientes $\vec{x}$, mas é possível recuperar $\vec{f}$ \cite{CANDESDICTS}.

A partir desses estudos, \citet{CANDESDICTS} apresentou uma nova definição para o problema de CS, 
baseado na solução utilizando a norma $\ell_1$, considerando $\vec{f} = \mathbf{D}\vec{x}$ o sinal
e $\vec{y} = \mathbf{\Phi}\vec{f} + \vec{e}$ as medidas, $\vec{e}$ o erro.
\begin{equation}
    \label{eq:problemDl1}
    \vec{f'} = \underset{\vec{g} \in \mathbb{C}^d}{\text{argmin}} \lVert \mathbf{D}^*\vec{g} \rVert_1, 
    \hspace{1em} \text{sujeito a} \hspace{1em}
    \lVert \mathbf{\Phi} \vec{g} - \vec{y} \rVert_2 \le \epsilon, 
\end{equation}
tal que $\lVert \vec{e} \rVert_2 \le \epsilon $.

\citet{CANDESDICTS} também redefiniu a RIP, chamando de D-RIP como segue. 
Dado um operador de amostragem $\mathbf{\Phi}$, ele satisfaz a D-RIP para um determinado 
dicionário $\mathbf{D}$ de ordem $s$ se:
\begin{equation}
    (1 - \delta_s)\lVert \mathbf{D}\vec{x} \rVert\SPSB{2}{2} \le \lVert \mathbf{\Phi} \mathbf{D}\vec{x} \rVert \SPSB{2}{2} \le 
    (1 + \delta_s)\lVert \mathbf{D}\vec{x} \rVert\SPSB{2}{2} \hspace{1em} \text{para todo vetor s-esparso,  } \vec{x}.
\end{equation}
e para algum $\delta_s$ de valor próximo a 0. %por exemplo $\delta_s \le 0,08$.
Tomando a nova definição, \citet{CANDESDICTS} provou o seguinte teorema sobre a recuperação do sinal.
\begin{teorema}
    \cite{CANDESDICTS}
    Dado $\mathbf{D}$ um dicionário e supondo um operador de amostragem $\mathbf{\Phi}$ que satisfaz
    a D-RIP de ordem $s$,
    a solução $\vec{f'}$ para a análise $\ell_1$ satisfaz
    \begin{equation*}
        \lVert \vec{f'} - \vec{f} \rVert_2 \le C_4 \left[ \epsilon + \frac{\lVert \mathbf{D}^* \vec{f} - \left( \mathbf{D}^* \vec{f} \right)_s \rVert_1}{\sqrt{s}} \right],
    \end{equation*}
    tal que $\left( \mathbf{D}^* \vec{f} \right)_s$ denota o vetor com os $s$ maiores coeficientes em 
    magnitude de $\mathbf{D}^* \vec{f}$ e $C_4$ é uma constante tal que $C_4 \ge 0$.
\end{teorema}

A abordagem baseada em dicionários coerentes abriu caminhos para novas análises e usos de CS para outros
problemas, além de tornar possível utilizar os modelos e técnicas de CS
para outros campos do conhecimento.

\section{Aprendizado de Dicionários}
\label{sec:diclearn}
A área de aprendizado de dicionários, do inglês \textit{dictionary learning}, busca, através
dos dados já conhecidos de uma classe de sinais, prover novos dicionários nos quais os sinais 
serão capazes de se conformar de maneira mais esparsa. 
Sob o ponto de vista de CS, um dicionário $\mat{D}$ normalmente é escolhido de forma aleatória,
desde que satisfaça a RIP.
Aprendizado de dicionários, por outro lado, busca gerar modelos considerando os sinais envolvidos,
ou seja, dicionários que dependem dos dados, ou \textit{data-dependent dictionaries} \cite{chen2015compressed}.

Nas seções seguintes será explicitado o problema geral de aprendizado de dicionários, bem como 
um algoritmo que é capaz de de gerar um dicionário a partir de dados observados.
%  e, por fim, uma aplicação focada em processamento de imagens.

\subsection{Problema Geral de Aprendizado de Dicionários}
Nessa seção será apresentado um modelo geral do problema que aprendizado de dicionários busca resolver.
De forma intuitiva, pode-se imaginar aprendizado de dicionários como se fosse desejado gerar 
um sub-dicionário da língua portuguesa a partir de uma grande quantidade textos.
% , livros, todos eles separados por palavras.

Mais formalmente, seja $\vec{x_1}, \vec{x_2}, ..., \vec{x_n} \in \mathbb{R}^L$
um conjunto finito de sinais de treinamento, e sejam $m$ e $s$ inteiros positivos.
Deseja-se encontrar a matriz $\mat{D}$ e os vetores s-esparsos
$\vec{\gamma_1}, \vec{\gamma_2}, ..., \vec{\gamma_n} \in \mathbb{R}^m$, tais que
$\mat{D}\vec{\gamma_i} \approx x_i$ para todo $i$. Dessa forma, pode-se definir o problema
de aprendizado de dicionários utilizando a norma $\ell_2$ como segue  \cite{chen2015compressed}:
\begin{equation}
    \label{eq:dlgeneral}
    \underset{\mat{D}, \vec{\gamma_1}...\vec{\gamma_n}}{min} 
    \sum_{i=1}^{n} {\lVert  \vec{x_i} - \mat{D} \vec{\gamma_i} \rVert \SPSB{2}{2}}
    \hspace{1em} \text{tal que} \hspace{1em}
    \lVert \vec{\gamma_i} \rVert_0 \le s, \text{ para todo } i.
\end{equation}

Nesse caso, $\mat{D} \in \mathbb{R}^{L\times m}$ é o dicionário aprendido, enquanto 
cada vetor $\vec{\gamma_i} \in \mathbb{R}^m$, com no máximo $s$ coeficientes não nulos, 
% , corresponde 
% à representação
% linear de $\vec{x_i}$ em $\mat{D}$,
% O valor de $m$ pode ser maior que o de $L$, talvez para explorar alguma redundância, mas 
e $s\ll L$. 
Neste caso, um sinal $\vec{x_i}$ contendo $L$ amostras é representado pela combinação linear de $s$ 
colunas do dicionário $\mat{D}$. 
Os coeficientes desta combinação linear são armazenados nos $s$ elementos não zero 
do vetor $\vec{\gamma_i}$.
Ainda, sobre o problema \eqref{eq:dlgeneral}, para que as escolhas
de $\vec{\gamma_i}$ e $\mat{D}$ sejam únicas, pode-se forçar que as colunas de $\mat{D}$ 
tenham norma $\ell_2$
unitária \cite{chen2015compressed}. O valor $m$ é conhecido como o número de átomos do 
dicionário.
É importante notar que a função de erro de \eqref{eq:dlgeneral} usa norma $\ell_2$, mas pode ser trocada
por outra função de erro, como, por exemplo, a norma $\ell_1$ \cite{chen2015compressed}.

Também é possível formular o problema com um dado erro de aproximação $\epsilon$.
Nesse caso, pode-se reformular o problema de aprendizado de dicionários como segue \cite{chen2015compressed}.
\begin{equation}
    \label{eq:dleps}
    \underset{\mat{D}, \vec{\gamma_1}...\vec{\gamma_n}}{min} 
    \sum_{i=1}^{n} {\lVert \vec{\gamma_i} \rVert_0}
    \hspace{1em} \text{tal que} \hspace{1em}
    \lVert \vec{x_i} - \mat{D}\vec{\gamma_i} \rVert_2 \le \epsilon, \text{ para todo } i.
\end{equation}

Unificando as duas formulações \eqref{eq:dlgeneral} e \eqref{eq:dleps}, chega-se ao seguinte
\cite{chen2015compressed}:
\begin{equation}
    \label{eq:dlunica}
    \underset{\mat{D}, \vec{\gamma_1}...\vec{\gamma_n}}{min} 
    \sum_{i=1}^{n} {\lVert \vec{x_i} - \mat{D}\vec{\gamma_i} \rVert\SPSB{2}{2} + \lambda \lVert \vec{\gamma_i} \rVert_0},
\end{equation}
no qual $\lambda$ é um parâmetro de balanceamento.
Porém, utilizando-se a norma $\ell_0$, o problema é usualmente NP-difícil. Dessa forma, pode-se gerar
uma reformulação somente trocando a norma $\ell_0$ pela norma $\ell_1$ \cite{chen2015compressed}:
\begin{equation}
    \label{eq:dlunical1}
    \underset{\mat{D}, \vec{\gamma_1}...\vec{\gamma_n}}{min} 
    \sum_{i=1}^{n} {\lVert \vec{x_i} - \mat{D}\vec{\gamma_i} \rVert\SPSB{2}{2} + \lambda \lVert \vec{\gamma_i} \rVert_1}
\end{equation}

Aprendizado de dicionários tem ligação com diversas outras áreas do conhecimento. 
Em especial
% e que será utilizado no decorrer do desenvolvimento do trabalho, está sua ligação
com CS, da forma que foi explicitada no início da seção, e com processamento de imagens,
o que será melhor abordados na seção \autoref{sec:codesparsa}.

\subsection{\textit{Online Dictionary Learning}}
\label{sec:odl}
Um dos principais algoritmos de aprendizado de dicionários, com aplicação em processamento de imagens, 
é o algoritmo \textit{Online Dictionary Learning (ODL)}. Um de seus principais diferenciais
se dá pela possibilidade de utilizar um conjunto de treinamento bastante volumoso, mantendo bom 
desempenho \cite{MairalOnlineDictLearn}.
Por isso, pode-se dizer que o ODL possui boa escalabilidade.

O ODL é um algoritmo \textit{online}, ou seja, a cada nova iteração $t$
é gerada uma nova versão do dicionário $\mat{D_{(t)}}$ a partir de uma nova amostra $\vec{x_{(t)}}$.

Entrando mais a fundo na definição geral do algoritmo, tomado um chute inicial $\mat{D_{(0)}}$, as próximas
iterações $t \ge 1$ serão baseadas em $\mat{D_{(t-1)}}$ e $\vec{x_{(t)}}$. O novo dicionário $\mat{D_{(t)}}$ será
gerado a partir de dois passos. Primeiramente, deve-se encontrar o vetor de coeficientes $\vec{\gamma_{(t)}}$
relativos a $\vec{x_{(t)}}$ e $\mat{D_{(t-1)}}$, resolvendo o problema de codificação esparsa a seguir \cite{chen2015compressed}:
\begin{equation}
    \vec{\gamma_{(t)}} = \underset{\vec{\gamma}}{argmin}
    \frac{1}{2} \lVert \vec{x_{(t)}} - \mat{D_{(t-1)}}\vec{\gamma} \rVert\SPSB{2}{2} +
    \lambda \lVert \vec{\gamma} \rVert_1,
\end{equation}
sendo que $\lambda$ é um parâmetro de configuração do algoritmo. Esse problema pode ser resolvido por algum dos 
algoritmos discutidos na \autoref{sec:csalgo}. 
Também é possível substituir a norma $\ell_1$ pela $\ell_0$,
de forma que algum algoritmo guloso de CS possa ser utilizado. O mesmo se dará para o passo seguinte.

No segundo passo do algoritmo, definimos o novo dicionário $\mat{D_{(t)}}$ através dos vetores de coeficientes
anteriores, $\vec{\gamma_{(1)}}, ..., \vec{\gamma_{(t-1)}}$, além de considerar o novo $\vec{\gamma_{(t)}}$.
Para facilitar, consideremos a matriz $\mat{X}$ com colunas $\vec{x_1},...,\vec{x_t}$ e a matriz $\mat{\Gamma}$
com colunas $\vec{\gamma_1},...,\vec{\gamma_t}$.
Dessa forma, e considerando que os valores de $\vec{\gamma_i}$ são fixos, pode-se 
formular o problema da seguinte forma \cite{chen2015compressed}:
\begin{equation}
    \label{eq:newdt}
    \mat{D_{(t)}} = \underset{\mat{D}}{argmin}
    \frac{1}{t} \sum_{i=1}^t \lVert \vec{x_i} - \mat{D}\vec{\gamma_i} \rVert\SPSB{2}{2}.
\end{equation}

A \autoref{eq:newdt} pode ser resolvida utilizando-se o método do 
gradiente descendente. Para isso, primeiramente precisamos definir 
as seguintes matrizes \cite{chen2015compressed}.
\begin{equation}
    \mat{A_{(t)}} = \sum_{i=1}^t \vec{\gamma_i}\vec{\gamma_i^T} \in \mathbb{R}^{m \times m},
    \hspace{0.5em}
    \mat{B_{(t)}} = \sum_{i=1}^t \vec{x_i}\vec{\gamma_i^T} \in \mathbb{R}^{L \times m}.
\end{equation}

Tomando como valor inicial $\mat{D} = \mat{D_{(t-1)}}$, 
e utilizando o seguinte cálculo recursivo em cada coluna $\vec{d_k}$, 
que sempre minimiza a função objetivo \cite{MairalOnlineDictLearn}, 
chega-se no novo dicionário $\mat{D_{(t)}}$,
iterando até que não se tenha mudança em $\mat{D}$.
\begin{equation}
    \vec{d_k} \leftarrow \frac{1}{\mat{A_{(t)_{k,k}}}}
    \left( \vec{B_{(t)_{:,k}}} - \mat{D}\vec{A_{(t)_{:,k}}} \right) +
    \vec{d_k}.
\end{equation}

Por fim, será descrito o algoritmo do ODL, conforme \citet{MairalOnlineDictLearn}.
\vspace{1em}

\begin{algorithm}[H]
    \label{algo:odl}
    \caption{\textit{Online Dictionary Learning (ODL)}.}
    \Entrada{Distribuição de probabilidade $p(\vec{x})$, para $\vec{x} \in \mathbb{R}^L$, 
    parâmetro $\lambda$, 
    dicionário inicial $\mat{D_{(0)}}$, número de iterações $T$.}
    \Saida{Dicionário final $\mat{D_{(t)}}$.}
    $\mat{A_{(0)}} \leftarrow \mat{0}$\;
    $\mat{B_{(0)}} \leftarrow \mat{0}$\;
    \For{$t = 1..T$}{
        Escolher nova amostra $\vec{x_{(t)}}$ de $p(\vec{x})$\;
        Resolver:
        $\vec{\gamma_{(t)}} = \underset{\vec{\gamma}}{argmin} \lVert \vec{x_{(t)}} - \mat{D_{(t-1)}}\vec{\gamma} \rVert_2^2 +
        \lambda \lVert \vec{\gamma} \rVert_1$\;
        $\mat{A_{(t)}} \leftarrow \mat{A_{(t-1)}} + \vec{\gamma_{(t)}} \vec{\gamma_{(t)}^T}$\;
        $\mat{B_{(t)}} \leftarrow \mat{B_{(t-1)}} + \vec{x_{(t)}} \vec{\gamma_{(t)}^T}$\;
        $\mat{D} \leftarrow \mat{D_{(t-1)}}$\;
        Realizar a atualização do dicionário $\mat{D}$ para todas as colunas $k$ até convergência:
        $\vec{d_k} \leftarrow \frac{1}{\mat{A_{(t)_{k,k}}}}
        \left( \vec{B_{(t)_{:,k}}} - \mat{D}\vec{A_{(t)_{:,k}}} \right) + \vec{d_k}$ \;
        \If{$\lVert \vec{d_k} \rVert_2 > 1$}{
            Normalizar $\vec{d_k}$\;
        }
        $\mat{D_{(t)}} \leftarrow \mat{D} $\;
    }
    \Return{$\mat{D_{(t)}}$}
\end{algorithm}
\vspace{1em}

\subsection{Codificação Esparsa}
\label{sec:codesparsa}
A partir das bases de \emph{compressed sensing} e de aprendizado de dicionários, pode-se 
buscar um outro objetivo, compressão de sinais.
No caso que será estudado, o foco será em codificação esparsa de imagens, buscando 
embasar os estudos para a proposta do trabalho em questão.

É necessário considerar que imagens não são usualmente esparsas no domínio tempo.
Porém, no domínio da transformada do cosseno, ou no domínio da DCT (\textit{Discrete Cosine Transform}), 
imagens são, em geral, compressíveis, vide \eqref{eq:compressiblesignal}, fato 
que permite, por exemplo, gerar representações da imagem com alta fidelidade, mesmo
utilizando baixa quantidade de informação.
% Preciso de referências aqui.

Por outro lado, pode-se imaginar que, para uma determinada classe de imagens,
por exemplo, imagens naturais, a utilização de um dicionário previamente treinado 
pode gerar bons resultados. Para remoção de ruído em imagens, \citet{EladDenoising} 
mostram que o uso de dicionários aprendidos têm resultados melhores que o uso de 
dicionários gerais, teóricos.

Considerando uma imagem $I$, separada em patches $p_i$ de tamanho $\sqrt{L}\times\sqrt{L}$, 
com ou sem sobreposição
\footnote{Normalmente, para problemas de remoção de ruído, é utilizada sobreposição,
enquanto para representação esparsa não é utilizada.}
e vetorizando cada patch $p_i$ em vetores
$\vec{x_i} \in \mathbb{R}^L$. 
Tomando um dicionário $\mat{D} \in \mathbb{R}^{L\times m}$, 
aprendido via patches de imagens correlatas a $I$, se desejarmos representar os patches 
$\vec{x_i}$ em relação a $\mat{D}$, podemos utilizar a seguinte formulação:
\begin{equation}
    \label{eq:patchcoding}
    \vec{\gamma_i} = \underset{\vec{\gamma}}{argmin} \lVert \vec{x_i} - \mat{D}\vec{\gamma} \rVert_2^2
    \hspace{1em} \text{sujeito a} \hspace{1em}
    \lVert \vec{\gamma} \rVert_0 \le s
    \text{ para todo } i,
\end{equation}
tal que $s$ é o número máximo de valores não nulos da representação $\vec{\gamma_i} \in \mathbb{R}^m$.
Nesse caso, pode-se utilizar algum dos algoritmos apresentados na
Seção \ref{sec:greedy}, por exemplo o OMP. 
Para que a representação seja esparsa, precisa-se garantir que $s \ll L$.
Por exemplo, tomando uma imagem $I$ e separando em patches de $8\times 8$, ou seja,
$L = 64$, poderia ser escolhido um valor de $s = 4$ ou $s=6$, independente do valor 
de $m$, garantido $s \le m$, cujo valor escolhido, por exemplo, poderia ser $m = 256$.

Existem diversas outras aplicações de aprendizado de dicionários no campo de processamento de
imagens, principalmente \cite{MairalSparse}:
\begin{itemize}
    \item \textit{Denoising}: remoção de ruído de imagens;
    \item \textit{Inpainting}: preenchimento de regiões não \textit{pintadas} de imagens;
    \item \textit{Demosaicking}: reconstrução da imagem a partir de sensores digitais;
    \item \textit{Up-scaling}: aumento da resolução de imagens.
\end{itemize}

Estas aplicações fogem ao escopo do trabalho apresentado e, portanto, não serão
aprofundadas nesse referencial, porém são amplamente desenvolvidas por diversos
autores da área.

% \section{Codificação de Imagens}
% Decidir se terá ou não


\chapter{Trabalhos Relacionados}
\label{cap:relacionados}
Neste capítulo serão abordados alguns trabalhos que se relacionam com a proposta apresentada.
O foco principal da proposta está na codificação esparsa de quadros de vídeos utilizando dicionários
previamente treinados, buscando executar o processo em tempo real.

Todos os trabalhos encontrados, bem como os padrões de vídeo existentes,
utilizam a técnida de separar os quadros em blocos, ou \textit{patches},
para que a aplicação das técnicas de transformação e compressão sejam 
mais eficientes.

\citet{BRYTFACEKSVD}, em seu trabalho, fizeram a compressão de imagens de faces, 
utilizando o algoritmo K-SVD para aprendizado de um dicionário. 
Cada imagem facial foi amostrada para as mesmas dimensões, com as faces centralizadas
em um mesmo ponto, de forma que, aproximadamente, cada componente da face localiza-se
em uma mesma posição.
Por fim, cada imagem foi dividia e patches de tamanho $15\times 15$ sem sobreposição.
Para cada posição de patch, foi treinado um dicionário
de 512 átomos. A partir dessas definições, \citet{BRYTFACEKSVD} chegaram a resultados 
com alta taxa de compressão, e ótimas qualidades de recuperação da imagem.
Os resultados alcançados pelos autores indicam a possibilidade de se utilizar essa
metodologia de forma menos restritiva, com, possivelmente, resultados menos impressionantes
tanto em qualidade quanto em compressão.

Alguns trabalhos utilizam as teorias de CS para enviarem amostragens dos blocos
dos vídeos por parte do \textit{encoder}, utilizando-se dos teoremas provados pela teoria.
\citet{NebotDVC} apresentou um trabalho exatamente nesse sentido.
Seguindo o mesmo caminho, e buscando aprimorar a técnica apresentada por \citeauthor{NebotDVC}, 
\citet{DoDISCOS} propõe uma mescla entre os métodos tradicionais de codificação de vídeos
e a utilização de CS, conseguindo bons resultados e abrindo horizontes nesse sentido.
Em ambos trabalhos, a etapa de CS deve ser executada por parte do \textit{decoder}, 
o que é bastante custoso do ponto de vista de vídeos de maior resolução.

\citet{ZhangVideoCS} propõe um método que também mescla os métodos existentes
com a ideia de enviar amostragens. 
No trabalho proposto, apresenta uma forma de definir como cada bloco será codificado,
se utilizando amostragem ou DCT.
Os blocos que utlizam amostragem executam o processo de minimização da norma TV, 
enquanto os demais blocos aplicam a DCT inversa, por parte do \textit{decoder}.
A técnica foi incorporada a codificação H.264, chegando a ganhos significativos na
codificação \cite{ZhangVideoCS}.

Além destes trabalhos, o uso de CS para aprimorar vídeos de baixa qualidade foi 
apresentado por \citet{WirelessXiangCai}, com foco em distribuição de vídeos para
redes Wireless.
O uso de CS, nesse caso, se dá com o intuito de, além de melhorar os vídeos de baixa
qualidade e \textit{bitrate}, fornecer um canal capaz de lidar com ruído, 
tal qual a teoria de CS prevê.

Todos os trabalhos citados anteriormente utilizam como dicionário a DCT.
No sentido de utilizar técnicas de aprendizado de dicionários, 
\citet{chen2010dictionary} apresenta uma proposta baseada na de \citet{ZhangVideoCS},
porém, por parte do \textit{decoder}, ao invés de utilizar algum dicionário conhecido,
utilizar um aprendido.

% Ler o Lima e falar sobre com mais intensidade... OK
\citet{lima2012codificaccao} apresenta em seu trabalho um codec de vídeo bastante 
próximo ao proposto.
Em sua proposta, o autor utiliza o algoritmo K-SVD para treinamento de um dicionário
de 256 átomos, seguindo a proposta de \citeauthor{BRYTFACEKSVD}, conforme descrito
anteriomente.
Para a decomposição, também utiliza o algoritmo OMP, utilizando blocos $8\times8$,
sem sobreposição.
As principais diferenças entre o trabalho descrito e o proposto
estão no uso do ODL como algoritmo de treinamento de dicionários, 
além da forma como são processados os blocos.
No trabalho descrito, \citeauthor{lima2012codificaccao} utiliza a diferença entre o
bloco anterior e o atual ou somente o atual, dado um limite. 
No trabalho proposto, sempre será utilizado o bloco atual.
Porém, quando a diferença não for significativa, não recalculará a representação do bloco.
% A escolha se dá pelo fato de que o dicionário base foi treinado para os blocos 
% não residuais, e que, portanto, espera-se que a representação tenha melhores resultados 
% para estes.

No próximo capítulo será detalhada a proposta do trabalho, explicitando detalhes
da implementação.
Em seguida, testes e resultados serão apresentados com base na proposta.

\chapter{Aplicação de técnicas de compressed sensing e aprendizado de dicionários para codificação de vídeos em tempo real}
\label{cap:proposta}
Após considerar o desenvolvimento da área de CS e de aprendizado de dicionários e 
resumidos alguns trabalhos que focaram em alguma dessas áreas, será descrita a proposta 
do trabalho de forma detalhada.

O trabalho proposto visa desenvolver uma metodologia para codificação de vídeos em
tempo real, utilizando dicionários pré-aprendidos relacionados ao próprio vídeo.
Por ser um \textit{quadrowork} com foco em tempo real, transmissão e recepção, 
naturalmente se põe em questão 
a necessidade de definir as funções que serão desenvolvidas por parte do \textit{encoder}
e por parte do \textit{decoder}.

% A proposta foca na codificação de quadros a partir de dicionários previamente treinados,
% apresentando um novo olha sobre a transformação aplicada aos quadros.
% As técnicas apresentadas de forma resumida na seção \autoref{sec:codvideo} podem ser 
% aplicadas juntamente a metodologia apresentada.

A imagem a seguir apresenta um diagrama geral de blocos, dividido entre \textit{encoder}
e \textit{decoder}, além de representar blocos funcionais de cada uma das partes de 
forma geral.
\begin{figure}[H]
    \caption{Diagrama geral da solução proposta.}
    \begin{center}
        \includegraphics[width=0.9\textwidth]{img/DiagramaFinal.png}
    \end{center}
    \legend{Fonte: O Autor.}
    \label{fig:geral}
\end{figure}

Entende-se que os quadros processados estarão no formato de imagem colorida,
pixel a pixel, RGB (Red, Green, Blue). 
Ou seja, os quadros terão dimensão 
$m \times n \times 3$,
sendo a resolução do vídeo $m \times n$. 
No caso do sistema criado, a ordem dos pixels é 
linha a linha, ou seja, primeiro a linha $0$ e todas suas colunas, depois a $1$, e assim por diante.
Em contraste com essa definição o quadro em memória poderia ser coluna por coluna, o que alteraria
alguns cálculos internos, sendo possível adaptar o sistema desenvolvido de forma bastante simples.
Essa é uma diferença para com os codecs conhecidos, que utilizam comumente o espaço de cor YCbCr
para processamento.
O codec proposto não necessita fazer tal transformação, pois a transformação executada pelas 
técnicas de aprendizado de dicionários absorve a transformação no espaço de cor.
Em seguida são definidas as nomenclaturas de alguns parâmetros importantes da abordagem proposta.

\section{Parâmetros do sistema}
Os parâmetros modificáveis do sistema proposto podem ser vistos na \autoref{tbl:params}. 
As escolhas e resultados obtidos com a alteração dos parâmetros serão discutidas no 
Capítulo \ref{sec:results}.

\begin{table}[h]
    \caption{Parâmetros do sistema.}
    \centering
        \begin{tabular}{|c|p{10cm}|}
          \hline
          \multicolumn{1}{|c|}{\textit{Parâmetro}} & 
            \multicolumn{1}{c|}{\textit{Descrição}}\\
          \hline
          \hline
          $p$    & Tamanho do patch. \\ 
          $K$    & Número de átomos do dicionário, também descrito como "tamanho" do dicionário. \\
          $s$    & Valor máximo da norma $\ell_0$ de cada patch. Quantidade de valores não nulos da representação do patch. \\     
          $q$    & Parâmetro de esparsidade de envio da informação, $q \le s$. \\
          \hline
        \end{tabular}
    \legend{Fonte: O Autor.}
    \label{tbl:params}
\end{table}

Nas seções seguintes serão descritas mais a fundo cada uma das etapas, seguindo a ordem
apresentada na \autoref{fig:geral}, além de explicitar a ligação entre cada um dos blocos funcionais
do projeto.

\section{Aprendizado de dicionário}
\label{sec:learn}
A etapa de aprendizado do dicionário, a qual é realizada off-line, é essencial para que a qualidade da representação
esparsa utilizada seja boa.
Além disso, para o caso de treinamento a partir de quadros de vídeos, caso em que se está
trabalhando, é também necessário fazer a escolha de um algoritmo que permita a utilização
de uma grande quantidade de dados de treinamento.

Considerando esses aspectos e o desempenho apresentado por \citet{MairalOnlineDictLearn}, foi escolhido
como algoritmo de treinamento do dicionário o \textit{Online Dictionary Learning} \cite{MairalOnlineDictLearn},
descrito na \autoref{sec:odl}.
Este algoritmo apresenta bom resultado para grande número de sinais de treinamento.

O treinamento foi executado da seguinte forma:
\begin{enumerate}
    \item Os vídeos foram separados em diversas classes. Por exemplo, vídeos naturais, vídeos
    de esportes, \textit{cartoon}, etc.;
    \item Os quadros foram sorteados, de forma a garantir que um comportamento dos últimos quadros
    não prepondere sobre todo o dicionário;
    \item Cada quadro foi separado em patches com tamanho $p \times p$;
    Para o treinamento, foram utilizados patches com sobreposição. Por fim, todos os patches
    foram vetorizados como descritos na \autoref{sec:quadroaquisition};
    \item O dicionário foi obtido executando o algoritmo ODL (Algoritmo \ref{algo:odl}).
\end{enumerate}

Vale ressaltar que, para vídeos muito especializados, pode-se utilizar um treinamento
mais especializado. 
Por exemplo, uma transmissão esportiva, de um esporte específico pode se beneficiar 
de um dicionário obtido a partir de apenas quadros desse determinado esporte.

A fase de aprendizado do dicionário, por envolver um tempo maior de processamento,
deve ser executada antes da transmissão em tempo real, por parte do \textit{encoder}.
Isso é possível, mesmo que não
se conheça a transmissão em si, mas se conheça que tipo de conteúdo será transmitido.

Um importante parâmetro que deve ser escolhido é o número de átomos (i.e., colunas do dicionário) $K$ do dicionário.
Escolhas de valores maiores tendem a proporcionar maior qualidade na representação do vídeo,
porém com perda de desempenho. No Capítulo \ref{sec:results} serão mostrados resultados
de escolhas diferentes no número de átomos do dicionário.

Como parametrização do ODL, utiliza-se o valor $s$ como esparsidade desejada e
$K$ como número de átomos do dicionário.
O algoritmo ainda precisa saber o número de amostras que devem ser selecionadas aleatoriamente
de cada quadro.
Para determinar isso, foram executados testes de qualidade com diversos valores
(\autoref{sec:parametrizacao}).
Foi utilizada a implementação da biblioteca SPAMS \cite{SPAMS} do algoritmo ODL.

O resultado final desse etapa será um dicionário $\mat{D} \in \mathbb{R}^{3p^2 \times K}$,
que será utilizado nas etapas seguintes de codificação e decodificação.
Assim, portanto, em caso de uma transmissão de tempo real ou até mesmo se o vídeo for salvo em arquivo,
uma das primeiras informações que deve ser enviada é o dicionário que servirá de base
para a transmissão.


% \section{\textit{Encoder}}
\section{Aquisição do quadro}
\label{sec:quadroaquisition}
Essa etapa tem como entrada o quadro a ser codificado, sendo que o histórico de quadros já
processados, para a posterior verificação de igualdade, está armazenado também neste
subsistema.

Já nesse ponto do processamento é necessário ter em vista o tamanho dos patches $p\times p$
que será utilizado. A escolha deve seguir o parâmetro definido na escolha do dicionário.
Valores típicos a serem escolhidos são $p=4$ ou $p=8$. Na seção \ref{sec:parametrizacao} serão 
discutidos resultados alcançados com ambas escolhas de tamanho de patch.

A escolha por processar patches se dá pela necessidade do processamento em tempo real, pois 
os algoritmos relacionados a CS dependem diretamente do tamanho
dos sinais envolvidos, do tamanho dos dicionários e do número de valores não nulos.
Porém, o tamanho dos dicionários e o número de valores não nulos precisam ser maiores quanto maior for 
o sinal, o que leva a um aumento de complexidade maior que linear com o aumento do tamanho dos
patches, além de uma utilização maior de memória para o dicionário.
Utilizar patches pequenos possibilita a paralelização dos cálculos.
No caso do trabalho que está sendo apresentado, em que o processamento dos patches, que será 
comentado na próxima seção, se dá utilizando a GPU, a utilização de maior 
paralelismo tende a aumentar a velocidade de processamento.
Resultados nesse sentido serão discutidos na \autoref{sec:parametrizacao}.
Como já comentado na \autoref{sec:learn}, existe também um \textit{trade-off} entre 
diminuir o tamanho do patch e aumentar a compressão.

Tomada a imagem RGB $\mat{I}$ de dimensões $m \times n \times 3$, ela será separada em patches
$p \times p \times 3$, sem sobreposição. Por exemplo, um dos patches iniciará em $\mat{I_{0,0}}$
e terá parte em $p$ linhas e $p$ colunas, indo a $\mat{I_{p-1, p-1}}$. Em seguida, o próximo
patch iniciará em $\mat{I_{0, p}}$ e terminará em $\mat{I_{p-1, 2p-1}}$.
Nos finais de linha e de coluna, os valores de $m$ e $n$ podem não ser divisíveis por $p$,
o que gera um resíduo. 
Nesse caso, foi adotada a solução que o padrão JPEG utiliza de repetir
o último pixel a esquerda para as colunas e o pixel acima para as linhas, até que chegue-se
a um patch $p \times p$ \cite{mitchell1992digital}.
Junto ao processo de tomada dos patches, estes são vetorizados, também no formato 
linha a linha, para cada pixel RGB.
Para um patch $\mat{P}$, os três primeiros valores do vetor corresponderão ao RGB de
$\mat{P_{0,0}}$. 
Os próximos três a $\mat{P_{0,1}}$, e assim por diante.
Como resultado final, pode-se dizer que a imagem $\mat{I}$ foi separada em 
\begin{equation*}
    T = \ceil*{\frac{m}{p}} \ceil*{\frac{n}{p}}
\end{equation*}
vetores de dimensão $L = 3p^2$. Pode-se escrever esses vetores como uma matriz 
$\mat{X}\in \mathbb{R}^{L\times T}$, 
na qual cada coluna $\vec{x_i}$ da matriz representa um dos patches vetorizados. 
A \autoref{fig:vectorize} ilustra o processo de vetorização de um patch.
\begin{figure}[H]
    \caption{Funcionamento da vetorização do patch.}
    \begin{center}
        \includegraphics[width=0.6\textwidth]{img/vectorize}
    \end{center}
    \legend{Fonte: O Autor.}
    \label{fig:vectorize}
\end{figure}


Além do processo de vetorização, este subsistema também verifica se o patch atual $i$ é 
igual ao patch $i$ correspondente no quadro anterior. 
Caso seja, marca um vetor de booleanos $\vec{c}\in \mathbb{B}^T$, que indica os 
patches que precisam ou não ser recalculados.
A métrica considera que um patch deve ser recalculado caso qualquer um dos valores dos 
pixels inseridos nele mudem.
Esse simples cálculo sobre os patches garante que, para vídeos estáticos, o desempenho
da aplicação seja acelerado.
Parte considerável dos vídeos possuem partes com essas características, e esse cálculo simples
não aumenta significativamente a complexidade do sistema como um todo.

\section{Codificação esparsa dos patches}
A partir dos patches $\mat{X}$ da etapa anterior, do dicionário $\mat{D}$, e do parâmetro 
de esparsidade desejada $s$, pode-se formular o problema de codificação esparsa, tal que 
$\vec{\gamma_i}$ seja a representação esparsa de $\vec{x_i}$, como segue:
\begin{equation}
    \vec{\gamma_i} = \underset{\vec{\gamma}}{argmin} \lVert \vec{x_i} - \mat{D}\vec{\gamma} \rVert_2^2
    \hspace{1em} \text{sujeito a} \hspace{1em}
    \lVert \vec{\gamma} \rVert_0 \le s,
    \text{ para todo } i.
\end{equation}

O problema acima, como mencionado anteriormente, pode ser resolvido via OMP.
A implementação básica escolhida para o sistema foi baseada na biblioteca SPAMS \cite{SPAMS}.
A partir dela, foi desenvolvida uma versão em CUDA\reg, focada em paralelizar o algoritmo
OMP para cada $(\vec{x_i}, \vec{\gamma_i})$. Assim, foi possível obter uma representação
em tempo real, conforme será verificado no Capítulo \ref{sec:results}.

Um importante fato a ser considerado sobre o Algoritmo \ref{algo:omp} (Subseção \ref{sec:greedy}) 
é que, a cada iteração $i$,
ele descobre a melhor solução para o parâmetro de esparsidade $i$. Ou seja, se escolhido $s=5$,
por exemplo, é possível armazenar-se os resultados com parâmetro de esparsidade $s=1,...,5$. 
A utilidade desse fato se dá no controle da taxa de transmissão, pois quanto mais esparsa a 
representação, menor o bitrate. 
Portanto, com a aplicação do OMP, é possível gerar as melhores e piores representações.
Imaginando múltiplas transmissões a partir do mesmo \textit{encoder}, cada uma poderia ter 
uma taxa diferente sem a necessidade de mais cálculos nessa etapa.
% Como resultado final desse subsistema teremos, para cada patch $i$, uma matriz de representação
% $\mat{\Gamma_i} \in \mathbb{R}^{K \times s}$, sendo que cada coluna $(\mat{\Gamma_i})_j$ é 
% j-esparsa.
Assim, montamos para cada patch $i$ uma matriz de representação $\mat{\Gamma_i} \in R^{K \times s}$
que armazena as várias representações esparsas para o patch $i$. Cada coluna $(\mat{\Gamma_i})_j$ é 
j-esparsa, onde j corresponde aos valores de s de 1 a $s_max$ (no exemplo anterior $s_max = 5$). 
$K$ corresponde ao número de átomos de $\vec{\gamma_i}$, 
i.e., o número de elementos do vetor $\vec{\gamma_i}$. 

\section{Quantização e compressão}
A partir da codificação esparsa apresentada na seção anterior, a ideia dessa seção é 
fazer com que a codificação seja a mais comprimida possível, sem perdas sensíveis
na representação do sinal.
Além disso, ao final dessa seção, é necessário que haja uma representação em formato de 
\textit{stream} de bytes, para ser enviada ou armazenada pelo \textit{encoder}.

Primeiramente, o sinal é quantizado uniformemente em 8 bits. 
Para isso, é necessário identificar-se os coeficientes máximo $u$ e mínimo $l$ em $\mat{\Gamma}$.
Em seguida, cada coeficiente $c$ de $\mat{\Gamma}$ é quantizado de acordo com a seguinte equação:
\begin{equation*}
    c' = \floor*{0,5 + 255\frac{c - l}{u - l}}.
\end{equation*}

Um dos parâmetros que entra em ação é o parâmetro de esparsidade de envio da informação, $q$. 
Ele é o responsável pela escolha de qual será o nível de esparsidade escolhido,
dado que $1 \le q \le s$.
A partir desse parâmetro escolhe-se a coluna $q$ de cada $\mat{\Gamma_i}$ (já quantizada), 
formando $\mat{C} \in \mathbb{N}^{2q \times T}$.
Para representação de $\mat{C}$ são utilizadas as matrizes $\mat{V} \in \mathbb{N}^{q \times T}$ e
$\mat{R} \in \mathbb{N}^{q \times T}$, sendo que $\mat{V}$ representa os coeficientes não nulos de
$\mat{C}$ e $\mat{R}$ representa os índices dos mesmos:
\begin{equation*}
    \mat{C} = 
    \begin{bmatrix}
        \mat{V} \\
        \mat{R}
    \end{bmatrix}.
\end{equation*}

Para geração do \textit{bitstream}, são criados vetores a partir de $\mat{V}$ e $\mat{R}$.
% Uma consideração importante é que nem sempre os $q$ índices de um patch estarão completos.
% Nesse caso foi inserido um valor inválido no vetor de índices, enquanto o vetor de coeficientes
% mantém os valores.
O exemplo a seguir ilustra uma situação para a qual $q = 3$ e o número de átomos em 
$\vec{\gamma_i}$ é $K = 16$. 
$K$ limita o maior valor que os índice da matriz $\mat{R}$ podem assumir. 
\begin{equation*}
    \mat{V} = 
    \begin{bmatrix}
        189 & 36 & 114 \\
        45  & 0 & 32  \\
        8   & 0 & 0
    \end{bmatrix},
    \mat{R} = 
    \begin{bmatrix}
        7 & 12 & 15 \\
        1  & 0 & 3  \\
        5   & 0 & 0
    \end{bmatrix}
\end{equation*}
tal que as entradas com valor $0$ correspondem a entradas que não foram necessárias 
(i.e., a representação esparsa do patch correspondente à respectiva coluna das matrizes 
contém menos que $q$ coeficientes não nulos),
e cada coluna representa um patch $\vec{\gamma_i}$.
A matriz $\mat{V}$ está organizada de modo que o coeficiente de maior magnitude
esteja sempre nas linhas de menor índice. 
Assim, para uma coluna $j$, se na linha $i$ for encontrado um valor $0$ (i.e., coeficiente não necessário),
significa que as demais linhas da coluna também serão $0$.
Logo, ao encontrar um valor $0$ numa coluna, apenas este precisa ser inserido no vetor $\vec{r}$, 
pois se sabe que o próximo índice já será relativo a próxima coluna.  
Dessa forma, os vetores $\vec{v}$ e $\vec{r}$ serão os seguintes: 
\begin{center}
    $\vec{v} = \left[ 189, 45, 8, 36, 114, 32 \right]$, \\
    $\vec{r} = \left[ 7,1,5,12,0,15,3,0 \right]$.
\end{center}

Ainda em tempo, considerando que alguns dos patches não foram recalculados, estes 
também não precisam ser reenviados. 
Para marcar em que ponto isso acontece foi utilizado o valor $254$ em $\vec{r}$, 
seguido do número de patches não enviados.

Esses vetores, mais a informação de máximo, mínimo e $q$ precisam ser empacotados 
e comprimidos para enviar ao decoder.
A compressão utilizada foi baseada em codificação de Huffman, e foi utilizada 
a biblioteca \textit{Boost Gzip} \cite{Boost} para tal. 
O Apêndice A descreve o processo de codificação de Huffman.

% \section{\textit{Decoder}}

\section{Descompressão e dequantização}
\label{sec:decdeq}

A primeira etapa do processo de decodificação consiste na descompressão dos dados recebidos. 
É executada a decodificação de Huffman, 
baseando-se na tabela de compressão gerada para recuperar os valores originais.
A biblioteca \textit{Boost Gzip} \cite{Boost} foi utilizada novamente com esse objetivo.
A partir do sinal descomprimido deve-se recuperar as matrizes $\mat{V}$ e $\mat{R}$
tomando os vetores $\vec{v}$ e $\vec{r}$ recebidos.
Em seguida é necessário recompor os coeficientes quantizados 
executando a operação inversa a de quantização.
Considerando $c'$ cada coeficiente recebido, $u$ o maior valor e $l$ o menor, 
valores todos recebidos no \textit{bitstream},
\begin{equation*}
    c = \frac{c' (u - l)}{255} + l.
\end{equation*}

Por fim, é inicializada com zeros uma matriz $\mat{\Gamma} \in \mathbb{R}^{K \times T}$.
% Em seguida, associa-se $\mat{\Gamma_{\mat{R_{:,i}}, i}} = \mat{V_{:,i}}$ para todo $0 \le i < T$.
Em seguida, associa-se a cada índice $R_{i,j}$ de $\mat{\Gamma}$ o coeficiente
$V_{i,j}$ correspondente, para todo $1 \le i \le T$ e $1 \le j \le q$.
Vale lembrar que alguns dos patches podem não ter sido recebidos. 
Essa informação deve ser passada adiante para que somente os patches modificados
sejam reprocessados.
Terminada essa etapa procede-se com a recuperação dos patches.

\section{Recuperação dos patches}
A recuperação dos patches por parte do \textit{decoder} é um processo muito simples,
pois incorre somente em uma multiplicação entre o dicionário $\mat{D}$ e a 
representação esparsa recebida $\mat{\Gamma}$.
Assim, pode-se definir que a matriz de patches $\mat{X} = \mat{D} \mat{\Gamma}$.
Uma simplificação que pode aumentar a velocidade da decodificação é não criar a matriz $\mat{\Gamma}$,
ou seja, utilizar as informações de $\mat{V}$ e $\mat{R}$ para formar $\mat{X}$. 
Esse procedimento tende a ser mais eficiente, pois quando formada a matriz $\mat{\Gamma}$, 
a maior parte dos coeficientes dessa matriz é nulo, por se tratar de uma representação esparsa.
% Porém, aplicando uma multiplicação da forma natural, esse fato é desconsiderado e acabam
% acontecendo mais operações de multiplicação do que o necessário.

\section{Reconstrução do quadro}
A reconstrução do quadro se dá exatamente da forma contrária a separação por patches.
Vale notar que alguns dos patches não precisarão ser atualizados
(i. e., não se modificaram de um quadro para outro).
Essa informação foi recebida pelo \textit{decoder} na \autoref{sec:decdeq} e repassada
até essa etapa.

Assim, cada um dos patches de $\mat{X}$, que estavam vetorizados, são novamente transformados
em matrizes de dimensão $p \times p \times 3$, e colocados em sua devida posição, formando
a imagem recebida $\mat{I}$ de dimensões $m \times n$.

\section{Implementação}
A implementação do codec se deu utilizando a linguagem de programação Python para a etapa 
de aprendizado de dicionários, e, como já citado, a biblioteca SPAMS \cite{SPAMS}.
Para o \emph{encoder} e \emph{decoder} foi escolhida a linguagem C++. 
O carregamento de vídeos utilizou a biblioteca OpenCV \cite{OpenCV}.
Já para o processamento das matrizes na memória da CPU, a biblioteca 
Eigen \cite{Eigen} foi a selecionada.

O programa para testes executa os processos de codificação e decodificação, realizando 
métricas de tempo e qualidade para ambas etapas.
Além disso, a parte de codificação salva um arquivo comprimido com o resultado da mesma.
Um programa que somente desempacota os dados e decodifica também foi desenvolvido.

Além disso, foram criados alguns subprogramas com o intuito de facilitar os testes e 
execuções, bem como analisar outras possibilidades, e executar métricas em paralelo ao 
desenvolvimento do codec.

\chapter{Resultados}
\label{sec:results}
% Durante a implementação da proposta, surgiram alguns parâmetros gerais da implementação
% que poderiam ser modificados, vide tabela \ref{tbl:params}. 
% Nas próximas seções serão discutidos os parâmetros e resultados alcançados com as 
% alterações dos mesmos.
De modo a avaliar o desempenho da abordagem proposta, foram realizados experimentos 
com vídeos utilizados na literatura para testes,
disponíveis em \url{https://media.xiph.org/video/derf/}.
% Criar citação
Os vídeos estão em formato de sequência de quadros, sem compressão, ou somente com 
compressão sem perdas.
Alguns dos vídeos disponíveis foram escolhidos.
Estes foram classificados nos seguintes grupos: \textit{cartoon}, 
monitoramento, esportes, \textit{indoor} e natureza, de forma que fosse possível 
verificar se existe alguma diferença no uso da técnica para diferentes classes de vídeos.
A tabela a seguir ilustra as escolhas.
Os vídeos em negrito foram os escolhidos para a validação, enquanto os demais para treinamento.

\begin{table}[h]
    \caption{Vídeos utilizados para treinamento e validação (mostrados em negrito).}
    \centering
        \begin{tabular}{|c|l|c|c|}
          \hline
          \multicolumn{1}{|c}{\textit{Categoria}} & 
          \multicolumn{1}{|c}{\textit{Vídeo}} & 
          \multicolumn{1}{|c}{\textit{Resolução}} & 
          \multicolumn{1}{|c|}{\textit{Nº de quadros}}  \\
          \hline
          \hline
          \multirow{3}{*}{Cartoon} 
          & \textbf{sintel\_trailer} & $1024\times436$ & $ 1.253 $ \\ 
          & big\_buck\_bunny & 720p & $ 14.315 $ \\
          & elephants\_dream & $1024\times436$ & $ 15.691 $ \\
          \hline
          \multirow{3}{*}{Esportes} 
          & \textbf{football} & NTSC & $360$ \\
          & stefan & SIF & $300$ \\ 
          & tennis & SIF & $150$ \\
          \hline
          \multirow{6}{*}{Indoor} 
          & \textbf{johnny} & 720p & $600$ \\ 
          & carphone & QCIF & $382$ \\
          & deadline & CIF & $1.374$ \\
          & foreman & CIF & $300$ \\
          & hall\_monitor & CIF & $300$ \\
          & mother\_daughter & QCIF & $961$ \\
          \hline
          \multirow{4}{*}{Monitoramento} 
          & \textbf{stockholm} & 720p & $604$ \\ 
          & bridge\_close & CIF & $2.001$ \\
          & bridge\_far & CIF & $2.101$ \\
          & station & 1080p & $313$ \\
          \hline 
          \multirow{6}{*}{Natureza} 
          & \textbf{park\_joy} & 720p & $500$ \\
          & ducks\_take\_off & 720p & $500$ \\
          & garden & SIF & $115$ \\
          & in\_to\_tree & 720p & $500$ \\
          & park\_run & 720p & $504$ \\
          & waterfall & CIF & $260$ \\
          \hline
        \end{tabular}
    \legend{Fonte: O Autor.}
    \label{tbl:vidtrain}
\end{table}

A máquina utilizada para treinamento e testes possui um processador Intel i5 2.5 GHz e 4 cores físicos,
e 8Gb de memória RAM.
Além disso, a placa de vídeo é Nvidia Geforce GTX 1050Ti, com 4Gb de memória.

Para ilustrar os vídeos utilizados na avaliação de resultados, a figura abaixo apresenta uma imagem de 
cada vídeo, para que se possa perceber as peculiaridades inerentes a cada um dos vídeos escolhidos.
\begin{figure}[H]
    \caption{Imagens dos vídeos escolhidos para os testes.
    (a) sintel\_trailer.
    (b) football.
    (c) johnny.
    (d) stockholm.
    (e) park\_joy.}
    \begin{center}
        \begin{tabular}{r c r c}
            \vspace{0.5em}
            (a) & \raisebox{-.5\height}{\includegraphics[width=0.4\textwidth]{img/sintel.png}} & \hspace{0.5em} 
            (b) & \raisebox{-.5\height}{\includegraphics[width=0.4\textwidth]{img/football.png}} \\
            \vspace{0.5em} 
            (c) & \raisebox{-.5\height}{\includegraphics[width=0.4\textwidth]{img/johnny.png}} & \hspace{0.5em} 
            (d) & \raisebox{-.5\height}{\includegraphics[width=0.4\textwidth]{img/stockholm.png}} \\
        \end{tabular}
        \begin{tabular}{r c}
            (e) & \raisebox{-.5\height}{\includegraphics[width=0.4\textwidth]{img/parkjoy.png}} \\
        \end{tabular}
    \end{center}
    \legend{Fonte: O Autor.}
\end{figure}

Em seguida serão discutidos o treinamento e os testes realizados com os vídeos.

\section{Treinamento}
Foi gerado um dicionário para cada classe de vídeos, e para cada variação em $K$ (tamanho do dicionário) e 
$p$ (tamanho do patch),
utilizando o algoritmo ODL, da forma que foi descrito na proposta do trabalho.

Para o treinamento foram utilizados os vídeos de cada classe, com exceção daquele
que foi escolhido para teste.
De cada um dos conjuntos de vídeos foram amostrados quadros a cada $t$ segundos, variando
o valor de $t$ para providenciar pelo menos $10$ e no máximo $100$ quadros para o processo 
de treinamento, por classe de vídeos.
A ordem de processamento dos quadros foi aleatória, para evitar viés para os últimos quadros. 
Cada quadro foi então transformado em sequência de patches, com sobreposição.
Essa sequência foi introduzida no algoritmo ODL, que tomou no máximo $2.500$ amostras por sequência
para fazer o treinamento do dicionário.
% Como dicionários iniciais foram utilizados valores randômicos com distribuição normal de 
% média aproximadamente $0$.

A tabela a seguir apresenta os parâmetros de cada dicionário criado para os testes subsequentes.
Cada parametrização foi aplicada a todas as classes de vídeos.
É importante recordar que o parâmetro $p$ trata do tamanho do patch $p \times p \times 3$, 
enquanto $K$ representa o número de átomos do dicionário.
\begin{table}[h]
    \caption{Parâmetros tamanho do patch $p$ e tamanho do dicionário $K$ utilizados para treinamento e validação.}
    \centering
        \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|}
          \hline
          \emph{Tamanho do patch} & $4$ & $4$ & $4$ & $4$ & $4$ & $8$ & $8$ & $8$ & $8$ \\
          \hline
          \emph{Tamanho do dicionário} & $16$ & $24$ & $32$ & $48$ & $64$ & $32$ & $64$ & $128$ & $192$ \\ 
          \hline
        \end{tabular}
    \legend{Fonte: O Autor.}
    \label{tbl:testparams}
\end{table}

Os parâmetros para teste foram escolhidos com base na implementação, também considerando 
o padrão H.264, que utiliza, na etapa de transformação, patches de $4\times4$, 
e o padrão JPEG, cujos patches são $8\times8$ \cite{mitchell1992digital}.
O valor de $s$, parâmetro de esparsidade (\autoref{tbl:params}), foi fixo para os valores de $p$. 
Sendo assim, para $p=4$, $s=4$, e para $p=8$, $s=8$.

A \autoref{fig:diccp8d192} mostra um dicionário aprendido para a classe cartoon com patches $8\times8$. 
Isto resulta em um dicionário contendo $192$ linhas ($8\times8\times3$). 
Neste exemplo, o dicionário também contém $192$ colunas. 
Cada quadrado mostrado contém $8\times8$ pixels, sendo cada pixel exibindo um valore RGB.
O conteúdo de cada um dos quadrados corresponde a uma coluna, com os valores associados às $192$ linhas. 

A \autoref{fig:dicip4d32} mostra um outro exemplo de dicionário aprendido para a classe indoors com patches de $4\times4$. 
Neste exemplo, o dicionário contém 48 linhas ($4\times4\times3$) e 
$32$ colunas (número de quadrados mostrados na figura).

% INSERIR IMAGEM DE DICIONÁRIO, CITANDO K e p
\begin{figure}[H]
    \caption{Exemplo de dicionário aprendido para a classe cartoon com patches $8\times8$. 
    Isto resulta em um dicionário contendo $192$ linhas ($8\times8\times3$). 
    Este dicionário contém $192$ colunas. 
    Cada quadrado mostrado contém $8\times8$ pixels, 
    cada um exibindo um valore RGB.
    O conteúdo de cada um dos quadrados corresponde a uma coluna, com os valores 
    associados às $192$ linhas.}
    \begin{center}
           \includegraphics[width=0.8\textwidth]{img/cartoon_p8_d192.png}
    \end{center}
    \legend{Fonte: O Autor.}
    \label{fig:diccp8d192}
\end{figure}

\begin{figure}[H]
    \caption{Exemplo de dicionário aprendido para a classe cartoon com patches $4\times4$. 
    Isto resulta em um dicionário contendo $48$ linhas ($4\times4\times3$). 
    Este dicionário contém $32$ colunas. 
    Cada quadrado mostrado contém $4\times4$ pixels, 
    cada um exibindo um valore RGB.
    O conteúdo de cada um dos quadrados corresponde a uma coluna, com os valores 
    associados às $48$ linhas.}
    \begin{center}
           \includegraphics[width=0.4\textwidth]{img/indoor_p4_d32.png}
    \end{center}
    \legend{Fonte: O Autor.}
    \label{fig:dicip4d32}
\end{figure}

% \begin{figure}[H]
%     \caption{Dicionários aprendidos. 
%     (a) Classe cartoon, tamanho do dicionário $192$ e patches $8\times8$. 
%     (b) Classe indoor, tamanho do dicionário $32$ e patches $4\times4$. }
%     \begin{center}
%         \begin{tabular}{r c}
%             \vspace*{1em}
%             (a) & \raisebox{-.5\height}{\includegraphics[width=0.8\textwidth]{img/cartoon_p8_d192.png}} \\
%         \end{tabular}
%         \begin{tabular}{r c}
%            (b) & \raisebox{-.5\height}{\includegraphics[width=0.4\textwidth]{img/indoor_p4_d32.png}} \\
%         \end{tabular}
%     \end{center}
%     \legend{Fonte: O Autor.}
% \end{figure}

Em seguida serão apresentados os resultados alcançados com as diferentes parametrizações 
e diferentes classes de vídeos.

\section{Alterações no tamanho do dicionário, no tamanho do patch e no parâmetro de esparsidade}
\label{sec:parametrizacao}
Nessa seção serão apresentados e discutidos resultados alcançados na compressão e 
decompressão dos vídeos escolhidos de cada classe para os parâmetros definidos na 
\autoref{tbl:testparams}.
No total foram 9 parametrizações diferentes para cada uma das 5 classes de vídeos, 
totalizando 45 combinações diferentes para serem testadas.

Ao observar o algoritmo OMP (\ref{algo:omp}), verifica-se que sua complexidade teórica 
é $O(s m d)$, tal que, nesse caso, $m = K$ e $d = 3p^2$, portanto, $O(s K p^2)$.
Os resultados mostram o que a teoria espera, um aumento linear no tempo de processamento,
pois no caso considerado, foram mantidos $s$ e $d$ fixos, enquanto a variação ocorreu em $m$.
Vale ressaltar que o processamento de cada patch foi individual e utilizando a plataforma 
CUDA\reg, que paraleliza as operações.
Porém, por mais que patches possam ser executados em paralelo, seu tempo individualmente, 
no processamento do OMP, aumenta conforme o tamanho do dicionário.

\begin{figure}[H]
    \caption{Tempo médio para codificação e decodificação por quadro para patches $4\times4$ em função do tamanho do dicionário $K$.}
    \begin{center}
        \includegraphics[width=0.9\textwidth]{img/graficos/p4_ds_edtime.png}
    \end{center}
    \legend{Fonte: O Autor.}
    \label{fig:timep4}
\end{figure}

Na figura acima (\ref{fig:timep4}) também pode-se constatar que a decodificação tem tempos iguais, independentes
do tamanho do dicionário.
Isso se dá pelo fato de que não é feita a multiplicação pelo método formal, mas sim tomando
somente cada um dos $s$ valores não nulos do vetor.
O mesmo pode ser constatado na figura abaixo, que apresenta os resultados alcançados com $p=8$.

\begin{figure}[H]
    \caption{Tempo médio para codificação e decodificação por quadro para patches $8\times8$ em função do tamanho do dicionário $K$.}
    \begin{center}
        \includegraphics[width=0.9\textwidth]{img/graficos/p8_ds_edtime.png}
    \end{center}
    \legend{Fonte: O Autor.}
    \label{fig:timep8}
\end{figure}

Um fato importante a ser detalhado é de que a classe esportes teve menor tempo médio por quadro.
Esse fato está simplesmente ligado a resolução do vídeo utilizado por essa classe, NTSC, que é 
aproximadamente $2,63$ vezes menor que 720p.
O mesmo acontece com a classe cartoon, no qual o vídeo escolhido possui resolução menor e, portanto,
menor tempo de codificação.
Percebe-se, portanto, uma relação linear entre o tamanho do quadro e o tempo de codificação.

Além disso, o vídeo de cartoon possui vários quadros com partes que se repetem.
O sistema simples que não recalcula os patches que são iguais entrou em ação, fazendo com que 
o tempo médio para decodificação fosse ainda um pouco menor.

Também foi verificada a qualidade dos vídeos utilizando o PSNR médio. 
Os resultados mostram que o PSNR não se alterou significativamente para os diversos tamanhos
de dicionário, o que indica que é possível utilizar valores baixos de $K$ sem perdas significativas
na qualidade da representação.

\begin{figure}[H]
    \caption{PSNR médio em função do tamanho do dicionário $K$, com quantização de 8 bits.}
    \begin{center}
        \includegraphics[width=0.9\textwidth]{img/graficos/ds_psnr.png}
    \end{center}
    \legend{Fonte: O Autor.}
    \label{fig:psnr8bit}
\end{figure}

Nos gráficos da \autoref{fig:psnr8bit} verifica-se uma variabilidade no PSNR médio devido 
a quantização.
Para melhorar esse fato, poderiam ser utilizados inteiros de 16 bits ao invés de 8 bits na 
representação comprimida, considerando que, neste caso, a representação perde significativamente em 
compressibilidade.
A \autoref{fig:psnr16bit} mostra que o PSNR médio é bem mais estável utilizando uma representação 
de 16 bits para todas as classes.

\begin{figure}[H]
    \caption{PSNR médio em função do tamanho do dicionário $K$, com quantização de 16 bits.}
    \begin{center}
        \includegraphics[width=0.9\textwidth]{img/graficos/ds_psnr_16bit.png}
    \end{center}
    \legend{Fonte: O Autor.}
    \label{fig:psnr16bit}
\end{figure}

Além de alcançar maior estabilidade utilizando 16 bits na quantização, 
também é possível verificar que acontece alteração no PSNR devido ao uso 
dos 16 bits, podendo ser uma alternativa para melhoria na representação.

Pode-se verificar, ainda, com o uso de 16 bits, que o PSNR aumenta em função 
do tamanho do dicionário, de uma forma geral.
Uma exceção está nos vídeos indoor, que, para tamanho do patch $4$ e tamanho do dicionário $48$
tem um resultado de PSNR médio um pouco pior.
Porém, apesar da diferença de PSNR confrome o tamanho do dicionário, essa não é 
tão grande, o que mostra que o uso de dicionários menores pode ser bastante útil,
especialmente quando se leva em conta a velocidade de codificação.

Em seguida, foi escolhida a melhor representação do vídeo indoor, que apresenta 
pouca variação nas cenas, para avaliar as mudanças no PSNR médio em função da esparsidade.
Também foi escolhido o vídeo de esportes, usando a mesma configuração, este pelo fato 
de que possui patches com grama, que é uma imagem com alta frequência.
Sumarizando, foram escolhidos $p=4$, $K=32$, e $s=1,2,3,4,5,6$.

\begin{figure}[H]
    \caption{PSNR médio em função do parâmetro de esparsidade $s$, para patches $4\times4$ ($p=4$) e 
    tamanho do dicionário $K=32$.}
    \begin{center}
        \includegraphics[width=0.6\textwidth]{img/graficos/p4d32_sv_psnr.png}
    \end{center}
    \legend{Fonte: O Autor.}
    \label{fig:psnrsvar}
\end{figure}

O que se pode perceber é que conforme o valor de $s$ aumenta, o PSNR médio também, 
mas não de forma linear.
Os pontos $s=4,5,6$ de ambos vídeos não apresentam tão importantes melhoras no 
PSNR médio na relação entre eles. 
Inclusive, para $s~=~6$, o vídeo indoor apresentou degradação em relação a $s=5$, 
causada pelos erros de quantização envolvidos.
Dadas essas constatações, pode-se verificar que o aumento do valor de $s$ faz com 
que a representação seja capaz de aprimorar as altas frequências, muito semelhante 
ao uso da DCT.

Por fim, foi aplicada a métrica de \emph{bitrate},
que consiste em calcular quantos bits por segundo a representação compactada 
de cada vídeo conseguiu alcançar.
A partir da codificação salva dos vídeos codificados,
foi percebido que as melhores compressões aconteceram com tamanho de patch $p=8$, 
variando pouco em relação ao tamanho do dicionário.
Além disso, é possível verificar que o PSNR médio não apresenta mudança significativa em relação 
à mudança do tamanho do patch ou do dicionário, como já citado anteriormente,
o que proporciona a possibilidade de se escolher a representação mais compacta para 
comparar com o codec H.264.
Portanto, foi calculado o bitrate usando o tamanho do patch em $8$ e o tamanho do dicionário
em $128$.

% Tabela do bitrate
\begin{table}[h]
    \caption{Bitrate calculado para vídeos de teste com tamanho do patch $8$, tamanho do 
    dicionário $128$ e parâmetro de esparsidade $8$.}
    \centering
        \begin{tabular}{|l|l|c|c|c|c|}
          \hline
          \multicolumn{1}{|c}{\textit{Classe}} & 
          \multicolumn{1}{|c}{\textit{Vídeo}} & 
          \multicolumn{1}{|c}{\textit{Nº quadros}} & 
          \multicolumn{1}{|c}{\textit{FPS}} & 
          \multicolumn{1}{|c}{\textit{Tam. arquivo (bytes)}} & 
          \multicolumn{1}{|c|}{\textit{Bitrate (kbit/s)}} \\
          \hline
          \hline
          Cartoon & sintel\_trailer & $1.253$ & $24$ & $79.674.062$ & $11.922,5$ \\
          Esportes & football &  $360$ & $30$ & $21.420.945$ & $13.945,9$ \\
          Indoor & johnny  &   $600$ & $60$ & $72.782.464$ & $56.861,3$ \\
          Monitor. & stockholm & $604$ & $59,94$ & $82.818.027$ & $64.208,8$ \\
          Natureza & park\_joy & $500$ & $50$ & $80.040.734$ & $62.531,8$ \\
          \hline
        \end{tabular}
    \legend{Fonte: O Autor.}
    \label{tbl:bitrate}
\end{table}

A informação de quantos bytes a representação possui foi verificada através do salvamento
de um arquivo por teste com a codificação apresentada na proposta do trabalho.

É possível observar que, para vídeos com a câmera em movimento, caso dos dois últimos vídeos da \autoref{tbl:bitrate}, 
o valor do
o bitrate degrada consideravelmente, chamando a atenção da necessidade de se agregar possivelmente
algum tipo de detecção de movimento.
Em especial é possível notar que o maior vídeo (sintel\_trailer) teve maior compressão.
Além de ser o maior vídeo, o mesmo também possui diversas partes com a câmera parada, 
o que facilita a compressão devido ao método proposto.

Fica claro que, quando se deseja tempo real na codificação, deve-se utilizar valores 
de tamanho de patch, parâmetro de esparsidade e tamanho de dicionário mais baixos, enquanto para 
que haja uma representação mais comprimida, 
devem ser utilizados valores mais altos.
O parâmetro de esparsidade $s$ é capaz de controlar a qualidade, a compressão e até mesmo a velocidade 
da codificação, sendo então necessário considerar várias possibilidades para seus valores.

Para resumir, a \autoref{tbl:recomendation} traz recomendações para os valores dos parâmetros do codec, 
nos casos em que o foco está em tempo real ou compressão.

\begin{table}[h]
    \caption{Valores recomendados de parâmetros em função da aplicação desejada.}
    \centering
    \begin{tabular}{|l|c|c|c|c|}
        \hline
        \multicolumn{1}{|c|}{\emph{Aplicação}} & 
        \emph{Foco} & 
        \emph{Tam. patch} & 
        \emph{Tam. dicionário} & 
        \emph{Par. de esparsidade} \\
        \hline
        Tempo real & qualidade & 4 & 16 & 4 \\
        Tempo real & compressão & 8 & 64 & 5 \\
        Gravação & qualidade & 8 & 128 & 10 \\
        Gravação & qual. + compr. & 8 & 128 & 8 \\
        Gravação & compressão & 8 & 128 & 4 \\
        \hline
    \end{tabular}
    \legend{Fonte: O Autor.}
    \label{tbl:recomendation}
\end{table}

\section{Comparação com codec H.264}
Para a comparação com o codec H.264 foi utilizado o software FFmpeg \cite{FFmpeg}, tendo como entrada
as mesmas sequências que serviram para os testes executados. 
O software permite que se gere arquivos de saída com aproximadamente um valor de bitrate desejado.
Dessa forma, foi executado o programa para alcançar os mesmos bitrates que os apresentados 
na \autoref{tbl:bitrate}.
O codec H.264 permite diversas parametrizações.
Por questão de simplicidade, foi utilizada a configuração padrão, apenas forçando o bitrate desejado.
Em seguida, foi calculado o PSNR médio dos vídeos gerados com o codec H.264.

% Usar novos testes para chegar ao valores
\begin{table}[h]
    \caption{Comparação PSNR médio para mesmo bitrate.}
    \centering
        \begin{tabular}{|l|l|c|c|c|}
          \hline
          \multicolumn{1}{|c}{\textit{Classe}} & 
          \multicolumn{1}{|c}{\textit{Vídeo}} & 
          \multicolumn{1}{|c|}{\textit{Bitrate (kbit/s)}} &
          \multicolumn{1}{|c}{\textit{PSNR Proposta (dB)}} & 
          \multicolumn{1}{|c|}{\textit{PSNR H.264 (dB)}} \\
          \hline
          \hline
          Cartoon & sintel\_trailer & $11.922,5$ & $41,83$ & $54,96$ \\
          Esportes & football & $13.945,9$ & $24,96$ & $36,55$ \\
          Indoor & johnny & $56.861,3$ & $30,25$ & $37,50$ \\
          Monitor. & stockholm & $64.208,8$ & $35,11$ & $42,96$ \\
          Natureza & park\_joy & $62.531,8$ & $23,60$ & $32,37$ \\
          \hline
        \end{tabular}
    \legend{Fonte: O Autor.}
    \label{tbl:bitrateh264}
\end{table}

Os resultados obtidos tiveram, para todos os casos, valores de PSNR médio inferiores
aos obtidos com o uso do codec H.264, o que já era esperado.
A abordagem proposta é bastante simples, enquanto que o padrão H.264 é amplamente 
desenvolvido e foi aprimorado tanto pela 
academia quanto pela indústria.
Porém, é possível perceber que 
o codec proposto funciona, porém precisa ser aprimorado.
Em especial, buscar utilizar as técnicas já conhecidas dos padrões de codec, 
por exemplo predição de movimento, pode 
ser uma via para melhorias no PSNR médio e no bitrate.

Para possibilitar uma melhor visualização da situação, também foi executado o 
software FFmpeg codificando os vídeos para H.264 sem utilizar nenhuma parametrização, 
ou seja, utilizando o padrão do programa.
Os resultados são mostrados na \autoref{tbl:bitrateonlyh264}.

\begin{table}[h]
    \caption{PSNR médio e bitrate usando codificação padrão.}
    \centering
        \begin{tabular}{|l|l|c|c|}
          \hline
          \multicolumn{1}{|c}{\textit{Classe}} & 
          \multicolumn{1}{|c}{\textit{Vídeo}} & 
          \multicolumn{1}{|c|}{\textit{Bitrate (kbit/s)}} &
          \multicolumn{1}{|c|}{\textit{PSNR H.264 (dB)}} \\
          \hline
          \hline
          Cartoon & sintel\_trailer & $901,15$ & $45,58$ \\
          Esportes & football & $2.624,67$ & $32,85$ \\
          Indoor & johnny & $874,84$ & $37,93$ \\
          Monitoramento & stockholm & $3.703,45$ & $31,96$ \\
          Natureza & park\_joy & $14.828,28$ & $27,26$ \\
          \hline
        \end{tabular}
    \legend{Fonte: O Autor.}
    \label{tbl:bitrateonlyh264}
\end{table}

Os experimentos realizados indicam que a opção pelo uso das técnicas propostas,
agregados a melhorias que possam ser executadas, podem gerar resultados ainda melhores.

\section{Resultado visual}
\label{sec:resultadovisual}
Por fim, serão observados alguns resultados visuais relativos 
ao codec proposto.
Os resultados discutidos apresentam erros nos quadros gerados 
pelo codec proposto,
comparando a imagem de referência com a gerada pela codificação.

\begin{figure}[H]
    \caption{Fundo de cena do vídeo johnny, tamanho do dicionário $K=32$, parâmetro de esparsidade $s=5$ e patches $4\times4$,
    quantizado 8 bits.
    (a) Referência. 
    (b) Resultado com codec proposto.}
    \begin{center}
        \begin{tabular}{r c r c}
            (a) & \raisebox{-0.5 \height}{\includegraphics[width=0.4\textwidth]{img/johnnyref.png}} & \hspace{1em}
            (b) & \raisebox{-0.5 \height}{\includegraphics[width=0.4\textwidth]{img/johnnyres.png}} \\
        \end{tabular}
    \end{center}
    \legend{Fonte: O Autor.}
    \label{fig:johnnyres}
\end{figure}

Na \autoref{fig:johnnyres} pode-se verificar que altas frequências foram adicionadas a imagem,
na comparação entre a imagem de referência e a imagem gerada pelo codec.

\begin{figure}[H]
    \caption{Vídeo big\_buck\_bunny, tamanho do dicionário $K=16$, parâmetro de esparsidade $s=5$ e patches $4\times4$, 
    quantizado 8 bits. 
    (a) Referência. 
    (b) Resultado com codec proposto.
    Um retângulo delimita uma região onde é possível perceber artefatos de quantização.}
    \begin{center}
        \begin{tabular}{r c r c}
            (a) & \raisebox{-0.5 \height}{\includegraphics[width=0.4\textwidth]{img/bbbref.png}} & \hspace{1em}
            (b) & \raisebox{-0.5 \height}{\includegraphics[width=0.4\textwidth]{img/bbbres.png}} \\
        \end{tabular}
    \end{center}
    \legend{Fonte: O Autor.}
    \label{fig:bbbres}
\end{figure}

Já nesse caso, o quadro resultado é bem próximo ao original. 
O que se nota, apesar disso, é que em alguns pontos da imagem foram criados artefatos relacionados 
ao fato da imagem ter sido dividida em patches.
% A imagem foi recortada para melhor visualização do efeito.
Para reduzir um pouco os efeitos, mas sem causar ofuscamento na imagem, foi utilizado um filtro 
bilateral.
Esta não é a solução ideal, dado que existem algoritmos para especificamente filtrar esses blocos,
porém na versão final do codec não foi implementada essa funcionalidade.

\chapter{Conclusão}
O trabalho apresentou uma proposta de codificação e decodificação de vídeo em tempo real
utilizando métodos de \emph{compressed sensing}
aliados a aprendizado de dicionários.
% além de realizar métricas relacionadas ao próprio codec 
% e também em relação ao padrão H.264, 
O desempenho do codec proposto foi avaliado considerando métricas como PSNR e bitrate em 
comparação com o padrão H.264,
amplamente utilizado para codificação de vídeos.

Na fase de execução de testes e geração de resultados foi possível constatar o funcionamento 
do codec para 5 tipos diferentes de classes de vídeos.
Ficou clara também a relação entre execução em tempo real, compressibilidade do vídeo e 
qualidade com os parâmetros $K$ (número de átomos do dicionário), $p$ (tamanho do bloco), 
e $s$ (parâmetro de esparsidade da representação).

Mudanças no valor de $K$ (tamanho do dicionário) acarretam pouca diferença na qualidade do vídeo, desde que 
o valor não seja muito pequeno. 
Por outro lado, o valor de $K$ altera linearmente o tempo de codificação dos quadros, como 
pode ser verificado nos gráficos das Figuras \ref{fig:timep4} e \ref{fig:timep8}.
Também se percebe que o tempo de decodificação não se altera.
A compressibilidade é alterada pelo valor de $K$, sendo que valores maiores correspondem 
a maior capacidade de compressão (i.e., resultam em arquivos de menor tamanho).
Resumindo, se o objetivo for maior compressão, deve-se escolher valores maiores de $K$.
Se a ideia é tempo real, valores menores são necessários.
Vale lembrar que os dicionários precisam ser previamente gerados. 
O que pode valer a pena, nesse caso, é escolher, para determinada classe, um dicionário para 
tempo real e outro para obter maior compressão, através de testes.

Quanto ao tamanho do patch $p$, esse produz dois distúrbios no codec.
Em primeiro lugar, ao observar $p=4$ e $p=8$, fica claro que, para tempo real, $p=4$ é uma melhor 
solução. 
Para maior compressão, $p=8$. 
Seria interessante serem executados testes com valores de $p$ maiores que $8$, 
no sentido de verificar a capacidade de compressão.
Para isso, em primeiro lugar, deve-se trabalhar em tornar mais veloz a codificação, tanto 
melhorando a implementação do algoritmo utilizado, ou buscando outras soluções.
Por exemplo, durante a execução do trabalho, não foi possível verificar o funcionamento 
paralelo do algoritmo IHT \cite{BLUMENSATHIHT}, que claramente apresenta características
interessantes para um algoritmo paralelizável.
Um detalhe importante é que o tamanho do patch não altera significativamente a qualidade 
da representação, podendo ser alcançada boa qualidade com tamanhos diferentes. 
Porém, vale ressaltar que o uso de patches sem sobreposição tende a produzir artefatos 
nos quadros de vídeos comprimidos.
Para minimizar este problema foram criados algoritmos para \emph{deblocking}, que poderiam 
ser aplicados ao codec proposto.

Já no que diz respeito ao parâmetro de esparsidade $s$, ficou claro que ele altera a qualidade da representação 
e também a compressibilidade.
Quanto à compressibilidade, o resultado pode ser verificado pela própria representação dos dados.
Considere um quadro 720p usando $p=4$, utilizando $1$ byte para o valor e $1$ byte para o índice em cada 
patch, e que são $57600$ patches, $112,5$ kbytes serão utilizados aproximadamente a cada incremento
em $s$.

Por fim, as comparações com o codec H.264 mostraram que existem muitos pontos que podem ser 
aprimorados, mas também mostra que a proposta apresentada pode ser construtiva.
Em relação aos padrões já existentes, fica clara a necessidade de maior desenvolvimento em 
todas as dimensões do codec, pois o que foi apresentado ilustra a ideia principal.
Um caminho a ser seguido é combinar as metodologias já existentes para predição intra-quadro 
e inter-quadro com o aprendizado de dicionários, além de estruturar essa relação.
Além disso, é necessário verificar formas de implementar a camada de rede 
(i.e. parte do codec que define como transmissor e receptor irão se comunicar) 
do codec baseando-se 
nos padrões já existentes.

De forma resumida, este trabalho apresentou uma proposta para a codificação de vídeos 
utilizando aprendizado de dicionários e técnicas de compressed sensing.
% Além disso, foi possível somar conhecimento de áreas até antes desconhecidas, 
% compressed sensing e aprendizado de dicionários.
Do ponto de vista do aprendizado, o trabalho proposto permitiu que, 
através da pesquisa e do estudo, fosse possível compreender e dominar 
melhor os assuntos base da proposta, que não são estudados no escopo das disciplinas de graduação.


% referências
% aqui será usado o environment padrao `thebibliography'; porém, sugere-se
% seriamente o uso de BibTeX e do estilo abnt.bst (veja na página do
% UTUG)
% 
% observe também o estilo meio estranho de alguns labels; isso é
% devido ao uso do pacote `natbib', que permite fazer citações de
% autores, ano, e diversas combinações desses

\bibliographystyle{abntex2-alf}
\bibliography{biblio}

% \newpage
\chapter*{APÊNDICES}
{
    \centering
    \textbf{APÊNDICE A} \\
    \textbf{Codificação de Huffman} \par
}
\vspace{1em}

Dentre os diversos tipos de codificação de dados que existem, alguns deles 
permitem a representação compacta dos dados sem perdas de compressão.
Esse é o caso da codificação de Huffman, um algoritmo de compressão por entropia,
ou seja, que se aproveita da repetibilidade dos dados e de sua distribuição, 
pois, em geral, sinais que carregam informação possuem bastante redundância.

% O método foi apresentado em 1952, e continua sendo amplamente utilizado. 
% Em primeiro lugar, 
Considere que deseja-se comprimir uma sequência de 
símbolos, ou mensagem, utilizando códigos de tamanho variável, um para cada símbolo.
Segundo \citet{HuffmanCoding}, duas restrições básicas são impostas para 
a codificação de mensagens proposta pelo autor:
\begin{enumerate}
    \item Dois símbolos diferentes não podem ter o mesmo código;
    \item Os códigos das mensagem precisam ser construídos de forma que não seja necessário 
    identificar onde começa ou termina um código.
\end{enumerate}

Um princípio básico utilizado é que o tamanho de um código nunca pode ser menor 
do que o de outro menos provável \cite{HuffmanCoding}.

Para facilitar as explicações, dados $N$ símbolos, eles serão representados 
pelos numerais $1, 2, ..., N$.
Algo que pode ser assumido, sem perda de generalidade, considerando $P(s)$ a probabilidade de um símbolo
$a$ qualquer aparecer na mensagem, é que \cite{HuffmanCoding}:
\begin{equation}
    \label{eq:hufprob}
    P(1) \ge P(2) \ge \cdots \ge P(N).
\end{equation}

Por consequência, se quisermos uma codificação ótima, o tamanho do código $L(s)$ 
deve ser \cite{HuffmanCoding}:
\begin{equation}
    \label{eq:huflen}
    L(1) \le L(2) \le \cdots \le L(N).
\end{equation}

Pode-se definir, a partir de \eqref{eq:hufprob} e \eqref{eq:huflen} o tamanho $L$ da mensagem 
codificada:
\begin{equation*}
    L = \sum_{i=1}^N {P(i)L(i)}.
\end{equation*}
É importante ressaltar que:
\begin{equation*}
    \sum_{i=1}^N {P(i)} = 1.
\end{equation*}

Por fim, \citet{HuffmanCoding} apresentou três novas restrições, além das iniciais.
Considere-se $D$ o número de valores que um dígito do código pode assumir.
\begin{enumerate}
    \item $L(1) \le L(2) \le \cdots \le L(N-1) = L(N)$.
    \item Pelo menos $2$ e não mais que $D$ símbolos com código de tamanho $L(N)$ tem códigos 
    com início idêntico, diferenciando-se por seus dígitos finais.
    \item Cada possível sequência de $L(N)-1$ dígitos deve ser usada ou como código ou ser 
    prefixo de outros códigos.
\end{enumerate}

Em seguida, serão explicados os passos do algoritmo apresentado em \citet{HuffmanCoding}.
Por fim, será mostrado um exemplo.
Para facilitar, vamos utilizar o problema de codificação binária, $D=2$, com valores 
possíveis do dígito $0$ e $1$.

A explanação partirá de que a tabela das probabilidades de cada símbolo já está pronta.
Para gerar essa tabela, podem ser simplesmente contadas quantas vezes cada símbolo aparece
em relação ao total dos símbolos da mensagem.

Tomando a tabela de probabilidades ordenada, os dois símbolos de menor probabilidade 
têm seus sufixos definidos por $0$ e $1$.
Em seguida, esses símbolos podem ser considerados como apenas um, com probabilidade igual 
a soma das duas probabilidades. 
A tabela então é atualizada removendo-se os dois símbolos e adicionando o símbolo unido. 
O processo volta a ser executado, iterativamente, até que haja somente um símbolo que seja 
a união de todos, com probabilidade $1$.
Cada vez que é definido o sufixo, considere-se que é inserido a frente do sufixo anterior 
de cada símbolo o valor $0$ ou $1$.

O exemplo a seguir mostra o funcionamento do algoritmo de forma mais clara.
Na figura abaixo, são mostrados os passos da codificação exemplificados por 
\citet{HuffmanCoding}.

\begin{figure}[H]
    \caption{Execução dos passos de codificação de Huffman.}
    \begin{center}
        \includegraphics[width=0.9\textwidth]{img/huffmanprocess.png}
    \end{center}
    \legend{Fonte: \citet{HuffmanCoding}}
\end{figure}

Os códigos binários para cada símbolo gerados foram os seguintes:
\begin{figure}[H]
    \caption{Códigos binários gerados pela codificação de Huffman.}
    \begin{center}
        \includegraphics[width=0.6\textwidth]{img/huffmantable.png}
    \end{center}
    \legend{Fonte: \citet{HuffmanCoding}}
\end{figure}

O método apresentado é muito utilizado e possui variadas implementações na 
literatura.
Além disso, serve de base para diversos compressores de arquivos, também 
estando presente em padrões de codificação de imagens, tal qual o JPEG, 
ou de codificação de vídeo, por exemplo, o H.264.
% Escrever exemplo disso aí
\newpage
{
    \centering
    \textbf{APÊNDICE B} \\
    \textbf{Codificação de Vídeo} \par
}
\vspace{1em}

A comunicação através de vídeo, nas últimas décadas, tem sido uma das principais formas
de comunicação, sob as mais diversas formas.
\citet{SullivanH264} apresentam alguns cenários onde a vídeos digitais são aplicados:
\begin{itemize}
    \item Transmissão televisiva via satélite, ou cabo;
    \item Serviços de conversação via internet;
    \item Streaming de vídeos;
    \item Gravação e armazenamento de vídeos, por exemplo DVD.
\end{itemize}

Se imaginar-se armazenar, por exemplo, apenas uma imagem RGB, $1.280\times720$, 
sem nenhuma compressão, utilizando $1$ byte por canal de cor, a quantidade de bytes necessários 
para tal tarefa seria $1.280\cdot720\cdot3 = 2.764.800$ bytes, ou, aproximadamente, $2,7MB$
por imagem.
Expandindo a ideia, um vídeo de $10$ minutos, ou $600$ segundos, 
utilizando uma taxa de $30$ quadros por segundo,
precisaria de quase $50GB$ para ser armazenado!

Esse exemplo ilustra a necessidade de codificar os vídeos de forma a
reduzir substancialmente a quantidade de informação necessária para armazená-los.
A partir disso, serão descritas algumas características de \textit{codecs} 
(\emph{\textbf{co}der} e \emph{\textbf{dec}oder} de vídeo) precisam observar.

Um dos princípios básicos utilizados na codificação de vídeos é a de que o olho humano
é mais sensível ao brilho do que a cor diretamente \cite{SullivanH264}.
Ou seja, a informação de crominância pode ser representada com menor precisão que 
a informação de luminância.
De fato é isso que acontece na maioria dos \emph{codecs}. 
Em geral, é utilizada o espaço de cor Y, Cb, Cr, no qual Y, chamado componente \emph{lumma},
ou o brilho, em geral é codificado com dimensão 4 vezes maior que Cb e Cr, componentes 
\emph{chroma} do cinza para o azul (Cb) e do cinza para o vermelho (Cr).

Em alguns \emph{codecs} de vídeo existe a possibilidade de utilizar os formatos
\emph{progressive} e \emph{interlaced} \cite{SullivanH264}.
No caso de \emph{progressive}, todo quadro é salvo em sequência.
Já no formato \emph{interlaced}, podem ser utilizados campos entrelaçados.
Por exemplo, um primeiro campo pode ser as linhas pares do quadro, enquanto o segundo
as linhas ímpares \cite{SullivanH264}.
Na sequência do texto será utilizado o termo imagem sem diferenciação entre os 
formatos apresentados.

Técnicas para compressão digital, não somente para vídeos, mas para aplicações em geral,
podem ser classificadas como segue \cite{SullivanH264}:
\begin{itemize}
    \item \textbf{Predição:} Processo no qual são criadas predições sobre a informação 
    que virá. Caso a predição seja de boa qualidade, a diferença entre a predição e a 
    imagem em si, ou resíduo, será pequena e representável com menos bits.
    \item \textbf{Transformações:} Este processo é o de buscar outras formas de representar
    os dados, em geral mais esparsas (ou comprimidas). Por exemplo, para imagens a DCT 
    fornece uma transformação mais compressível que a utilização da imagem original.
    \item \textbf{Quantização:} O processo de quantização se refere a representar os dados
    com menor quantidade de informação, ou seja, menos bits. Um exemplo é trocar uma representação 
    em ponto flutuante por uma representação de inteiros com 8 bits.
    \item \textbf{Codificação de entropia:} Processo que utiliza a redundância de informação para 
    criar uma tabela de representação na qual a informação mais redundante é codificada
    com menos bits e a mais, com mais bits. A codificação de Huffman é um exemplo desse processo.
\end{itemize}

Uma forma simples de fazer compressão de vídeos se dá por tomar cada imagem do vídeos
separadamente e comprimi-la utilizando técnicas relativas a imagens, por exemplo JPEG \cite{SullivanH264}.
Ainda podem ser utilizadas técnicas de predição intra-quadro, visando melhorar a codificação.
Essas técnicas atingem certo grau de compressão, porém vídeos possuem grande correlação temporal
entre seus quadros, ou seja, o quadro do instante $t$ está fortemente correlacionado ao quadro $t-1$ e
ao quadro $t+1$, em geral.
Utilizar a forma anterior não aproveita esse fato, o que leva a se imaginar buscar metodologias
que façam codificação inter-quadro.

A \autoref{fig:hybenc} apresenta a ideia do funcionamento geral de um \textit{encoder} de vídeo,
mostrando, em alto nível, o funcionamento do mesmo.
\begin{figure}[H]
    \label{fig:hybenc}
    \caption{\textit{Encoder} de vídeo híbrido (em especial H.264).}
    \begin{center}
        \includegraphics[width=0.7\textwidth]{img/HybridCodec.png}
    \end{center}
    \legend{Fonte: \citet{SullivanH264}.}
\end{figure}

Um conceito que aproveita a dependência temporal é o MCP (\textit{motion-compensated prediction}).
O MCP considera que, muitas vezes, as mudanças durante os vídeos acontecem devido ao movimento.
Dessa forma, se for possível estimar um vetor de movimento, seria possível fazer uma predição
de compensação de movimento \cite{SullivanH264}. 

Diversas formas de executar-se o MCP foram desenvolvidas pela literatura, unindo ganhos
na complexidade a ganhos em compressibilidade e qualidade, utilizando uma ou mais imagens 
do passado como base para criar predições de movimento.

A seguir será explicado, de forma superficial, o funcionamento do codec H.264, com o qual 
serão feitas comparações nesse trabalho.

\subsection*{Codec H.264}
O codec H.264 foi lançado como padrão em 2003.
Ele incorporou funcionalidades de codecs anteriores, como H.262 e H.263, mas também
trouxe novas funcionalidades.

Antes de entrar mais especificamente nas funcionalidades, é necessário entender-se o 
funcionamento geral do codec.
Em primeiro lugar, podemos dividir o codec em \emph{Network Abstraction Layer} (NAL), a parte
relativa à configuração da rede pela qual o video será transmitido,
e a \emph{Video Coding Layer} (VCL), que diz respeito a forma como será representado o vídeo 
e seus quadros.
Neste resumo o foco será nas funcionalidades relativas a codificação de vídeo, 
por tratarem de um assunto mais próximo a proposta do trabalho.

Sendo assim, a seguir serão listadas funcionalidades presentes no codec.
Basicamente, a VCL separa cada imagem em porções com uma quantidade variável de macroblocos 
de dimensão $16\times16$.
Estes, por sua vez, podem ser divididos em sub-blocos de $16\times8$, $8\times16$,
$8\times8$, $8\times4$, $4\times8$ e $4\times4$.
A partir dos sub-blocos, dos macroblocos e das porções é que a codificação de vídeo 
é executada, levando em consideração o MCP.

Cada um dos quadros pode somente fazer predição intra-quadro (I-quadros), utilizar 
predição inter-quadros (P-quadros) com uma imagem de referência, ou utilizar 
duas imagens de referência, com pesos diferenciados (B-quadros).
Segundo \citet{WiegangH264}, as principais funcionalidades relativas a eficiência
da codificação são as seguintes:
\begin{itemize}
    \item \textbf{Compensação de movimento (CM) com blocos de tamanho variável:}
    Dentro do macrobloco, cada um dos sub-blocos pode fazer CM.
    \item \textbf{CM com acurácia de um quarto de amostra:} A maioria dos codecs anteriores 
    provia CM com acurácia de um meio de amostra. O codec H.264 aumenta o poder 
    de acurácia para um quarto.
    \item \textbf{Vetores de movimento nas bordas da imagem:} Já presente como opcional
    no padrão H.263, permite que bordas também tenham vetores de movimento, utilizando
    técnicas de extrapolação das bordas.
    \item \textbf{Imagens de referência para CM múltiplas:} Permite que o \textit{encoder}
    escolha entre múltiplas imagens as referências para fazer CM.
    \item \textbf{Possibilidade de utilizar imagens preditas como referência:} Em alguns 
    codecs anteriores não era permitido utilizar imagens preditas como referência para o 
    processo de CM. O H.264 remove essa restrição.
    \item \textbf{Predição com pesos:} Permite que o MCP atribua pesos e offsets aos 
    sinais de referência utilizados.
    \item \textbf{Melhorias na predição intra-imagem:} Foram aprimoradas técnicas de
    extrapolação de arestas para a predição intra-imagem.
    \item \textbf{DCT aplicada a blocos menores:} No H.264 a DCT é aplicada a blocos de 
    dimensão $4\times4$, utilizando uma transformada inteira. Porém é possível aplicar 
    a DCT de mesma dimensão novamente a blocos maiores, de forma hierárquica.
    \item \textbf{Melhorias na codificação de entropia:} Foi melhorada a codificação de 
    entropia utilizando um método chamado \emph{arithmetic coding}.
\end{itemize}

Esse apêndice buscou apresentar os conceitos básicos utilizados na codificação de vídeos, 
dando enfoque principal ao padrão H.264, fortemente utilizado no meio.
% Buscar terminar melhor essa parte....
\newpage
{
    \centering
    \textbf{APÊNDICE C} \\
    \textbf{Introdução a CUDA\reg} \par
}
\vspace{1em}

CUDA\reg~é uma plataforma de programação paralela, bem como um modelo de programação, 
desenvolvido pela Nvidia para aplicações de propósito geral poderem ser executadas
em GPU's.
Sua primeira versão foi lançada em 2006.
Desde então, diversas empresas e trabalhos acadêmicos utilizaram a plataforma.
Além da forte utilização, também bibliotecas baseadas na plataforma surgiram, 
com o intuito de prover funções para aplicações já conhecidas como paralelizáveis.
Exemplos de tais plataformas são cuFFT, para aplicações com transformada de Fourier,
cuBLAS, para álgebra linear básica, NPP, para processamento de vídeo, imagens e 
sinais em geral.

A plataforma tem ótimos resultados para algoritmos, procedimentos, que possam utilizar
fortemente o paralelismo \cite{CUDAMAIN}.
Atualmente, GPU's podem possuir mais de 4000 cores, por exemplo, a Nvidia Geforce RTX 2080 Ti,
além de serem capazes de rodarem 32 threads simultaneamente.
Todos os cores, ou pelo menos aqueles que forem designados para determinada aplicação,
devem estar rodando o mesmo código, porém com valores de variáveis que podem ser diferentes.

A arquitetura de CUDA\reg~se dá como na figura abaixo.
Ao ser executado um determinado \textit{kernel}, este é distribuído em um \textit{grid}
com $B$ blocos, cada bloco com $T$ threads.
Dentro de um bloco pode ser compartilhada memória de rápido acesso, enquanto para 
acesso fora do bloco precisa-se de memória global.
\begin{figure}[H]
    \caption{Arquitetura de CUDA\reg.}
    \begin{center}
        \includegraphics[width=0.5\textwidth]{img/CUDAarch.png}
    \end{center}
    \legend{Fonte: \cite{CUDACGUIDE}}
\end{figure}

Os resultados que CUDA\reg~apresenta são muito consistentes para algoritmos claramente
paralelizáveis, como é possível verificar no gráfico abaixo, que apresenta o 
\emph{speedup} alcançado por funções da cuBLAS em comparação com as mesmas funções 
executadas na CPU.
\begin{figure}[H]
    \caption{Speedup de cuBLAS (GPU) em relação a MKL BLAS (CPU).}
    \begin{center}
        \includegraphics[width=0.9\textwidth]{img/cublas9_2.png}
    \end{center}
    \legend{Fonte: \cite{CUBLAS}}
\end{figure}


Em geral o uso da interface com CUDA, através de alguma das linguagens de programação 
que permitem o uso, tais quais Python, C++, Fortran, se dá nas seguintes etapas:
\begin{enumerate}
    \item Alocação inicial de memória da GPU;
    \item Envio dos dados para a GPU;
    \item Processamento das informações;
    \item Aquisição dos dados;
    \item Liberação de memória da GPU.
\end{enumerate}

Os passos de alocação e liberação de memória demandam bastante tempo de CPU.
Em geral, para ganhos de performance, tenta-se alocar memória somente no início da
execução da aplicação, enviando, processando e recuperando as computações executadas 
sem gerar novas alocações.

Para exemplificar o quão simples é executar programas claramente paralelos em 
CUDA\reg, a seguir está descrito um \textit{kernel} que soma duas matrizes,
$\mat{A}$ e $\mat{B}$, e põe o resultado em $\mat{C}$.
\begin{center}
    \begin{lstlisting}
        __global__ void MatAdd(float A[N][N], float B[N][N],
                               float C[N][N])
        {
            int i = threadIdx.x;
            int j = threadIdx.y;
            C[i][j] = A[i][j] + B[i][j];
        }
        \end{lstlisting}
\end{center}

É possível perceber que, além da simplicidade do código, a sintaxe é muito próxima a
da linguagem C. 
Esse fato pode ser considerado uma ajuda para a popularização da plataforma.
Também é possível verificar como se dá o paralelismo. 
Através dos parâmetros $x$ e $y$ de $threadIdx$, seleciona-se qual parte da matriz que 
será somada. 
Nesse caso, por simplicidade, é considerado que o \textit{kernel} será criado com apenas
$1$ bloco, de forma que somente é necessário utilizar o número da thread para definir 
os índices operados.
Caso fossem utilizados mais blocos, deveriam ser considerados os valores de $blockIdx$, 
que corresponde ao identificador de que bloco está sendo processado, e $blockDim$, que 
representa o tamanho do bloco.

% A plataforma CUDA\reg~foi utlizada no trabalho proposto para a paralelização do algoritmo
% OMP (\ref{algo:omp}), conforme será discutido nos próximos capítulos.


\end{document}
