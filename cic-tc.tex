% 
% exemplo genérico de uso da classe iiufrgs.cls
% $Id: iiufrgs.tex,v 1.1.1.1 2005/01/18 23:54:42 avila Exp $
% 
% This is an example file and is hereby explicitly put in the
% public domain.
% 
\documentclass[cic,tc]{iiufrgs}
% Para usar o modelo, deve-se informar o programa e o tipo de documento.
% Programas :
% * cic       -- Graduação em Ciência da Computação
% * ecp       -- Graduação em Ciência da Computação
% * ppgc      -- Programa de Pós Graduação em Computação
% * pgmigro   -- Programa de Pós Graduação em Microeletrônica
% 
% Tipos de Documento:
% * tc                -- Trabalhos de Conclusão (apenas cic e ecp)
% * diss ou mestrado  -- Dissertações de Mestrado (ppgc e pgmicro)
% * tese ou doutorado -- Teses de Doutorado (ppgc e pgmicro)
% * ti                -- Trabalho Individual (ppgc e pgmicro)
% 
% Outras Opções:
% * english    -- para textos em inglês
% * openright  -- Força início de capítulos em páginas ímpares (padrão da
% biblioteca)
% * oneside    -- Desliga frente-e-verso
% * nominatalocal -- Lê os dados da nominata do arquivo nominatalocal.def


% Use unicode
\usepackage[utf8]{inputenc}   % pacote para acentuação

% Necessário para incluir figuras
\usepackage{graphicx}         % pacote para importar figuras

\usepackage{times}            % pacote para usar fonte Adobe Times
% \usepackage{palatino}
% \usepackage{mathptmx}       % p/ usar fonte Adobe Times nas fórmulas
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{bm}
\usepackage{amsthm}      % Teoremas
\usepackage{thmtools}    % Front end para amsthm (\declaretheorem)
\usepackage{icomma}
\usepackage{listings}
\usepackage{tcolorbox}
\usepackage{hyperref}
\usepackage{multirow}

\newcommand{\lstfont}[1]{\color{#1}\scriptsize\ttfamily}

\declaretheorem[style=definition,name=Definição,parent=chapter,qed=\textemdash]{definicao}
\declaretheorem[style=plain,name=Teorema,qed=\textnormal{\textemdash}]{teorema}
\declaretheorem[style=plain,name=Axioma,qed=\textnormal{\textemdash}]{axioma}

\usepackage[alf,abnt-emphasize=bf]{abntex2cite}	% pacote para usar citações abnt

\usepackage[portuguese,ruled,vlined,boxed]{algorithm2e}
\renewcommand{\algorithmautorefname}{Algoritmo}% para utilizar \autoref

\def\SPSB#1#2{\rlap{\textsuperscript{#1}}\SB{#2}}
\def\SP#1{\textsuperscript{#1}}
\def\SB#1{\textsubscript{#1}}

\renewcommand{\vec}[1]{\bm{#1}}
\newcommand{\mat}[1]{\bm{#1}}
\newcommand{\reg}{\textsuperscript{\textregistered}}

\usepackage{mathtools}
\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}
\DeclarePairedDelimiter{\floor}{\lfloor}{\rfloor}


\lstset{
    language=[ANSI]C++,
    showstringspaces=false,
    backgroundcolor=\color{white},
    basicstyle=\lstfont{black},
    identifierstyle=\lstfont{black},
    keywordstyle=\lstfont{blue!95},
    numberstyle=\lstfont{black},
    stringstyle=\lstfont{cyan},
    commentstyle=\lstfont{green!90},
    emph={
        cudaMalloc, cudaFree,
        __global__, __shared__, __device__, __host__,
        __syncthreads,
    },
    emphstyle={\lstfont{green!60!black}}
}


% 
% Informações gerais
% 
\title{Aplicação de técnicas de compressed sensing e dictionary learning para codificação de vídeos em tempo real.}

\author{Sachser}{Eduardo}
% alguns documentos podem ter varios autores:
% \author{Flaumann}{Frida Gutenberg}
% \author{Flaumann}{Klaus Gutenberg}

% orientador e co-orientador são opcionais (não diga isso pra eles :))
\advisor[Prof.~Dr.]{Oliveira Neto}{Manuel Menezes de }
% \coadvisor[Prof.~Dr.]{Knuth}{Donald Ervin}

% a data deve ser a da defesa; se nao especificada, são gerados
% mes e ano correntes
% \date{maio}{2001}

% o local de realização do trabalho pode ser especificado (ex. para TCs)
% com o comando \location:
% \location{Itaquaquecetuba}{SP}

% itens individuais da nominata podem ser redefinidos com os comandos
% abaixo:
% \renewcommand{\nominataReit}{Prof\textsuperscript{a}.~Wrana Maria Panizzi}
% \renewcommand{\nominataReitname}{Reitora}
% \renewcommand{\nominataPRE}{Prof.~Jos{\'e} Carlos Ferraz Hennemann}
% \renewcommand{\nominataPREname}{Pr{\'o}-Reitor de Ensino}
\renewcommand{\nominataPRAPG}{Prof.~Vladimir Pinheiro do Nascimento}
% \renewcommand{\nominataPRAPGname}{Pr{\'o}-Reitora Adjunta de P{\'o}s-Gradua{\c{c}}{\~a}o}
% \renewcommand{\nominataDir}{Prof.~Philippe Olivier Alexandre Navaux}
% \renewcommand{\nominataDirname}{Diretor do Instituto de Inform{\'a}tica}
\renewcommand{\nominataCoord}{Prof.~Sérgio Luis Cechin}
% \renewcommand{\nominataCoordname}{Coordenador do PPGC}
% \renewcommand{\nominataBibchefe}{Beatriz Regina Bastos Haro}
% \renewcommand{\nominataBibchefename}{Bibliotec{\'a}ria-chefe do Instituto de Inform{\'a}tica}
% \renewcommand{\nominataChefeINA}{Prof.~Jos{\'e} Valdeni de Lima}
% \renewcommand{\nominataChefeINAname}{Chefe do \deptINA}
% \renewcommand{\nominataChefeINT}{Prof.~Leila Ribeiro}
% \renewcommand{\nominataChefeINTname}{Chefe do \deptINT}

% A seguir são apresentados comandos específicos para alguns
% tipos de documentos.

% Relatório de Pesquisa [rp]:
% \rp{123}             % numero do rp
% \financ{CNPq, CAPES} % orgaos financiadores

% Trabalho Individual [ti]:
% \ti{123}     % numero do TI
% \ti[II]{456} % no caso de ser o segundo TI

% Monografias de Especialização [espec]:
% \espec{Redes e Sistemas Distribuídos}      % nome do curso
% \coord[Profa.~Dra.]{Weber}{Taisy da Silva} % coordenador do curso
% \dept{INA}                                 % departamento relacionado

% 
% palavras-chave
% iniciar todas com letras minúsculas, exceto no caso de abreviaturas
% 
\keyword{compressed sensing}
\keyword{compressive sampling}
\keyword{dictionary learning}
\keyword{real time}
\keyword{video}
\keyword{UFRGS}

%\settowidth{\seclen}{1.10~}

% 
% inicio do documento
% 
\begin{document}

% folha de rosto
% às vezes é necessário redefinir algum comando logo antes de produzir
% a folha de rosto:
% \renewcommand{\coordname}{Coordenadora do Curso}
\maketitle

% dedicatoria
% \clearpage
% \begin{flushright}
%     \mbox{}\vfill
%     {\sffamily\itshape
%       ``If I have seen farther than others,\\
%       it is because I stood on the shoulders of giants.''\\}
%     --- \textsc{Sir~Isaac Newton}
% \end{flushright}

% agradecimentos
%\chapter*{Agradecimentos}
%Agradeço ao \LaTeX\ por não ter vírus de macro\ldots



% resumo na língua do documento
\begin{abstract}
    O trabalho propõe uma metodologia para codificação e decodificação de 
    vídeos em tempo real, utilizando técnicas de compressed sensing e aprendizado 
    de dicionários, apresentando parametrizações possíveis e resultados alcançados 
    a partir da variação dos parâmetros utilizados.
    Por fim, compara o amplamente utilizado padrão de codificação de vídeos H.264
    com a proposta, através das métricas de bitrate e PSNR médio.
\end{abstract}

% resumo na outra língua
% como parametros devem ser passados o titulo e as palavras-chave
% na outra língua, separadas por vírgulas
\begin{englishabstract}{Translate title to english.}{compressed sensing. compressive sampling. UFRGS}
    Must be done yet.
\end{englishabstract}

% lista de figuras
\listoffigures

% lista de tabelas
\listoftables

% lista de abreviaturas e siglas
% o parametro deve ser a abreviatura mais longa
\begin{listofabbrv}{CoSaMP}
    \item[RIP] Restricted Isometric Property
    \item[OMP] Orthogonal Matching Pursuit
    \item[CoSaMP] Compressive Sampling Matching Pursuit 
    \item[ODL] Online Dictionary Learning 
    \item[DCT] Discrete Cosine Transform 
    \item[GPU] Graphical Processing Unit
    \item[PSNR] Peak signal-noise ratio 
    \item[CoDec] Coding and Decoding  
    \item[FPS] Frames por segundo
\end{listofabbrv}

% idem para a lista de símbolos
% \begin{listofsymbols}{$\alpha\beta\pi\omega$}
%     \item[$\sum{\frac{a}{b}}$] Somatório do produtório
%     \item[$\alpha\beta\pi\omega$] Fator de inconstância do resultado
% \end{listofsymbols}

% sumario
\tableofcontents

% aqui comeca o texto propriamente dito

% introducao
\chapter{Introdução}
O processo de globalização vem acontecendo em todo mundo, 
e uma grande aliada desse processo é a internet.
Essa jovem e promissora tecnologia tem transformado a vida das pessoas.
Em especial, a internet trouxe novas formas de comunicação.

Hoje em dia é possível comunicar-se mesmo em longas distâncias, 
através da internet.
Reuniões podem ser feitas através de videoconferências, transmissões 
em tempo real de eventos, streaming de vídeo e áudio passam por 
inúmeros dispositivos conectados a grande rede.
Tais dispositivos vão desde grandes datacenters, passando por computadores 
pessoais, laptops, smartphones, e até câmeras de monitoramento instaladas
em cidades, todos com a capacidade de receber e enviar informações 
pela internet.

Segundo a revista Forbes \cite{VideoMarketing}, mais de 500 milhões de horas são assistidos 
diariamente no Youtube. 
Também segundo a revista, até 2021, 17.000 horas de conteúdo de vídeo passarão 
pela internet, por segundo.

Essa grandiosa utilização de vídeos somente é possível graças a eficiência 
dos padrões de transmissão de vídeo e áudio criados ao longo dos anos, 
e ainda sendo estudados e melhorados.
Diversos padrões foram criados, e com o avanço tecnológico, mais tecnologias
são possíveis de serem aplicadas a novos padrões, permitindo que mais informação
trafegue na rede com menor quantidade de dados sendo necessários.

Dentro desse contexto, o trabalho que segue buscará discutir como novos 
campos do conhecimento tais quais compressed sensing e aprendizado de 
dicionários (\emph{dictionary learning}), apresentando uma proposta de 
codificação de vídeos em tempo real baseada nesses assuntos, bem como 
métricas e avaliações do funcionamento da proposta.

O capítulo \autoref{cap:ref} trará o referencial teórico que serviu de base
para a elaboração da proposta do trabalho,
abordando assuntos relativos a processamento de sinais, compressed sensing, 
aprendizado de dicionários, codificação de vídeos e uma breve introdução 
a plataforma CUDA\reg.
No capítulo seguinte discutir-se-ão alguns trabalhos que inspiraram a 
proposta ou que apresentam diferentes óticas para o mesmo problema.
A seguir, será detalhada a proposta. 
Baseando-se na mesma, serão apresentados alguns resultados de medidas 
aplicadas ao objeto do trabalho, encerrando com conclusões tiradas com 
base na proposta, nos trabalhos relacionados, e nas medidas executadas. 

\section{Objetivos}
Este trabalho tem os seguintes objetivos:
\begin{itemize}
    \item Apresentar uma proposta de codificação de decodificação de vídeos
    em tempo real baseada em técnicas de compressed sensing e aprendizado de 
    dicionários.
    \item Realizar medidas comparativas entre as diversas possibilidades 
    de parametrização do objeto do trabalho proposto.
    \item Realizar medidas comparativas com outros padrões conhecidos de 
    codecs de vídeo.
\end{itemize}

\section{Notações Utilizadas}
Algumas notações serão utilizadas ao longo de todo o trabalho.
Para representar matrizes, serão utilizadas letras gregas ou romanas, 
maiúsculas e em negrito, por exemplo $\mat{X}$.
As colunas de $\mat{X}$ serão representadas pela letra correspondente 
minúscula em negrito, com o indexador da coluna, $\vec{x_i}$, também em negrito.
Outra forma possível de representar partes de uma matriz podem ser $\mat{X_{:,i}}$,
que representa todas as linhas da coluna $i$, e $\mat{X_{i,:}}$, que representa 
todas as colunas da linha $i$.
Um valor qualquer da matriz é descrito como $\mat{X_{i,j}}$.
Letras minúsculas em negrito representarão vetores.
A indexação de vetores acontecerá no formato $x_i$, não utilizando negrito. % Revisar todo o texto

%Apresentar normas e (t)
Alguns algoritmos calculam variáveis relacionadas a uma determinada iteração $t$.
Nesses algorimos, seguindo as notações anteriormente apresentadas, $\mat{X_{(t)}}$ 
representa a matriz $\mat{X}$ da iteração de número $t$.
O mesmo acontece com vetores, por exemplo, $\vec{x_{(t)}}$.

Por fim, vale lembrar a definição da norma $\ell_p$ para um vetor $\vec{x} \in \mathbb{R}^m$:
\begin{equation*}
    \lVert \vec{x} \rVert_p = 
    \left( \sum_{i=1}^m {|x_i|^p} \right)^{\frac{1}{p}}
\end{equation*}
podendo escrever, portanto, a norma $\ell_2$, por exemplo, como:
\begin{equation*}
    \lVert \vec{x} \rVert_2 = 
    \sqrt{\sum_{i=1}^m {x_i^2}}
\end{equation*}
e a norma $\ell_1$:
\begin{equation*}
    \lVert \vec{x} \rVert_1 = 
    \sum_{i=1}^m {|x_i|}
\end{equation*}

As normas acima apresentadas, bem como as notações, serão amplamente utilizadas
em todo o texto. 
Outras definições serão agregadas ao continuar a leitura, somando-se as atuais, 
que foram apresentadas por serem aplicadas em toda a extensão do trabalho.

\chapter{Referencial Teórico}
\label{cap:ref}

\section{Introdução a Sinais e Sistemas}
O trabalho apresentará uma metodologia para compressão de vídeos.
Porém, vídeos são, particularmente, uma sequência de imagens.
Já imagens, por sua vez, são um exemplo de sinais bidimensionais.
Vídeos, portanto, sinais tridimensionais.
Fica claro, a partir do posto acima, que há a necessidade de observar-se 
o que é um sinal e alguns resultados importantes, primeiramente, para 
em seguida aprimorarem-se os estudos acerca de outros conceitos.

"Um sinal é formalmente definido como uma função de uma ou mais variáveis, 
a qual veicula informações sobre a natureza de um fenômeno físico" \cite{haykin2001sinais}.
Também segundo \citet{haykin2001sinais}, os sinais são chamados unidimensionais quando
dependem de apenas uma variável, e multidimensionais quando dependem de mais que uma.
Exemplo de multidimensionais foram citadas anteriormente, imagens e vídeos. 
Já unidimensionais, podemos tomar como exemplo os sinais de som, dependentes apenas da variável tempo.

Além disso, temos de definir o que é um sistema. 
Segundo \citet{haykin2001sinais}, "Um sistema é definido como uma entidade que manipula
um ou mais sinais para realizar uma função, produzindo novos sinais".
Um exemplo simples poderia ser o controle de volume de um aparelho de som,
que gera um novo sinal proporcional ao sinal de entrada.
Podemos considerar sistemas bem mais complexos também, como um reconhecedor 
de faces, que precisa tomar como sinais as faces já conhecidas e a que se 
deseja reconhecer, e fornece como saída o nome ou as informações da face reconhecida.

Sinais podem ser contínuos - ou analógicos - e digitais.
Na verdade, em geral, sinais da natureza são contínuos, mas são digitalizados 
para que seja possível armazenamento, envio e processamento por meios digitais.
Dessa forma, \citet{haykin2001sinais} apresenta os passos geralmente executados 
para digitalizar sinais analógicos:
\begin{enumerate}
    \item \emph{Amostragem:} O sinal analógico é amostrado com determinada taxa de amostragem.
    \item \emph{Quantização:} Cada uma das amostras é transformada para um valor digital em um intervalo definido.
    \item \emph{Codificação:} Os valores quantizados são salvos de alguma forma.
    \item \emph{Redundância:} Podem ser geradas informações de redundância para armazenamento do sinal.
\end{enumerate} 

De uma forma geral, a aquisição ou até mesmo a transmissão de um sinal podem conter ruído.
Dessa forma, pode se imaginar que um sinal amostrado é composto pelo próprio sinal somado ao ruído,
$\vec{f} = \vec{y} + \vec{e}$, no qual $\vec{f}$ é a amostragem, $\vec{y}$ é o sinal real, 
e $\vec{e}$ é o erro.


Uma definição importante para o prosseguimento do trabalho é a de energia de um sinal $\vec{f} \in \mathbb{R}^m$,
$E$, como segue:
\begin{equation}
    E = \sum_{i=1}^m f_i^2 = \lVert \vec{f} \rVert_2^2
\end{equation}

Por fim, um resultado clássico sobre amostragem de sinais no domínio tempo, o teorema Shannon-Nyquist.
\begin{teorema}
    \cite{NyquistSampling}.
    Um sinal contínuo pode ser apropriadamente amostrado somente se ele não contiver 
    componentes em frequência $f_{max}$ acima de metade da frequência de amostragem $f_s$.
    \begin{equation*}
        f_{max} \le \frac{f_s}{2}.
    \end{equation*}
\end{teorema}

A partir desse pequeno resumo focado em amostragem de sinais digitais,
as próximas seções utilizarão os conceitos apresentados para formularem outros novos.

\section{Compressed Sensing}
\subsection{O modelo de Compressed Sensing}
\textit{Compressed Sensing (CS)} ou \textit{Compressive Sampling} é um campo de estudo de sinais cujos
primeiros trabalhos surgiram a partir de 2006, a partir da análise de amostragens executadas em imagens de 
ressonância magnética. Essas amostragens eram de muito menor dimensionalidade do que a da imagem, o que 
fez com que os métodos conhecidos de processamento de sinais não tivessem boa acurácia.

"Muitos sinais de interesse possuem menos informação do que a dimensão do ambiente sugere"
\footnote{"Many signals of interest contain far less information than their ambient dimension suggests"}
(\citeauthor{chen2015compressed}, \citeyear{chen2015compressed}, p. 2, tradução própria).
As formas tradicionais de aquisição de sinais baseadas nos teoremas de Shannon e Nyquist acabam por causar o descarte
de boa parte da informação coletada durante a etapa de compressão. Tal fato traz a tona a pergunta: é possível haver 
uma forma de aquisição dos sinais na qual as amostras comprimidas são obtidas diretamente? \cite{chen2015compressed}.

O modelo de Compressed Sensing surgiu com esse intuito \cite{DonohoCS}. Trabalhos na área mostram que, para certas classes
de sinais, poucas amostras são necessárias para representar o sinal com acurácia \cite{chen2015compressed}.
Ou seja, Compressed Sensing busca encontrar quais tipos
de sinais podem ser amostrados de forma já comprimida e respostas de como fazê-lo.

De acordo com o modelo, um sinal $ \vec{f} $ em geral é um elemento de $ \mathbb{C}^d $. Amostragens são executadas na forma:
\begin{equation}
    y_i = \langle \vec{\phi_i}, \vec{f} \rangle \text{ para } i=1,2,...,m, 
\end{equation}
na qual $m \ll d$. Os vetores $\vec{\phi_i}$ são linhas de uma matriz $m \times d$ $\mathbf{\Phi}$, chamada matriz 
de amostragem. Assim, pode-se reescrever o vetor de amostragem como $\vec{y} = \mathbf{\Phi} \vec{f}$. Fica claro que, 
se $ m \ll d$, reconstruir $\vec{f}$ a partir de $\vec{y}$, sem assumir nada a mais, é um problema 
com infinitas soluções \cite{chen2015compressed}.

Uma importante consideração que CS faz é a de que os sinais de interesse possuem menos informação do que sugere a 
dimensão $d$. Uma forma de quantificar essa noção é a esparsidade, que pode ser definida como a quantidade de valores não
nulos $s$ de um sinal $\vec{f} \in \mathbb{C}^d$, também conhecida como norma $\ell_0$:
\begin{equation}
    \lVert \vec{f} \rVert_0 = s
\end{equation}

Considerando o mesmo sinal $\vec{f}$, diz-se que este é \textit{s-esparso}, quando, para dado um um valor $s$, $\vec{f}$
satisfaz a seguinte inequação:
\begin{equation}
    \label{eq:f0less}
    \lVert \vec{f} \rVert_0 \le s \ll d
\end{equation} 

Na prática, sinais não são usualmente encontrados esparsos, o que leva a definição de que \textit{sinais compressíveis}
são aqueles que obedecem a seguinte lei de decaimento exponencial:
\begin{equation}
    \label{eq:compressiblesignal}
    | f\SPSB{*}{k} | < R k^{-\frac{1}{q}},  
\end{equation}
tal que $\vec{f}^* $ é o rearranjo decrescente de $\vec{f}$, $R$ é uma constante positiva e $0< q < 1$. Percebe-se
que para valores bem pequenos de $q$ a compressibilidade se torna praticamente o mesmo que esparsidade. Se considerarmos
$\vec{f_s}$ o vetor com os $s$ maiores valores de $\vec{f}$ em magnitude, temos que, para sinais compressíveis $\vec{f}$ e 
$\vec{f_s}$:
\begin{equation}
    \lVert \vec{f} - \vec{f_s} \rVert_2 \le Rs^{\frac{1}{2} - \frac{1}{q}} \hspace{1em} \text{ e } \hspace{1em}
    \lVert \vec{f} - \vec{f_s} \rVert_1 \le Rs^{1 - \frac{1}{q}} 
\end{equation} 

Por fim, a definição \eqref{eq:f0less} exige que $\vec{f}$ seja esparso, ou seja, tenha $s$ coeficientes não nulos
no máximo. Por outro lado, $\vec{f}$ pode ser esparso em alguma outra base ortonormal $\mathbf{D}$, uma \textit{sparsifying basis} 
\cite{CandesDecoLinear}. Nesse caso, considera-se $\vec{f}$ s-esparso se:
\begin{equation}
    \vec{f} = \mathbf{D}\vec{x} \hspace{1em} \text{dado que} \hspace{1em} \lVert \vec{x} \rVert_0 \le s \ll d.
\end{equation}


\subsection{Mecanismos de Amostragem}
A partir das definições básicas do modelo, pode-se formular o problema básico de CS da seguinte forma:

Tomando um operador de amostragem $\mathbf{\Phi}$, mapeamento linear de $\mathbb{C}^d$ para algum espaço de dimensão 
$\mathbb{C}^m$, para recuperarmos um sinal $\vec{f}$ a partir de suas medidas $\vec{y} = \mathbf{\Phi} \vec{f}$, pode-se escrever
como um problema de minimização.
\begin{equation}
    \label{eq:problem}
    \vec{f}' = \underset{\vec{g} \in \mathbb{C}^d}{\text{argmin}} \lVert \vec{g} \rVert_0 \hspace{1em} \text{sujeito a} \hspace{1em}
    \mathbf{\Phi} \vec{g} = \vec{y} 
\end{equation}

A partir da formulação, se $\mathbf{\Phi}$ não mapeia 2 vetores esparsos quaisquer para a mesma imagem, ou seja,
se $\vec{f} \ne \vec{g} \rightarrow \mathbf{\Phi}\vec{f} \ne \mathbf{\Phi}\vec{g} $, então a solução $\vec{f}'$ recupera
$\vec{f}$, $\vec{f}' = \vec{f}$ \cite{chen2015compressed}. Esse problema, por outro lado, é intratável, e, em geral,
NP-difícil \cite{Mut05}.
Para que o operador de amostragem forneça o resultado anterior, ele deve ser \textit{incoerente}.
Dado um operador $\mathbf{\Phi}$ de colunas $\{ \vec{\phi_i} \}$  com norma unitária, define-se a sua coerência $\mu$
como a maior correlação entre suas colunas.
\begin{equation}
    \label{eq:coerence}
    \mu = \underset{i \ne j}{max}\langle \vec{\phi_i} , \vec{\phi_j} \rangle
\end{equation}

Fica definido, portanto, que um operador de amostragem é \textit{incoerente} quando a sua coerência $\mu$ é 
suficientemente pequena. Por exemplo, um operador de amostragem que seja uma base ortonormal é incoerente, bem como
operadores que sejam aproximadamente ortonormais para vetores esparsos.

Uma propriedade que captura a mesma ideia que o referido acima foi desenvolvida por \citet{CandesSignalRecovery}, chamada 
\textit{Restricted Isometry Property} (RIP). A constante de isometria restrita 
$\delta_s$ é a menor tal que:
\begin{equation}
    \label{eq:rip}
    (1 - \delta_s)\lVert \vec{f} \rVert\SPSB{2}{2} \le \lVert \mathbf{\Phi} \vec{f} \rVert \SPSB{2}{2} \le 
    (1 + \delta_s)\lVert \vec{f} \rVert\SPSB{2}{2} \hspace{1em} \text{para todo vetor s-esparso } \vec{f}.
\end{equation}

Diz-se que um operador de amostragem $\mathbf{\Phi}$ tem a RIP de ordem $s$ quando $\delta_s$ é suficientemente
pequeno, por exemplo, $\delta_s \le 0,1$.

A questão importante da RIP é descobrir qual o número de amostras $m$ é necessária e quais são as 
classes de matrizes que possuem a propriedade. Doi importantes exemplos de matrizes que satisfazem a RIP são
as seguintes \cite{chen2015compressed}: 
\begin{itemize}
    \item \textbf{Matrizes subgaussianas}: uma variável randômica $\mat{X}$ é subgaussiana se 
    $\mathbb{P}(|\mat{X}| > t) \le Ce^{-ct^2}$ para todo $t>0$ e constantes positivas $C$ e $c$. Ou seja,
    variáveis subgaussianas possuem distribuição de média aproximadamente $0$, e a maior parte dos valores
    próximos a média. Exemplos dessa distribuição são a própria distribuição Gaussiana e a matrizes de 
    Bernoulli, que possuem coeficientes $-1$ e $+1$ distribuídos com média $0$. \citet{Mendelson2008} provaram que
    se $\mat{\Phi} \in \mathbb{R}^{m\times d}$ é subgaussiana, então, com alta probabilidade, $\frac{1}{\sqrt{m}}\mat{\Phi}$
    satisfaz a RIP de ordem $s$ quando $m$ está na ordem de $s\log{d}$.
    \item \textbf{Matrizes parcialmente ortogonais limitadas}: dada uma matriz $d\times d$ ortogonal $\mat{\Psi}$
    cujos coeficientes são limitados por $\frac{C}{\sqrt{d}}$ para uma constante $C$. Uma matriz parcialmente
    ortogonal limitada $\mat{\Phi}$ é formada escolhendo $m$ colunas de $\mat{\Psi}$ randomicamente.
    Por exemplo, a matriz da transformada discreta de Fourier tem coeficientes limitados em $\frac{1}{\sqrt{d}}$,
    logo escolhendo $m$ linhas randomicamente tem-se uma matriz parcialmente ortogonal limitada.
    \citet{rudelson2008sparse} provaram que essas matrizes satisfazem RIP com alta probabilidade quando
    o número de medidas $m$ é na ordem de $s\log^4{d}$.
\end{itemize}


\subsection{Algoritmos aplicados ao modelo de Compressive Sensing}
\label{sec:csalgo}
Ao considerar-se a formulação do problema geral de CS apresentada na seção anterior, um dos resultados também apresentados
é de que o problema é NP-difícil. Sob essa ótica, diversas soluções alternativas foram desenvolvidas com 
o intuito de, através da solução de algum outro problema relacionado, ou do uso de alguma diferente estratégia, fosse possível 
chegar a uma solução ótima para a formulação de CS. 

Inicialmente, é necessário levar em consideração que nem sempre as amostras coletadas estão completamente corretas,
o que leva a um novo vetor de medidas, $\vec{y} = \mathbf{\Phi} \vec{f} + \vec{e}$, que considera o ruído de amostragem, 
ou vetor de erro, $\vec{e}$.

Além disso, é essencial definir as propriedades ideais de um método de recuperação
baseado em CS. Segundo \citet{chen2015compressed}, as propriedades são as seguintes:
\begin{itemize}
    \item \textbf{Amostragem não adaptativa:} Os operadoes de amostragem não devem ser dependentes do sinal. 
          Operadores que possuem RIP também possuem essa propriedade.
    \item \textbf{Número ótimo de amostras:} O número de amostras necessárias deve ser mínimo.
    \item \textbf{Garatia de Uniformidade:} Um único operador de amostragem deve ser suficiente para qualquer sinal.
    \item \textbf{Robustez:} O método deve ser estável e robusto em relação ao ruído, e possuir garantias 
          quanto ao erro.
    \item \textbf{Complexidade:} O algoritmo deve ser eficiente.
\end{itemize}

Buscando obedecer o maior número das propriedades citadas acima, alguns métodos e algoritmos surgiram. 
Nas subseções seguintes serão descritas duas metodologias que foram utilizadas para tal.

\subsubsection{Métodos baseados em otimização}
Essa metodologia, utilizada pelos primeiros trabalhos na área, utiliza uma relaxação convexa como forma
de chegar a solução do problema \eqref{eq:problem}. Ou seja, utiliza a norma $\ell_1$ ao invés da norma $\ell_0$,
de forma que o problema se torna convexo e solúvel através de métodos de programação linear.

Dessa forma, o problema relaxado para a norma $\ell_1$ fica como segue:
\begin{equation}
    \label{eq:probleml1}
    \vec{f'} = \underset{\vec{g} \in \mathbb{C}^d}{\text{argmin}} \lVert \vec{g} \rVert_1 \hspace{1em} \text{sujeito a} \hspace{1em}
    \lVert \mathbf{\Phi} \vec{g} - \vec{y} \rVert_2 \le \epsilon
\end{equation}
tal que $\lVert \vec{e} \rVert_2 \le \epsilon $.

A geometria da norma $\ell_1$ permite esparsidade, como pode-se ver no exemplo a seguir. Imaginando-se 
que a reta em verde retrata todas as possíveis soluções para um sinal $\vec{f} \in \mathbb{R}^2$, os pontos
mais esparsos da reta são $A=(0;1)$ e $B=(-1.\overline{6};0)$. A região em azul limita todos os pontos 
nos quais $\lVert\vec{p}\rVert_1 \le 1,0$, tal que $\vec{p} \in \mathbb{R}^2$. Nesse caso, o ponto $A$ é o 
de menor norma $\ell_1$ da reta, sendo essa a solução do problema \eqref{eq:probleml1} e, ao mesmo tempo, 
uma das possíveis soluções do problema \eqref{eq:problem}.
\begin{figure}[h]
    \caption{Minimização $\ell_1$ nos pontos da reta.}
    \begin{center}
        \includegraphics[width=0.9\textwidth]{img/l1ball}
    \end{center}
    \legend{Fonte: O Autor.}
    \label{fig:l1ball}
\end{figure}

Candès, Romberg e Tao chegaram a resultados quanto a garantias para os limites de erro, baseado na 
intensidade do ruído, como segue.
\begin{teorema}
    \cite{candes2006stable}. 
    Dado um operador de amostragem $\mathbf{\Phi}$ que satisfaz a RIP.
    Então, para qualquer sinal $\vec{f}$ e sua amostragem ruidosa $\vec{y} = \mathbf{\Phi}\vec{f} + \vec{e}$, 
    tal que $\lVert \vec{e} \rVert_2 \le \epsilon$, a solução $\vec{f}'$ de \eqref{eq:probleml1} satisfaz:
    \begin{equation*}
        \lVert \vec{f}' - \vec{f} \rVert_2 \le C \left[ \epsilon + \frac{\lVert \vec{f} - \vec{f_s} \rVert_1}{\sqrt{s}} \right],
    \end{equation*}
    tal que $\vec{f_s}$ denota o vetor com os $s$ maiores coeficientes em magnitude de $\vec{f}$ e $C$ é uma
    constante tal que $C \ge 0$.
\end{teorema}

\subsubsection{Métodos utilizando algoritmos gulosos}
\label{sec:greedy}
Depois da formalização do problema de CS, gerando a demanda para uma solução,
surgiram os primeiros algoritmos que, de forma iterativa, resolvem o problema \eqref{eq:problem}. 
Um dos principais algoritmos é o \textit{Orthogonal Matching Pursuit (OMP)}, analisado por Gilbert e Tropp \cite{GilbertOMP}.

Segundo \citet{GilbertOMP}, o algoritmo do OMP é o que segue:

\begin{algorithm}[H]
\label{algo:omp}
\caption{\textit{Orthogonal Matching Pursuit (OMP)}}
\Entrada{Matriz de medidas $m \times d$ $\mathbf{\Phi}$, Vetor de $m$ medidas $\vec{y}$, nível de esparsidade $s$}
\Saida{Estimativa do sinal ideal $\vec{f'} \in \mathbb{R}^d$}
$\vec{r_{(0)}} \leftarrow \vec{y}$\;
$t \leftarrow 1$\;
$\Lambda_{(0)} \leftarrow \emptyset$\;
$\vec{f'} \leftarrow \vec{0}$\;
\While{$t \le s$}{
    $\lambda_{(t)} = \underset{j=1,...,d}{argmax}|\langle\vec{r_{(t-1)}}, \vec{\phi_j}\rangle|$\;
    $\Lambda_{(t)} = \Lambda_{(t-1)} \cup \left\{\lambda_{(t)}\right\}$\;
    $\mathbf{\Phi_{(t)}} = \left[ \mathbf{\Phi_{(t-1)}} \hspace{0.5em} \vec{\phi_{\lambda_{(t)}}} \right]$\;
    Resolver problema de mínimos quadrados: $\vec{x_{(t)}} = \underset{\vec{x}}{argmin} \lVert \vec{y} - \mathbf{\Phi_{(t)}} \vec{x} \rVert^2$\;
    $\vec{a_{(t)}} \leftarrow \mathbf{\Phi_{(t)}} \vec{x_{(t)}}$\;
    $\vec{r_{(t)}} \leftarrow \vec{y} - \vec{a_{(t)}}$\;
    $t \leftarrow t + 1$\;
}
$\vec{f'}_{\Lambda_{(t-1)}} \leftarrow \vec{x_{(t-1)}}$\;
\end{algorithm}

Uma importante observação relativa ao sucesso do algoritmo OMP é que, dado que a matriz $\mathbf{\Phi}$ é incoerente,
seu conjugado transposto multiplicado por si mesmo é próximo a identidade, ou seja, 
$\vec{u} = \mathbf{\Phi}^* \vec{y} = \mathbf{\Phi}^* \mathbf{\Phi} \vec{f}$ 
é muito próximo a $\vec{f}$. Logo, o OMP considera que o mais alto coeficiente de 
$\vec{u}$ é um dos coeficientes esparsos de $\vec{f}$ \cite{chen2015compressed}.

Gilbert e Tropp ainda apresentam um teorema sobre o algoritmo.
\begin{teorema}
    \cite{GilbertOMP}.
    Dado $\mathbf{\Phi}$ uma matriz $m \times d$ subgaussiana de medidas tal que $m \ge C s \log{d}$ e
    $\vec{f}$ um sinal s-esparso em $\mathbb{R}^d$.
    Então, com alta probabilidade, OMP reconstrui corretamente o sinal $\vec{f}$ a partir de suas
    medidas $\vec{y} = \mathbf{\Phi}\vec{f}$.
\end{teorema}
Sem nenhuma modificação, o OMP não é reconhecidamente robusto a ruído, nem oferece garantias de uniformidade.
Porém, esse algoritmo possui um baixo custo computacional e boa eficiência, tendo complexidade de
$O(s m d)$ \cite{chen2015compressed}. 
Algo que fica claro, observando-se o pseudo-código e a complexidade, é que o OMP tem desempenho diretamente
proporcional com a esparsidade da solução, ou seja, a cada nova iteração no \textit{loop} principal, um 
novo coeficiente da solução é calculado.

Outros algoritmos de estratégia gulosa oferecem garantias de uniformidade, além de robustez a ruído, com 
limites demonstrados, bem como número de iterações e medidas. Dois principais destes algoritmos são o 
\textit{CoSaMP (Compressive Sampling Matching Pursuit)} \cite{NeedellCoSaMP}, e o 
\textit{IHT (Iterative Hard Thresholding)} \cite{BLUMENSATHIHT}.

\subsubsection{Métodos utilizando \textit{Total Variation}}
Em diversas aplicações, os sinais de interesse são imagens. Imagens natuais normalmente são compressíveis
em determinada base, tal qual Wavelets. Porém, a utilização dos métodos anteriores para recuperação 
destas imagens gera, algumas vezes, artefatos de alta frequência, que se tornam desagradáveis a
visualização \cite{chen2015compressed}.
Tal fato levou ao desenvolvimento de outro método de minimização, baseado em \textit{Total Variation},
ou seja, na minimização da norma $\ell_1$ do gradiente da imagem.

Para simplificar a definição, considere-se uma imagem em tons de cinza $\mat{X}$ de tamanho $N\times N$.
Por definição, a \textit{total variation} (TV) de uma imagem $\mat{X}$ é:
\begin{equation}
    \lVert \mat{X} \rVert_{TV} = \sum_{j,k}
    \sqrt{\left( \mat{X_{j+1,k}} - \mat{X_{j,k}} \right)^2 + \left( \mat{X_{j,k+1}} - \mat{X_{j,k}} \right)^2} = 
    \sum_{j,k} |\mat{(\nabla X)}_{j,k} |
\end{equation}
tal que $\mat{\nabla X}$ é o gradiente discreto da imagem $\mat{X}$. O gradiente pode ser definido da 
seguinte forma:
\begin{align*}
    \mat{(X_x)}_{j,k} = \mat{X_{j+1,k}} - \mat{X_{j,k}} \\
    \mat{(X_y)}_{j,k} = \mat{X_{j,k+1}} - \mat{X_{j,k}},
\end{align*}

Resultando, por fim, em:
\begin{equation}
    \mat{\nabla X} = 
    \begin{cases}
        \left( \mat{(X_x)}_{j,k}, \mat{(X_y)}_{j,k} \right), \hspace{0.5em} 1 \le j \le N-1, \hspace{0.5em} 1 \le k \le N-1 \\
        \left( 0, \mat{(X_y)}_{j,k} \right), \hspace{0.5em} j=N, \hspace{0.5em} 1 \le k \le N-1 \\
        \left( \mat{(X_x)}_{j,k}, 0 \right), \hspace{0.5em} 1 \le j \le N-1, \hspace{0.5em} k=N \\
        \left(0,0\right), \hspace{0.5em} j = N, \hspace{0.5em} k=N
    \end{cases}
\end{equation}

Após definidas essas bases, pode-se considerar a minimização a seguir, utilizando a norma TV \cite{chen2015compressed}.
\begin{equation}
    \mat{X'} = \underset{\mat{M}}{argmin} \lVert \mat{M} \rVert_{TV} 
    \hspace{1em} \text{sujeito a} \hspace{1em}
    \lVert \vec{y} - A(\mat{M}) \rVert_2 \le \epsilon,
\end{equation}
tal que $A$ seleciona medidas e vetoriza, $\vec{y} = A(\mat{X}) + \vec{e}$ são as medidas com ruído $\vec{e}$,
sendo que $\lVert \vec{e} \rVert_2 \le \epsilon$.

O ganho na representação de imagens se dá pelo fato de que não se cria uma representação esparsa da imagem
diretamente, mas sim do gradiente da imagem, o que torna a mesma mais suave e remove artefatos com alta
frequência.
Resultados utilizando a norma TV já foram observados em diversos trabalhos.
Por exemplo, entre os primeiros resultados que motivaram o surgimento dessa área de estudo está
o trabalho proposto por \citet{CandesMRI}, no qual, com aproximadamente $5\%$ das medidas de imagens de
ressonância magnética, foi possível recuperar toda a imagem, como é possível visualizar na figura 
abaixo.
\begin{figure}[H]
    \caption{Exemplo de recuperação por norma TV. Em (a) a imagem de teste.
    (b) Amostragem no domínio frequência. (c) Reconstrução via \textit{Filtered BackProjection}
    (d) Reconstrução utilizando a norma TV.}
    \begin{center}
        \includegraphics[width=0.6\textwidth]{img/candesmri}
    \end{center}
    \legend{Fonte: \citet{CandesMRI}}
    \label{fig:l1ball}
\end{figure}

\subsection{Resultados com dicionários coerentes}
A utilização de matrizes de amostragens incoerentes, ou dicionários incoerentes, limita a aplicação de 
compressed sensing em algumas áreas, ou para alguns problemas cuja base de solução dos mesmos é baseada
em dicionários coerentes, que podem ser, por exemplo, um dicionário supercompleto, com mais colunas que linhas. 
"Coerência é, de certa forma, uma propriedade natural para compressed sensing, 
porque se duas colunas são muito correlatas, será impossível em geral distinguir se a energia do sinal
vem de uma ou da outra" 
\footnote{"Coherence is in some sense a natural property in the compressed sensing framework, for if two
columns are closely correlated, it will be impossible in general to distinguish whether the energy in 
the signal comes from one or the other"}
(\citeauthor{CANDESDICTS}, \citeyear{CANDESDICTS}, tradução própria).

Porém, em alguns casos, não precisa-se recuperar os coeficientes originais do sinal, o que com dicionários 
coerentes não é possível, mas sim o próprio sinal já transportado para uma nova base.
Matematicamente falando, imagine-se um sinal $\vec{f} = \mathbf{D}\vec{x}$, no qual suas medidas são
$\vec{y} = \mathbf{\Phi}\vec{f} = \mathbf{\Phi}\mathbf{D}\vec{x}$, se o dicionário $\mathbf{D}$ for
coerente, não é possível recuperar os coeficientes $\vec{x}$, mas é possível recuperar $\vec{f}$ \cite{CANDESDICTS}.

A partir desses estudos, \citet{CANDESDICTS} apresentou uma nova definição para o problema de CS, 
baseado na solução utilizando a norma $\ell_1$, considerando $\vec{f} = \mathbf{D}\vec{x}$ o sinal
e $\vec{y} = \mathbf{\Phi}\vec{f} + \vec{e}$ as medidas, $\vec{e}$ o erro.
\begin{equation}
    \label{eq:problemDl1}
    \vec{f'} = \underset{\vec{g} \in \mathbb{C}^d}{\text{argmin}} \lVert \mathbf{D}^*\vec{g} \rVert_1 
    \hspace{1em} \text{sujeito a} \hspace{1em}
    \lVert \mathbf{\Phi} \vec{g} - \vec{y} \rVert_2 \le \epsilon
\end{equation}
tal que $\lVert \vec{e} \rVert_2 \le \epsilon $.

\citet{CANDESDICTS} também redefiniu a RIP, chamando de D-RIP como segue. 
Dado um operador de amostragem $\mathbf{\Phi}$, ele satisfaz a D-RIP para um determinado 
dicionário $\mathbf{D}$ de ordem $s$ se:
\begin{equation}
    (1 - \delta_s)\lVert \mathbf{D}\vec{x} \rVert\SPSB{2}{2} \le \lVert \mathbf{\Phi} \mathbf{D}\vec{x} \rVert \SPSB{2}{2} \le 
    (1 + \delta_s)\lVert \mathbf{D}\vec{x} \rVert\SPSB{2}{2} \hspace{1em} \text{para todo vetor s-esparso } \vec{x}.
\end{equation}
para algum $\delta_s$, por exemplo $\delta_s \le 0,08$.

Tomando a nova definição, \citet{CANDESDICTS} provou o seguinte teorema sobre a recuperação do sinal.
\begin{teorema}
    \cite{CANDESDICTS}
    Dado $\mathbf{D}$ um dicionário e supondo um operador de amostragem $\mathbf{\Phi}$ que satisfaz
    a D-RIP de ordem $s$.
    Então, a solução $\vec{f'}$ para a análise $\ell_1$ satisfaz:
    \begin{equation*}
        \lVert \vec{f'} - \vec{f} \rVert_2 \le C \left[ \epsilon + \frac{\lVert \mathbf{D}^* \vec{f} - \left( \mathbf{D}^* \vec{f} \right)_s \rVert_1}{\sqrt{s}} \right],
    \end{equation*}
    tal que $\left( \mathbf{D}^* \vec{f} \right)_s$ denota o vetor com os $s$ maiores coeficientes em 
    magnitude de $\mathbf{D}^* \vec{f}$ e $C$ é uma constante tal que $C \ge 0$.
\end{teorema}

Esse novo campo de estudo abriu caminhos para novas análises e usos de CS para outros
problemas, antes não possível, além tornar possível utilizar os modelos e técnicas de CS
para outros campos do conhecimento.

% \subsubsection{Métodos utilizando \textit{Total Variation}}
% Decidir se terá ou não

\section{Aprendizado de Dicionários}
A área de aprendizado de dicionários, do inglês \textit{dictionary learning}, busca, através
dos dados já conhecidos de uma classe de sinais, prover novos dicionários nos quais os sinais 
serão capazes de se conformar de forma mais esparsa. 
Sob o ponto de vista de CS, um dicionário $\mat{D}$ normalmente é escolhido de forma aleatória,
desde que satisfaça a RIP.
Aprendizado de dicionários, por outro lado, busca gerar modelos considerando os sinais envolvidos,
ou seja, dicionários que dependem dos dados, ou \textit{data-dependent dictionaries} \cite{chen2015compressed}.

Nas seções seguintes será explicitado o problema geral de aprendizado de dicionários, bem como 
um algoritmo que é capaz de de gerar um dicionário a partir de dados observados, e, por fim, 
uma aplicação focada em processamento de imagens.

\subsection{Problema Geral de Aprendizado de Dicionários}
Nessa seção será apresentado um modelo geral do problema que aprendizado de dicionários busca resolver.
De forma intuitiva, pode-se imaginar aprendizado de dicionários como se fosse desejado gerar 
um sub-dicionário da língua portuguesa a partir de uma grande quantidade textos, livros, todos 
eles separados por palavras.

Mais formalmente, suponha-se $\vec{x_1}, \vec{x_2}, ..., \vec{x_n} \in \mathbb{R}^L$
um conjunto finito de sinais de trainamento, e inteiros positivos $m, s$.
Deseja-se encontrar a matriz $\mat{D}$ e os s-esparsos vetores 
$\vec{\gamma_1}, \vec{\gamma_2}, ..., \vec{\gamma_n} \in \mathbb{R}^m$ os quais
$\mat{D}\vec{\gamma_i} \approx x_i$ para todo $i$. Dessa forma, pode-se escrever o problema
de aprendizado de dicionários utilizando a norma $\ell_2$ como segue  \cite{chen2015compressed}:
\begin{equation}
    \label{eq:dlgeneral}
    \underset{\mat{D}, \vec{\gamma_1}...\vec{\gamma_n}}{min} 
    \sum_{i=1}^{n} {\lVert  \vec{x_i} - \mat{D} \vec{\gamma_i} \rVert \SPSB{2}{2}}
    \hspace{1em} \text{tal que} \hspace{1em}
    \lVert \vec{\gamma_i} \rVert_0 \le s, \text{ para todo } i.
\end{equation}

Nesse caso, $\mat{D} \in \mathbb{R}^{L\times m}$ é o dicionário aprendido, enquanto os 
vetores $\vec{\gamma_i} \in \mathbb{R}^m$, com no máximo $s$ coeficientes não nulos, é a representação
linear de $\vec{x_i}$ em $\mat{D}$. O valor de $m$ pode ser maior que o de $L$, talvez para 
explorar alguma redundância, mas $s\ll L$. Ainda, sobre o problema \eqref{eq:dlgeneral}, para que as escolhas
de $\vec{\gamma_i}$ e $\mat{D}$ sejam únicas, pode-se forçar que as colunas de $\mat{D}$ tenham norma $\ell_2$
unitária \cite{chen2015compressed}. O valor $m$ é conhecido como o número de átomos do 
dicionário.

É importante notar que a função de erro de \eqref{eq:dlgeneral} usa norma $\ell_2$, mas pode ser trocada
por outra função de erro, como, por exemplo, a norma $\ell_1$ \cite{chen2015compressed}.

Também é possível formular o problema com um dado erro de aproximação $\epsilon$.
Nesse caso, pode-se reformular o problema de aprendizado de dicionários como segue \cite{chen2015compressed}.
\begin{equation}
    \label{eq:dleps}
    \underset{\mat{D}, \vec{\gamma_1}...\vec{\gamma_n}}{min} 
    \sum_{i=1}^{n} {\lVert \vec{\gamma_i} \rVert_0}
    \hspace{1em} \text{tal que} \hspace{1em}
    \lVert \vec{x_i} - \mat{D}\vec{\gamma_i} \rVert_2 \le \epsilon, \text{ para todo } i.
\end{equation}

Unificando as duas formulações \eqref{eq:dlgeneral} e \eqref{eq:dleps}, chega-se ao seguinte
\cite{chen2015compressed}.
\begin{equation}
    \label{eq:dlunica}
    \underset{\mat{D}, \vec{\gamma_1}...\vec{\gamma_n}}{min} 
    \sum_{i=1}^{n} {\lVert \vec{x_i} - \mat{D}\vec{\gamma_i} \rVert\SPSB{2}{2} + \lambda \lVert \vec{\gamma_i} \rVert_0}
\end{equation}
no qual $\lambda$ é um parâmetro de balanceamento.

Porém, utilizando-se a norma $\ell_0$, o problema é usualmente NP-difícil. Dessa forma, pode-se gerar
uma reformulação somente trocando a norma $\ell_0$ pela norma $\ell_1$ \cite{chen2015compressed}.
\begin{equation}
    \label{eq:dlunical1}
    \underset{\mat{D}, \vec{\gamma_1}...\vec{\gamma_n}}{min} 
    \sum_{i=1}^{n} {\lVert \vec{x_i} - \mat{D}\vec{\gamma_i} \rVert\SPSB{2}{2} + \lambda \lVert \vec{\gamma_i} \rVert_1}
\end{equation}

Aprendizado de dicionários tem ligação com diversas outras áreas do conhecimento. 
Em especial, e que será utilizado no decorrer do desenvolvimento do trabalho, está sua ligação
com CS, da forma que foi explicitada no início da seção, e com processamento de imagens,
o que será melhor abordados na seção \autoref{sec:codesparsa}.

\subsection{\textit{Online Dictionary Learning}}
\label{sec:odl}
Um dos principais algoritmos de aprendizado de dicionários, com aplicação em processamento de imagens
é o algoritmo \textit{Online Dictionary Learning (ODL)}. Um de seus principais diferenciais
se dá pela possibilidade de utilizar um conjunto de treinamento bastante volumoso, mantendo bom 
desempenho \cite{MairalOnlineDictLearn}.
Por isso, pode-se dizer que o ODL possui boa escalabilidade.

O ODL, como o próprio nome retrata, é um algoritmo \textit{online}, ou seja, a cada nova iteração $t$
é gerada uma nova versão do dicionário $\mat{D_{(t)}}$ a partir de uma nova amostra $\vec{x_{(t)}}$.

Entrando mais a fundo na definição geral do algoritmo, tomado um chute inicial $\mat{D_{(0)}}$, as próximas
iterações $t \ge 1$ serão baseadas em $\mat{D_{(t-1)}}$ e $\vec{x_{(t)}}$. O novo dicionário $\mat{D_{(t)}}$ será
gerado a partir de dois passos. Primeiramente, deve-se encontrar o vetor de coeficientes $\vec{\gamma_{(t)}}$
relativos a $\vec{x_{(t)}}$ e $\mat{D_{(t-1)}}$, resovendo o problema de codificação esparsa a seguir \cite{chen2015compressed}.
\begin{equation}
    \vec{\gamma_{(t)}} = \underset{\vec{\gamma}}{argmin}
    \frac{1}{2} \lVert \vec{x_{(t)}} - \mat{D_{(t-1)}}\vec{\gamma} \rVert\SPSB{2}{2} +
    \lambda \lVert \vec{\gamma} \rVert_1
\end{equation}
sendo que $\lambda$ é um parâmetro de configuração do algoritmo. Esse problema pode ser resolvido por algum dos 
algoritmos discutidos na seção \autoref{sec:csalgo}. Também é possível alterar-se a norma $\ell_1$ pela $\ell_0$,
de forma que algum algoritmo guloso de CS possa ser utilizado. O mesmo se dará para o passo seguinte.

No segundo passo do algoritmo, definimos o novo dicionário $\mat{D_{(t)}}$ através dos vetores de coeficientes
anteriores, $\vec{\gamma_{(1)}}, ..., \vec{\gamma_{(t-1)}}$, além de considerar o novo $\vec{\gamma_{(t)}}$.
Para facilitar, consideremos a matriz $\mat{X}$ com colunas $\vec{x_1},...,\vec{x_t}$ e a matriz $\mat{\Gamma}$
com colunas $\vec{\gamma_1},...,\vec{\gamma_t}$.
Dessa forma, e considerando que os valores de $\vec{\gamma_i}$ são fixos, pode-se formular o problema \cite{chen2015compressed}.
\begin{equation}
    \mat{D_{(t)}} = \underset{\mat{D}}{argmin}
    \frac{1}{t} \sum_{i=1}^t \lVert \vec{x_i} - \mat{D}\vec{\gamma_i} \rVert\SPSB{2}{2}.
\end{equation}

Processando o problema anterior, chega-se ao resultado de que ele pode ser resolvido utilizando-se o método do 
gradiente descendente. Para isso, primeiramente precisamos definir as matrizes a seguir \cite{chen2015compressed}.
\begin{equation}
    \mat{A_{(t)}} = \sum_{i=1}^t \vec{\gamma_i}\vec{\gamma_i^T} \in \mathbb{R}^{m \times m},
    \hspace{0.5em}
    \mat{B_{(t)}} = \sum_{i=1}^t \vec{x_i}\vec{\gamma_i^T} \in \mathbb{R}^{L \times m}.
\end{equation}

Tomando como valor inicial $\mat{D} = \mat{D_{(t-1)}}$, e utilizando o seguinte cálculo em cada coluna $\vec{d_k}$, 
de forma iterativa,
que sempre minimiza a função objetivo, chega-se no novo dicionário $\mat{D_{(t)}}$.
\begin{equation}
    \vec{d_k} \leftarrow \frac{1}{\mat{A_{(t)_{k,k}}}}
    \left( \vec{B_{(t)_{:,k}}} - \mat{D}\vec{A_{(t)_{:,k}}} \right) +
    \vec{d_k}
\end{equation}

Por fim, será descrito o algoritmo do ODL, conforme \citet{MairalOnlineDictLearn}.

\begin{algorithm}[H]
    \label{algo:odl}
    \caption{\textit{Online Dictionary Learning (ODL)}}
    \Entrada{Distribuição de $\vec{x} \in \mathbb{R}^L = p(\vec{x})$, parâmetro $\lambda$, 
    dicionário inicial $\mat{D_{(0)}}$, número de iterações $T$.}
    \Saida{Dicionário final $\mat{D_{(t)}}$.}
    $\mat{A_{(0)}} \leftarrow \mat{0}$\;
    $\mat{B_{(0)}} \leftarrow \mat{0}$\;
    \For{$t = 1..T$}{
        Escolher nova amostra $\vec{x_{(t)}}$ de $p(\vec{x})$\;
        Resolver:
        $\vec{\gamma_{(t)}} = \underset{\vec{\gamma}}{argmin} \lVert \vec{x_{(t)}} - \mat{D_{(t-1)}}\vec{\gamma} \rVert_2^2 +
        \lambda \lVert \vec{\gamma} \rVert_1$\;
        $\mat{A_{(t)}} \leftarrow \mat{A_{(t-1)}} + \vec{\gamma_{(t)}} \vec{\gamma_{(t)}^T}$\;
        $\mat{B_{(t)}} \leftarrow \mat{B_{(t-1)}} + \vec{x_{(t)}} \vec{\gamma_{(t)}^T}$\;
        Realizar a atualização do dicionário para todas as colunas $k$ até convergência:
        $\vec{d_k} \leftarrow \frac{1}{\mat{A_{(t)_{k,k}}}}
        \left( \vec{B_{(t)_{:,k}}} - \mat{D}\vec{A_{(t)_{:,k}}} \right) + \vec{d_k}$ \;
        \If{$\lVert \vec{d_k} \rVert_2 > 1$}{
            Normalizar $\vec{d_k}$\;
        }
    }
    \Return{$\mat{D_{(t)}}$}
\end{algorithm}


\subsection{Codificação Esparsa}
\label{sec:codesparsa}
A partir das bases de Compressed Sensing e de aprendizado de dicionários, pode-se 
buscar um outro objetivo, compressão de sinais.
No caso que será estudado, o foco será em codificação esparsa de imagens, buscando 
embasar os estudos para a proposta do trabalho em questão.

É necessário considerar que imagens não são usualmente esparsas no domínio tempo.
Porém, no domínio da transformada do cosseno, ou no domínio da DCT (\textit{Discrete Cosine Transform}), 
imagens são, em geral, compressíveis, vide \eqref{eq:compressiblesignal}, fato 
que permite, por exemplo, gerar representações da imagem com alta fidelidade, mesmo
utilizando baixa quantidade de informação.
% Preciso de referências aqui.

Por outro lado, pode-se imaginar que, para uma determinada classe de imagens,
por exemplo, imagens naturais, a utilização de um dicionário previamente treinado 
pode gerar bons resultados. Para remoção de ruído em imagens, \citet{EladDenoising} 
mostram que o uso de dicionários aprendidos têm resultados melhores que o uso de 
dicionários gerais, teóricos.

Considerando uma imagem $I$, separada em patches $P_i$ de tamanho $\sqrt{L}\times\sqrt{L}$, 
com ou sem sobreposição - normalmente para problemas de remoção de ruído, com sobreposição,
enquanto para representação esparsa, sem - e vetorizando cada patch $P_i$ em vetores
$\vec{x_i} \in \mathbb{R}^L$. Tomando um dicionário $\mat{D} \in \mathbb{R}^{L\times m}$, 
aprendido via patches de imagens correlatas a $I$, se desejar-se representar os patches 
$\vec{x_i}$ em relação a $\mat{D}$, temos a seguinte formulação.
\begin{equation}
    \label{eq:patchcoding}
    \vec{\gamma_i} = \underset{\vec{\gamma}}{argmin} \lVert \vec{x_i} - \mat{D}\vec{\gamma} \rVert_2^2
    \hspace{1em} \text{sujeito a} \hspace{1em}
    \lVert \vec{\gamma} \rVert_0 \le s
    \text{ para todo } i,
\end{equation}
tal que $s$ é o número máximo de valores não nulos da representação $\vec{\gamma_i} \in \mathbb{R}^m$.
Para resolver essa formulação, pode-se utilizar algum dos algoritmos apresentados na
seção \autoref{sec:greedy}, por exemplo o OMP. 
Para que a representação seja esparsa, precisa-se garantir que $s \ll L$.
Por exemplo, tomando uma imagem $I$ e separando em patches de $8\times 8$, ou seja,
$L = 64$, poderia ser escolhido um valor de $s = 4$ ou $s=6$, independente do valor 
de $m$, garantido $s \le m$, cujo valor escolhido, por exemplo, poderia ser $m = 256$.

Existem diversas outras aplicações de aprendizado de dicionários no campo de processamento de
imagens, principalmente \cite{MairalSparse}:
\begin{itemize}
    \item \textit{Denoising}: remoção de ruído de imagens;
    \item \textit{Inpainting}: preenchimento de regiões não \textit{pintadas} de imagens;
    \item \textit{Demosaicking}: reconstrução da imagem a partir de sensores digitais;
    \item \textit{Up-scaling}: aumento da resolução de imagens.
\end{itemize}

Estas aplicações fogem ao escopo do trabalho apresentado, portanto não serão
aprofundadas nesse referencial, porém são amplamente desenvolvidas por diversos
autores da área.

% \section{Codificação de Imagens}
% Decidir se terá ou não

\section{Codificação de Huffman}
Dentre os diversos tipos de codificação de dados que existem, alguns deles 
permitem a representação compacta dos dados sem perdas de compressão.
Esse é o caso da codificação de Huffman, um algoritmo de compressão por entropia,
ou seja, que se aproveita da repetibilidade dos dados e de sua distribuição, 
pois, em geral, sinais que carregam informação possuem bastante redundância.

O método foi apresentado em 1952, e continua sendo amplamente utilizado. 
Em primeiro lugar, considere-se que deseja-se comprimir uma sequência de 
símbolos, ou mensagem, utilizando códigos de tamanho variável, um para cada símbolo.
Segundo \citet{HuffmanCoding}, duas restrições básicas são impostas para 
a codificação de mensagens proposta pelo autor:
\begin{enumerate}
    \item Dois símbolos diferentes não podem ter o mesmo código;
    \item Os códigos das mensagem precisam ser construídos de forma que não seja necessário 
    identificar onde começa ou termina um código.
\end{enumerate}

Um princípio básico utilizado é que o tamanho de um código nunca pode ser menor 
do que o de outro menos provável \cite{HuffmanCoding}.

Para facilitar as explicações, dados $N$ símbolos, eles serão representados 
pelos numerais $1, 2, ..., N$.
Algo que pode ser assumido, sem perda de generalidade, considerando $P(s)$ a probabilidade de um símbolo
$s$ qualquer aparecer na mensagem, é que \cite{HuffmanCoding}:
\begin{equation}
    \label{eq:hufprob}
    P(1) \ge P(2) \ge \cdots \ge P(N).
\end{equation}

Por consequência, se quisermos uma codificação ótima, o tamanho do código $L(s)$ 
deve ser \cite{HuffmanCoding}:
\begin{equation}
    \label{eq:huflen}
    L(1) \le L(2) \le \cdots \le L(N).
\end{equation}

Pode-se definir, a partir de \eqref{eq:hufprob} e \eqref{eq:huflen} o tamanho $L$ da mensagem 
codificada:
\begin{equation*}
    L = \sum_{i=1}^N {P(i)L(i)}.
\end{equation*}

É importante ressaltar que:
\begin{equation*}
    \sum_{i=1}^N {P(i)} = 1.
\end{equation*}

Por fim, \citet{HuffmanCoding} apresentou três novas restrições, além das iniciais.
Considere-se $D$ o número de valores que um dígito do código pode assumir.
\begin{enumerate}
    \item $L(1) \le L(2) \le \cdots \le L(N-1) = L(N)$.
    \item Pelo menos $2$ e não mais que $D$ símbolos com código de tamanho $L(N)$ tem códigos 
    com início idêntico, diferenciando-se por seus dígitos finais.
    \item Cada possível sequência de $L(N)-1$ dígitos deve ser usada ou como código ou ser 
    prefixo de outros códigos.
\end{enumerate}

Em seguida, serão explicados os passos do algoritmo apresentado em \citet{HuffmanCoding}.
Por fim, será mostrado um exemplo.
Para facilitar, vamos utilizar o problema de codificação binária, $D=2$, com valores 
possíveis do dígito $0$ e $1$.

A explanação partirá de que a tabela das probabilidades de cada símbolo já está pronta.
Para gerar essa tabela, podem ser simplesmente contadas quantas vezes cada símbolo aparece
em relação ao total dos símbolos da mensagem.

Tomando a tabela de probabilidades ordenada, os dois símbolos de menor probabilidade 
têm seus sufixos definidos por $0$ e $1$.
Em seguida, esses símbolos podem ser considerados como apenas um, com probabilidade igual 
a soma das duas probabilidades. 
A tabela então é atualizada removendo-se os dois símbolos e adicionando o símbolo unido. 
O processo volta a ser executado, iterativamente, até que haja somente um símbolo que seja 
a união de todos, com probabilidade $1$.
Cada vez que é definido o sufixo, considere-se que é inserido a frente do sufixo anterior 
de cada símbolo o valor $0$ ou $1$.

O exemplo a seguir mostra o funcionamento do algoritmo de forma mais clara.
Na figura abaixo, são mostrados os passos da codificação exemplificados por 
\citet{HuffmanCoding}.

\begin{figure}[H]
    \caption{Execução dos passos de codificação de Huffman}
    \begin{center}
        \includegraphics[width=0.9\textwidth]{img/huffmanprocess.png}
    \end{center}
    \legend{Fonte: \citet{HuffmanCoding}}
\end{figure}

Os códigos binários para cada símbolo gerados foram os seguintes:
\begin{figure}[H]
    \caption{Códigos binários gerados pela codificação de Huffman}
    \begin{center}
        \includegraphics[width=0.6\textwidth]{img/huffmantable.png}
    \end{center}
    \legend{Fonte: \citet{HuffmanCoding}}
\end{figure}

O método apresentado é muito utilizado e possui variadas implementações na 
literatura.
Além disso, serve de base para diversos compressores de arquivos, também 
estando presente em padrões de codificação de imagens, tal qual o JPEG, 
ou de codificação de vídeo, por exemplo, o H.264.
% Escrever exemplo disso aí

\section{Codificação de Vídeo}
\label{sec:codvideo}
A comunicação através de vídeo, nas últimas décadas, tem sido uma das principais formas
de comunicação, sob as mais diversas formas.
\citet{SullivanH264} apresentam alguns cenários onde a vídeos digitais são aplicados:
\begin{itemize}
    \item Transmissão televisiva via satélite, ou cabo;
    \item Serviços de conversação via internet;
    \item Streaming de vídeos;
    \item Gravação e armazenamento de vídeos, por exemplo DVD.
\end{itemize}

Se imaginar-se armazenar, por exemplo, apenas uma imagem 720p, RGB, $1280\times720$, 
sem nenhuma compressão, utilizando $1$ byte por cor, a quantidade de bytes necessários 
para tal tarefa seria $1280\cdot720\cdot3 = 2764800$ bytes, ou, aproximadamente, $2,7Mb$
por imagem.
Expandindo a ideia, um vídeo de $10min$, ou $600s$, utilizando uma taxa de $30$ frames por segundo,
precisaria de quase $50Gb$ para ser armazenado!

Com esse pequeno exemplo, fica clara a necessidade de codificar os vídeos de forma a
reduzir substancialmente a quantidade de informação necessária para armazená-los.
A partir disso, serão descritas algumas características de \textit{codecs} 
(\emph{\textbf{co}der} e \emph{\textbf{dec}oder} de vídeo) precisam observar.

Um dos princípios básicos utilizados na codificação de vídeos é a de que o olho humano
é mais sensível ao brilho do que a cor diretamente \cite{SullivanH264}.
Ou seja, pode ser utilizada mais informação para representar o brilho, enquanto a cor
pode ser representada com menor precisão.
De fato é isso que acontece na maioria dos \emph{codecs}. 
Em geral, é utilizada o espaço de cor Y, Cb, Cr, no qual Y, chamado componente \emph{lumma},
ou o brilho, em geral é codificado com dimensão 4 vezes maior que Cb e Cr, componentes 
\emph{chroma} do cinza para o azul (Cb) e do cinza para o vermelho (Cr).

Em alguns \emph{codecs} de vídeo existe a possibilidade de utilizar os formatos
\emph{progressive} e \emph{interlaced} \cite{SullivanH264}.
No caso de \emph{progressive}, todo frame é salvo em sequência.
Já no formato \emph{interlaced}, podem ser utilizados campos entrelaçados.
Por exemplo, um primeiro campo pode ser as linhas pares do frame, enquanto o segundo
as linhas ímpares \cite{SullivanH264}.
Na sequência do texto será utilizado o termo imagem sem diferenciação entre os 
formatos apresentados.

Técnicas para compressão digital, não somente para vídeos, mas para aplicações em geral,
podem ser classificadas como segue \cite{SullivanH264}:
\begin{itemize}
    \item \textbf{Predição:} Processo no qual são criadas predições sobre a informação 
    que virá. Caso a predição for de boa qualidade, a diferença entre a predição e a 
    imagem em si, ou resíduo, será pequena, e, em geral, fácil de codificar, além de mais
    comprimida.
    \item \textbf{Transformações:} Este processo é o de buscar outras formas de representar
    os dados, em geral mais esparsas (ou comprimidas). Por exemplo, para imagens a DCT 
    fornece uma transformação mais compressível que a utilização da imagem bruta.
    \item \textbf{Quantização:} O processo de quantização se refere a representar os dados
    com menor quantidade de informação, ou seja, menos bits. Um exemplo é trocar uma representação 
    em ponto flutuante por uma representação em inteiros com 8bits.
    \item \textbf{Codificação de entropia:} Processo que utiliza a redundância de informação para 
    criar uma tabela de representação na qual a informação mais redundante é codificada
    com menos bits e a mais, com mais bits. A codificação de Huffman é um exemplo desse processo.
\end{itemize}

Uma forma simples de fazer compressão de vídeos se dá por tomar cada imagem do vídeos
separadamente e comprimi-la utilizando técnicas relativas a imagens, por exemplo JPEG \cite{SullivanH264}.
Ainda podem ser utilizadas técnicas de predição intra-frame, visando melhorar a codificação.
Essas técnicas atingem certo grau de compressão, porém vídeos possuem grande correlação temporal
entre seus frames, ou seja, o frame do instante $t$ está fortemente correlato ao frame $t-1$ e
ao frame $t+1$, em geral.
Utilizar a forma anterior não aproveita esse fato, o que leva a se imaginar buscar metodologias
que façam codificação inter-frame.

A imagem a seguir apresenta a ideia do funcionamento geral de um \textit{encoder} de vídeo,
mostrando, em conceito macro, o funcionamento do mesmo.
\begin{figure}[H]
    \caption{\textit{Encoder} de vídeo híbrido (em especial H.264).}
    \begin{center}
        \includegraphics[width=0.7\textwidth]{img/HybridCodec.png}
    \end{center}
    \legend{Fonte: \citet{SullivanH264}.}
\end{figure}

Um conceito que aproveita a dependência temporal é o MCP (\textit{Motion-compensated prediction}).
O MCP considera que, muitas vezes, as mudanças durante os vídeos acontecem devido ao movimento.
Dessa forma, se for possível estimar um vetor de movimento, seria possível fazer uma predição
de compensação de movimento, uma estimativa de movimento \cite{SullivanH264}. 

Diversas formas de executar-se o MCP foram desenvolvidas pela literatura, unindo ganhos
na complexidade a ganhos em compressividade e qualidade, utilizando uma ou mais imagens 
do passado como base para criar predições de movimento.

A seguir será explicado, de forma superficial, o funcionamento do codec H.264, com o qual 
serão feitas comparações nesse trabalho.

\subsection{Codec H.264}
O codec H.264 foi lançado como padrão em 2003.
Ele incorporou funcionalidades de codecs anteriores, como H.262 e H.263, mas também
trouxe novas funcionalidades.

Antes de entrar mais especificamente nas funcionalidades, é necessário entender-se o 
funcionamento geral do codec.
Em primeiro lugar, podemos dividir o codec em Network Abstraction Layer (NAL), a parte
relativa a configuração da rede pela qual o video será transmitido,
e a Video Coding Layer (VCL), que diz respeito a forma como será representado o vídeo 
e seus frames.
Neste resumo o foco será nas funcionalidades relativas a codificação de vídeo, 
por tratarem de um assunto mais próximo a proposta do trabalho.

Sendo assim, a seguir serão listadas funcionalidades presentes no codec.
Basicamente, a VCL separa cada imagem porções com uma quantidade variável de macroblocos 
de dimensão $16\times16$.
Estes, por sua vez, podem ser divididos em sub-blocos de $16\times8$, $8\times16$,
$8\times8$, $8\times4$, $4\times8$ e $4\times4$.
A partir dos sub-blocos, dos macroblocos e das porções é que a codificação de vídeo 
é executada, levando em consideração o MCP.

Cada um dos frames pode somente fazer predição intra-frame (I-frames), utilizar 
predição inter-frames (P-frames) com uma imagem de referência, ou utilizar 
duas imagens de referência, com pesos diferenciados (B-frames).

Segundo \citet{WiegangH264}, as principais funcionalidades relativas a eficiência
da codificação são as seguintes:
\begin{itemize}
    \item \textbf{Motion Compensation (MC) com blocos de tamanho variável:}
    Dentro do macrobloco, cada um dos sub-blocos pode fazer MC.
    \item \textbf{MC com acurácia de um quarto de amostra:} A maioria dos codecs anteriores 
    provia MC com acurácia de um meio de amostra. O codec H.264 aumenta o poder 
    de acurácia para um quarto.
    \item \textbf{Vetores de movimento nas bordas da imagem:} Já presente como opcional
    no padrão H.263, permite que bordas também tenham vetores de movimento, utilizando
    técnicas de extrapolação das bordas.
    \item \textbf{Imagens de referência para MC múltiplas:} Permite que o \textit{encoder}
    escolha entre múltiplas imagens as referências para fazer MC.
    \item \textbf{Possibilidade de utilizar imagens preditas como referência:} Em alguns 
    codecs anteriores não era permitido utilizar imagens preditas como referência para o 
    processo de MC. O H.264 remove essa restrição.
    \item \textbf{Predição com pesos:} Permite que o MCP atribua pesos e offsets aos 
    sinais de referência utilizados.
    \item \textbf{Melhorias na predição intra-imagem:} Foram aprimoradas técnicas de
    extrapolação de arestas para a predição intra-imagem.
    \item \textbf{DCT aplicada a blocos menores:} No H.264 a DCT é aplicada a blocos de 
    dimensão $4\times4$, utilizando uma transformada inteira. Porém é possível aplicar 
    a DCT de mesma dimensão novamente a blocos maiores, de forma hierárquica.
    \item \textbf{Melhorias na codificação de entropia:} Foi melhorada a codificação de 
    entropia utilizando um método chamado \emph{arithmetic coding}.
\end{itemize}

Essa subseção buscou apresentar os conceitos básicos utlizados na codificação de vídeos, 
dando enfoque principal ao padrão H.264, fortemente utilizado no meio.
% Buscar terminar melhor essa parte....

\section{Introdução a CUDA\reg}
CUDA\reg~é uma plataforma de programação paralela, bem como um modelo de programação, 
desenvolvido pela Nvidia para aplicações computacionais em geral poderem ser executadas
em GPU's.
Sua primeira versão foi lançada em 2006.
Desde então, diversas empresas e trabalhos acadêmicos utilizaram a plataforma.
Além da forte utilização, também bibliotecas baseadas na plataforma surgiram, 
com o intuito de prover funções para aplicações já conhecidas como paralelizáveis.
Exemplos de tais plataformas são cuFFT, para aplicações com transformada de Fourier,
cuBLAS, para álgebra linear básica, NPP, para processamento de vídeo, imagens e 
sinais em geral.

A plataforma tem ótimos resultados para algoritmos, procedimentos, que possam utilizar
fortemente o paralelismo \cite{CUDAMAIN}.
Atualmente, GPU's podem possuir mais de 4000 cores, por exemplo, a Nvidia Geforce RTX 2080 Ti,
além de serem capazes de rodarem 32 threads simultaneamente.
Todos os cores, ou pelo menos aqueles que forem designados para determinada aplicação,
devem estar rodando o mesmo código, porém com valores de variáveis que podem ser diferentes.

A arquitetura de CUDA\reg~se dá como na figura abaixo.
Ao ser executado um determinado \textit{kernel}, este é distribuído em um \textit{grid}
com $B$ blocos, cada bloco com $T$ threads.
Dentro de um bloco pode ser compartilhada memória de rápido acesso, enquanto para 
acesso fora do bloco precisa-se de memória global.
\begin{figure}[H]
    \caption{Arquitetura de CUDA\reg}
    \begin{center}
        \includegraphics[width=0.5\textwidth]{img/CUDAarch.png}
    \end{center}
    \legend{Fonte: \cite{CUDACGUIDE}}
\end{figure}

Os resultados que CUDA\reg~apresenta são muito consistentes para algoritmos claramente
paralelizáveis, como é possível verificar no gráfico abaixo, que apresenta o 
\emph{speedup} alcançado por funções da cuBLAS em comparação com as mesmas funções 
executadas na CPU.
\begin{figure}[H]
    \caption{Speedup de cuBLAS (GPU) em relação a MKL BLAS (CPU)}
    \begin{center}
        \includegraphics[width=0.9\textwidth]{img/cublas9_2.png}
    \end{center}
    \legend{Fonte: \cite{CUBLAS}}
\end{figure}


Em geral o uso da interface com CUDA, através de alguma das linguagens de programação 
que permitem o uso, tais quais Python, C++, Fortran, se dá nas seguintes etapas:
\begin{enumerate}
    \item Alocação inicial de memória da GPU;
    \item Envio dos dados para a GPU;
    \item Processamento das informações;
    \item Aquisição dos dados;
    \item Liberação de memória da GPU.
\end{enumerate}

Os passos de alocação e liberação de memória demandam bastante tempo de CPU.
Em geral, para ganhos de performance, tenta-se alocar memória somente no início da
execução da aplicação, enviando, processando e recuperando as computações executadas 
sem gerar novas alocações.

Para exemplificar o quão simples é executar programas claramente paralelos em 
CUDA\reg, a seguir está descrito um \textit{kernel} que soma duas matrizes,
$\mat{A}$ e $\mat{B}$, e põe o resultado em $\mat{C}$.
\begin{center}
    \begin{lstlisting}
        __global__ void MatAdd(float A[N][N], float B[N][N],
                               float C[N][N])
        {
            int i = threadIdx.x;
            int j = threadIdx.y;
            C[i][j] = A[i][j] + B[i][j];
        }
        \end{lstlisting}
\end{center}

É possível perceber que, além da simplicidade do código, a sintaxe é muito próxima a
da linguagem C. 
Esse fato pode ser considerado uma ajuda para a popularização da plataforma.
Também é possível verificar como se dá o paralelismo. 
Através dos parâmetros $x$ e $y$ de $threadIdx$, seleciona-se qual parte da matriz que 
será somada. 
Nesse caso, por simplicidade, é considerado que o \textit{kernel} será criado com apenas
$1$ bloco, de forma que somente é necessário utilizar o número da thread para definir 
os índices operados.
Caso fossem utilizados mais blocos, deveriam ser considerados os valores de $blockIdx$, 
que corresponde ao identificador de que bloco está sendo processado, e $blockDim$, que 
representa o tamanho do bloco.

A plataforma CUDA\reg~foi utlizada no trabalho proposto para a paralelização do algoritmo
OMP (\autoref{algo:omp}), conforme será discutido nos próximos capítulos.


\chapter{Trabalhos Relacionados}
Neste capítulo serão abordados alguns trabalhos que se relacionam com a proposta apresentada.
O foco principal da proposta está na codificação esparsa de frames de vídeos utilizando dicionários
previamente treinados, buscando executar o processo em tempo real.

Todos os trabalhos encontrados, bem como os padrões de vídeo existentes,
utilizam a técnida de separar os frames em blocos, ou \textit{patches},
para que a aplicação das técnicas de transformação e compressão sejam 
mais eficientes.

\citet{BRYTFACEKSVD}, em seu trabalho, fizeram a compressão de imagens de faces, 
utilizando o algoritmo K-SVD para aprendizado de um dicionário. 
Cada imagem facial foi amostrada para as mesmas dimensões, com as faces centralizadas
em um mesmo ponto, de forma que, aproximadamente, cada componente da face localiza-se
em uma mesma posição.
Por fim, cada imagem foi dividia e patches de tamanho $15\times 15$ sem sobreposição.
Para cada posição de patch, foi treinado um dicionário
de 512 átomos. A partir dessas definições, \citet{BRYTFACEKSVD} chegaram a resultados 
com alta taxa de compressão, e ótimas qualidades de recuperação da imagem.
Os resultados alcançados pelos autores indicam a possibilidade de se utilizar essa
metodologia de forma menos restritiva, com, possivelmente, resultados menos impressionantes
tanto em qualidade quanto em compressão.

Alguns trabalhos utilizam as teorias de CS para enviarem amostragens dos blocos
dos vídeos por parte do \textit{encoder}, utilizando-se dos teoremas provados pela teoria.
\citet{NebotDVC} apresentou um trabalho exatamente nesse sentido.
Seguindo o mesmo caminho, e buscando aprimorar a técnica apresentada por \citeauthor{NebotDVC}, 
\citet{DoDISCOS} propõe uma mescla entre os métodos tradicionais de codificação de vídeos
e a utilização de CS, conseguindo bons resultados e abrindo horizontes nesse sentido.
Em ambos trabalhos, a etapa de CS deve ser executada por parte do \textit{decoder}, 
o que é bastante custoso do ponto de vista de vídeos de maior resolução.

\citet{ZhangVideoCS} propõe um método que também mescla os métodos existentes
com a ideia de enviar amostragens. 
No trabalho proposto, apresenta uma forma de definir como cada bloco será codificado,
se utilizando amostragem ou DCT.
Os blocos que utlizam amostragem executam o processo de minimização da norma TV, 
enquanto os demais blocos aplicam a DCT inversa, por parte do \textit{decoder}.
A técnica foi incorporada a codificação H.264, chegando a ganhos significativos na
codificação \cite{ZhangVideoCS}.

Além destes trabalhos, o uso de CS para aprimorar vídeos de baixa qualidade foi 
apresentado por \citet{WirelessXiangCai}, com foco em distribuição de vídeos para
redes Wireless.
O uso de CS, nesse caso, se dá com o intuito de, além de melhorar os vídeos de baixa
qualidade e \textit{bitrate}, fornecer um canal capaz de lidar com ruído, 
tal qual a teoria de CS prevê.

Todos os trabalhos citados anteriormente utilizam como dicionário a DCT.
No sentido de utilizar técnicas de aprendizado de dicionários, 
\citet{chen2010dictionary} apresenta uma proposta baseada na de \citet{ZhangVideoCS},
porém, por parte do \textit{decoder}, ao invés de utilizar algum dicionário conhecido,
utilizar um aprendido.

% Ler o Lima e falar sobre com mais intensidade... OK
\citet{lima2012codificaccao} apresenta em seu trabalho um codec de vídeo bastante 
próximo ao proposto.
Em sua proposta, o autor utiliza o algoritmo K-SVD para treinamento de um dicionário
de 256 átomos, seguindo a proposta de \citeauthor{BRYTFACEKSVD}, conforme descrito
anteriomente.
Para a decomposição, também utiliza o algoritmo OMP, utilizando blocos $8\times8$,
sem sobreposição.
As principais diferenças entre o trabalho descrito e o proposto
estão no uso do ODL como algoritmo de treinamento de dicionários, 
além da forma como são processados os blocos.
No trabalho descrito, \citeauthor{lima2012codificaccao} utiliza a diferença entre o
bloco anterior e o atual ou somente o atual, dado um limite. 
No trabalho proposto, sempre será utilizado o bloco atual.
Porém, quando a diferença não for significativa, não recalculará a representação do bloco.
% A escolha se dá pelo fato de que o dicionário base foi treinado para os blocos 
% não residuais, e que, portanto, espera-se que a representação tenha melhores resultados 
% para estes.

No próximo capítulo será detalhada a proposta do trabalho, explicitando detalhes
da implementação.
Em seguida, testes e resultados serão apresentados com base na proposta.

\chapter{Proposta}
Após considerar o desenvolvimento da área de CS e de aprendizado de dicionários e 
resumidos alguns trabalhos que focaram em alguma dessas áreas, será descrita a proposta 
do trabalho de forma detalhada.

O trabalho proposto visa desenvolver uma metodologia para codificação de vídeos em
tempo real, utilizando pré-aprendidos dicionários relacionados ao próprio vídeo.
Por ser um \textit{framework} com foco em tempo real, transmissão e recepção, 
naturalmente se põe em questão 
a necessidade de definir as funções que serão desenvolvidas por parte do \textit{encoder}
e por parte do \textit{decoder}.

% A proposta foca na codificação de frames a partir de dicionários previamente treinados,
% apresentando um novo olha sobre a transformação aplicada aos frames.
% As técnicas apresentadas de forma resumida na seção \autoref{sec:codvideo} podem ser 
% aplicadas juntamente a metodologia apresentada.

A imagem a seguir apresenta um diagrama geral de blocos, dividindo entre \textit{encoder}
e \textit{decoder}, além de representar blocos funcionais de cada uma das partes de 
forma geral.
\begin{figure}[H]
    \caption{Diagrama geral da solução proposta.}
    \begin{center}
        \includegraphics[width=0.9\textwidth]{img/DiagramaFinal.png}
    \end{center}
    \legend{Fonte: O Autor.}
\end{figure}

Entende-se que os frames processados estarão no formato de imagem colorida,
pixel a pixel, RGB (Red, Green, Blue). 
Ou seja, os frames terão dimensão 
$m \times n \times 3$,
sendo a resolução do vídeo $m \times n$. 
No caso do sistema criado, a ordem dos pixels é 
linha a linha, ou seja, primeiro a linha $0$ e todas suas colunas, depois a $1$, e assim por diante.
Em contraste com essa definição o frame em memória poderia ser coluna por coluna, o que alteraria
alguns cálculos internos, sendo possível adaptar o sistema desenvolvido de forma bastante simples.
Essa é uma diferença para com os codecs conhecidos, que utilizam comumente o espaço de cor YCbCr
para processamento.
O codec proposto não necessita fazer tal transformação, pois a transformação executada pelas 
técnicas de aprendizado de dicionários absorve a transformação no espaço de cor.

Em seguida são definidas as nomenclaturas de alguns parâmetros importantes do
\textit{framework} proposto.

\section{Parâmetros do sistema}
Os parâmetros modificáveis do sistema proposto como um todo estão na tabela a seguir. 
As escolhas e resultados obtidos com a alteração dos parâmetros serão discutidas no 
capítulo \autoref{sec:results}.

\begin{table}[h]
    \caption{Parâmetros do sistema}
    \centering
        \begin{tabular}{|c|p{10cm}|}
          \hline
          \multicolumn{1}{|c|}{\textit{Parâmetro}} & 
            \multicolumn{1}{c|}{\textit{Descrição}}\\
          \hline
          \hline
          $p$    & Tamanho do patch. \\ 
          $s$    & Valor máximo de esparsidade de cada patch. Quantidade de valores não nulos da representação do patch. \\     
          $K$    & Número de átomos do dicionário. \\
          $q$    & Esparsidade de envio da informação, $q \le s$. \\
          \hline
        \end{tabular}
    \legend{Fonte: O Autor.}
    \label{tbl:params}
\end{table}

Nas seções seguintes serão descritas mais a fundo cada uma das etapas, seguindo a ordem
apresentada na imagem, além de explicitar a ligação entre cada um dos blocos funcionais
do projeto.

\section{Aprendizado de dicionário}
\label{sec:learn}
A parte de aprendizado do dicionário é essencial para que a qualidade da representação
esparsa utilizada seja boa.
Além disso, para o caso de treinamento a partir de frames de vídeos, caso em que se está
trabalhando, é também necessário fazer a escolha de um algoritmo que permita a utilização
de uma grande quantidade de dados de treinamento.

Considerando isso e o desempenho apresentado por \citet{MairalOnlineDictLearn}, foi escolhido
como algoritmo de treinamento do dicionário o \textit{Online Dictionary Learning},
descrito em \autoref{sec:odl},
pois esse apresenta bom resultado para grande número de sinais de treinamento.

O treinamento foi executado da seguinte forma:
\begin{enumerate}
    \item Separados frames de vídeos de classe semelhante. Por exemplo, vídeos naturais, vídeos
    de esportes, \textit{cartoon}, etc...
    \item Os frames foram sorteados, de forma a garantir que um comportamento dos últimos frames
    não prepondere sobre todo o dicionário.
    \item Cada frame foi separado em patches com tamanho $p \times p$, sendo $p$ o tamanho de
    patch escolhido para o sistema.
    Para o treinamento, foram utilizados patches com sobreposição. Por fim, todos os patches
    foram vetorizados da mesma forma que em \autoref{sec:frameaquisition}.
    \item Executado algoritmo do ODL, conforme o algoritmo \ref{algo:odl}.
\end{enumerate}

Vale ressaltar que, para vídeos muito especializados, pode-se utilizar um treinamento
mais especializado. Por exemplo, uma transmissão esportiva, que seja de somente um tipo
de esporte, pode treinar um dicionário somente com frames desse determinado esporte.

A fase de aprendizado do dicionário, por envolver um tempo maior de processamento,
deve ser executada antes da transmissão de tempo real, por parte do \textit{encoder}.
Isso é possível, mesmo que não
se conheça a transmissão em si, mas se conheça que tipo de conteúdo será transmitido.

Um importante parâmetro que deve ser escolhido é o número de átomos $K$ do dicionário.
Escolhas de valores maiores tendem a proporcionar maior qualidade na representação do vídeo,
porém com perda de desempenho. No capítulo \ref{sec:results} serão mostrados resultados
de escolhas diferentes no número de átomos do dicionário.

Como parametrização do ODL, utiliza-se o valor $s$ como esparsidade desejada e
$K$ como número de átomos do dicionário.
O algoritmo ainda precisa saber o número de amostras que devem ser selecionadas aleatoriamente
de cada frame.
Para determinar isso, foram executados testes de qualidade com diversos valores
(\ref{sec:parametrizacao}).
Foi utilizada a implementação da biblioteca SPAMS \cite{SPAMS} do algoritmo ODL.

O resultado final desse etapa será um dicionário $\mat{D} \in \mathbb{R}^{3p^2 \times K}$,
que será utilizado nas etapas seguintes de codificação e decodificação.
Assim, portanto, em caso de uma transmissão de tempo real ou até mesmo se salvo em arquivo,
uma das primeiras informações que deve ser enviada é o dicionário que servirá de base
para a transmissão.


\section{\textit{Encoder}}
\subsection{Aquisição do frame}
\label{sec:frameaquisition}
Essa etapa tem como entrada o frame a ser codificado, sendo que o histórico de frames já
processados, para a posterior verificação de igualdade, está armazenado também neste
subsistema.

Já nesse ponto do processamento é necessário ter em vista o tamanho dos patches $p\times p$
que será utilizado. A escolha deve seguir o parâmetro definido na escolha do dicionário.
Valores típicos a serem escolhidos são $p=4$ ou $p=8$. Na seção \ref{sec:parametrizacao} serão 
discutidos resultados alcançados com ambas escolhas de tamanho de patch.

A escolha por processar patches se dá pela necessidade do processamento em tempo real, pois 
os algoritmos relacionados a CS dependem diretamente do tamanho
dos sinais envolvidos, do tamanho dos dicionários e da esparsidade.
Porém, o tamanho dos dicionários e a esparsidade precisam ser maiores conforme maior for 
o sinal, o que leva a um aumento de complexidade maior que linear com o aumento do tamanho dos
patches, além de uma utilização maior de memória para o dicionário.
Utilizar patches pequenos possibilita a paralelização dos cálculos.
No caso do trabalho que está sendo apresentado, em que o processamento dos patches, que será 
comentado na próxima seção, se dá utilizando a arquitetura da GPU, a utilização de maior 
paralelismo tende a aumentar a velocidade de processamento.
Resultados nesse sentido serão discutidos na seção \ref{sec:parametrizacao}.
Como já comentado na seção \autoref{sec:learn}, existe também um \textit{trade-off} entre 
diminuir o tamanho do patch e aumentar a compressão.

Tomada a imagem RGB $\mat{I}$ de dimensões $m \times n \times 3$, ela será separada em patches
$p \times p \times 3$, sem sobreposição. Por exemplo, um dos patches iniciará em $\mat{I_{0,0}}$
e terá parte em $p$ linhas e $p$ colunas, indo a $\mat{I_{p-1, p-1}}$. Em seguida, o próximo
patch iniciará em $\mat{I_{0, p}}$ e terminará em $\mat{I_{p-1, 2p-1}}$.
Nos finais de linha e de coluna, os valores de $m$ e $n$ podem não ser divisíveis por $p$,
o que gera um resíduo. Nesse caso foi adotada a solução que o padrão JPEG utiliza de repetir
o último pixel a esquerda para as colunas e o pixel acima para as linhas, até que chegue-se
a um patch $p \times p$.
Junto ao processo de tomada dos patches, estes são vetorizados, também no formato 
linha a linha, para cada pixel RGB.
Para um patch $\mat{P}$, os três primeiros valores do vetor corresponderão ao RGB de
$\mat{P_{0,0}}$. 
Os próximos três a $\mat{P_{0,1}}$, e assim por diante.
Como resultado final, pode-se dizer que a imagem $\mat{I}$ foi separada em 
\begin{equation*}
    T = \ceil*{\frac{m}{p}} \ceil*{\frac{n}{p}}
\end{equation*}
sinais de dimensão $L = 3p^2$. Pode-se escrever esses sinais como uma matriz 
$\mat{X}\in \mathbb{R}^{L\times T}$, 
na qual cada coluna $\vec{x_i}$ da matriz representa um dos patches vetorizados.
\begin{figure}[H]
    \caption{Funcionamento da vetorização do patch.}
    \begin{center}
        \includegraphics[width=0.6\textwidth]{img/vectorize}
    \end{center}
    \legend{Fonte: O Autor.}
\end{figure}

Além do processo de vetorização, este subsistema também verifica se o patch atual $i$ é 
igual ao mesmo $i$ anterior. Caso seja, marca um vetor $\vec{c}\in \mathbb{B}^T$, que indica os 
patches que precisam ou não ser recalculados.
A métrica considera que um patch deve ser recalculado caso qualquer um dos valores dos 
pixels inseridos nele mudem.
Esse simples cálculo sobre os patches garante que, para vídeos estáticos, o desempenho
da aplicação seja acelerado.
Parte considerável dos vídeos possuem partes com essas características, e esse cálculo simples
não aumenta significativamente a complexidade do sistema como um todo.

\subsection{Codificação esparsa dos patches}
A partir dos patches $\mat{X}$ da etapa anterior, do dicionário $\mat{D}$, e do parâmetro 
de esparsidade desejada $s$, pode-se formular o problema de codificação esparsa, tal que 
$\vec{\gamma_i}$ seja a representação esparsa de $\vec{x_i}$, como segue:
\begin{equation}
    \vec{\gamma_i} = \underset{\vec{\gamma}}{argmin} \lVert \vec{x_i} - \mat{D}\vec{\gamma} \rVert_2^2
    \hspace{1em} \text{sujeito a} \hspace{1em}
    \lVert \vec{\gamma} \rVert_0 \le s,
    \text{ para todo } i.
\end{equation}

O problema acima, como citado anteriormente, pode ser resolvido via OMP.
A implementação básica escolhida para o sistema foi baseada na biblioteca SPAMS \cite{SPAMS}.
A partir dela, foi desenvolvida uma versão em CUDA\reg, focada em paralelizar o algoritmo
OMP para cada $(\vec{x_i}, \vec{\gamma_i})$. Assim, foi possível calcular a representação
em tempo suficiente para transmissão em tempo real, conforme será verificado no capítulo 
de resultados.

Um importante fato a ser considerado sobre o algoritmo \autoref{algo:omp} é que, a cada iteração $i$,
ele descobre a melhor solução para a esparsidade $i$. Ou seja, se escolhida esparsidade $s=5$,
por exemplo, é possível armazenar-se os resultados com esparsidade $s=1,...,5$. 
A utilidade desse fato se dá no controle da taxa de transmissão, pois quanto mais esparsa a 
representação, menor o bitrate. 
Portanto, com a aplicação do OMP, já se é possível gerar as melhores e piores representações.
Imaginando múltiplas transmissões a partir do mesmo \textit{encoder}, cada uma poderia ter 
uma taxa diferente sem a necessidade de mais cálculos nessa etapa.

Como resultado final desse subsistema teremos, para cada patch $i$, uma matriz de representação
$\mat{\Gamma_i} \in \mathbb{R}^{K \times s}$, sendo que cada coluna $(\mat{\Gamma_i})_j$ é 
j-esparsa.

\subsection{Quantização e compressão}
A partir da codificação esparsa apresentada na seção anterior, a ideia dessa seção é 
fazer com que a codificação seja a mais comprimida possível, sem perdas tão sensíveis
na representação do sinal.
Além disso, ao final dessa seção, é necessário que haja uma representação em formato de 
\textit{stream} de bytes, para ser enviada ou armazenada pelo \textit{encoder}.

Primeiramente, o sinal é quantizado uniformemente em 8bits. 
Para isso, é necessário identificar-se os coeficientes máximo $u$ e mínimo $l$ em $\mat{\Gamma}$.
Em seguida, cada coeficiente $c$ de $\mat{\Gamma}$ é quantizado de acordo com a seguinte equação:
\begin{equation*}
    c' = \floor*{0,5 + 255\frac{c - l}{u - l}}
\end{equation*}

Um dos parâmetros que entra em ação é o de esparsidade de envido da informação, $q$. 
Ele é o responsável pela escolha de qual será o nível de esparsidade escolhido,
dado que $1 \le q \le s$.
A partir desse parâmetro escolhem-se as colunas $q-1$ de cada $\mat{\Gamma_i}$ (já quantizado), 
formando $\mat{C} \in \mathbb{N}^{K \times T}$.
Para representação de $\mat{C}$ são utilizadas as matrizes $\mat{V} \in \mathbb{N}^{q \times T}$ e
$\mat{R} \in \mathbb{N}^{q \times T}$, sendo que $\mat{V}$ representa os coeficientes não nulos de
$\mat{C}$ e $\mat{R}$ representa os índices dos mesmos.

Para geração do \textit{bitstream}, são criados vetores a partir de $\mat{V}$ e $\mat{R}$.
Uma consideração importante é que nem sempre os $q$ índices de um patch estarão completos.
Nesse caso foi inserido um valor inválido no vetor de índices, enquanto o vetor de coeficientes
mantém os valores.

Como exemplo prático, selecione-se $q=3$ e $K=16$,
\begin{equation*}
    \mat{V} = 
    \begin{bmatrix}
        189 & 36 & 114 \\
        45  & -1 & 32  \\
        8   & -1 & -1
    \end{bmatrix},
    \mat{R} = 
    \begin{bmatrix}
        7 & 12 & 15 \\
        1  & -1 & 3  \\
        5   & -1 & -1
    \end{bmatrix}
\end{equation*}
tal que as entradas com valor $-1$ correspondem a entradas que não foram necessárias, 
e cada coluna representa um patch $\vec{\gamma_i}$. 
Dessa forma, os vetores $\vec{v}$ e $\vec{r}$ serão os seguintes: 
\begin{center}
    $\vec{v} = \left[ 189, 45, 8, 36, 114, 32 \right]$, \\
    $\vec{r} = \left[ 7,1,5,12,-1,15,3,-1 \right]$.
\end{center}

Ainda em tempo, considerando que alguns dos patches não foram recalculados, estes 
também não precisam ser reenviados. 
Para marcar em que ponto isso acontece foi utilizado o valor $-2$ em $\vec{r}$, 
seguido do número de patches não enviados.

Esses vetores, mais a informação de máximo, mínimo e $q$ precisam ser empacotados 
e comprimidos para enviar ao decoder.
A compressão utilizada foi baseada em codificação de Huffman, e foi utilizada 
a biblioteca \textit{Boost Gzip} \cite{Boost} para tal.

\section{\textit{Decoder}}

\subsection{Decompressão e dequantização}
\label{sec:decdeq}

A primeira etapa necessária é e decompressão dos dados recebidos. 
Foi executado o processo contrário a codificação de Huffman, 
baseando-se na tabela de compressão gerada para recuperar os valores originais.
A biblioteca \textit{Boost Gzip} \cite{Boost} foi utilizada novamente com esse objetivo.

A partir do sinal decomprimido deve-se recuperar as matrizes $\mat{V}$ e $\mat{R}$
tomando os vetores $\vec{v}$ e $\vec{r}$ recebidos.

Em seguida é necessário recompor os coeficientes quantizados 
executando a operação inversa a de quantização.
Considerando $c'$ cada coeficiente recebido, $u$ o maior valor e $l$ o menor, 
valores todos recebidos no \textit{bitstream},
\begin{equation*}
    c = \frac{c' (u - l)}{255} + l
\end{equation*}

Por fim, é inicializada com zeros uma matriz $\mat{\Gamma} \in \mathbb{R}^{K \times T}$,
basta associar $\mat{\Gamma_{\mat{R_{:,i}}, i}} = \mat{V_{:,i}}$ para todo $0 \le i < T$.

Vale lembrar que alguns dos patches podem não ter sido recebidos. 
Essa informação deve ser passada adiante para que somente os patches modificados
sejam reprocessados.

Terminada essa etapa procede-se com a recuperação dos patches.

\subsection{Recuperação dos patches}
A recuperação dos patches por parte do \textit{decoder} é um processo muito simples,
pois incorre somente em uma multiplicação entre o dicionário $\mat{D}$ e a 
representação esparsa recebida $\mat{\Gamma}$.

De tal modo, pode-se definir que a matriz de patches $\mat{X} = \mat{D} \mat{\Gamma}$.
Uma simplificação que pode aumentar a velocidade da decodificação é não criar a matriz $\mat{\Gamma}$,
ou seja, utilizar as informações de $\mat{V}$ e $\mat{R}$ para formar $\mat{X}$. 
Esse procedimento tende a ser mais eficiente, pois quando formada a matriz $\mat{\Gamma}$, 
a maior parte dos coeficientes dessa matriz é nulo, por se tratar de uma representação esparsa.
Porém, aplicando uma multiplicação da forma natural, esse fato é desconsiderado e acabam
acontecendo mais operações de multiplicação do que o necessário.

\subsection{Reconstrução do frame}
A reconstrução do frame se dá exatamente da forma contrária a separação por patches.

Vale notar que alguns dos patches não precisarão ser atualizados.
Essa informação foi recebida pelo \textit{decoder} na etapa \autoref{sec:decdeq} e repassada
até essa etapa.

Assim, cada um dos patches de $\mat{X}$, que estavam vetorizados, são novamente transformados
em matrizes de dimensão $p \times p \times 3$, e colocados em sua devida posição, formando
a imagem recebida $\mat{I}$ de dimensões $m \times n$.

\section{Implementação}
A implementação do codec se deu utilizando a linguagem de programação Python para a etapa 
de aprendizado de dicionários, e, como já citado, a biblioteca SPAMS \cite{SPAMS}.

Para o \emph{encoder} e \emph{decoder} foi escolhida a linguagem C++. 
O carregamento de vídeos utilizou a biblioteca OpenCV \cite{OpenCV}.
Já para o processamento matricial não executado pela plataforma CUDA\reg, a biblioteca 
Eigen \cite{Eigen} foi a selecionada.

O programa para testes executa os processos de codificação e decodificação, realizando 
métricas de tempo e qualidade para ambas etapas.
Além disso, a parte de codificação salva um arquivo comprimido com o resultado da mesma.
Um programa que somente desempacota os dados e decodifica também foi desenvolvido.

Além disso, foram criados alguns subprogramas com o intuito de facilitar os testes e 
execuções, bem como analisar outras possibilidades, e executar métricas em paralelo ao 
desenvolvimento do codec.

\chapter{Resultados}
\label{sec:results}
Durante a implementação da proposta, surgiram alguns parâmetros gerais da implementação
que poderiam ser modificados, vide tabela \ref{tbl:params}. 
Nas próximas seções serão discutidos os parâmetros e resultados alcançados com as 
alterações dos mesmos.

Os testes foram executados com vídeos utilizados na literatura para testes,
disponíveis em \url{https://media.xiph.org/video/derf/}.
% Criar citação
Os vídeos estão em formato de sequência de frames, sem compressão, ou somente com 
compressão sem perdas.
Alguns dos vídeos disponíveis foram escolhidos.
Estes, por sua vez, foram, de forma empírica, separados em grupos: \textit{cartoon}, 
monitoramento, esportes, \textit{indoor} e natureza, de forma que fosse possível 
verificar se existe alguma diferença no uso da técnica para diferentes classes de vídeos.
A tabela a seguir ilustra as escolhas.
Os vídeos em negrito foram os escolhidos para a validação, enquanto os demais para treinamento.

\begin{table}[h]
    \caption{Vídeos utilizados para treinamento e validação}
    \centering
        \begin{tabular}{|c|l|c|c|}
          \hline
          \multicolumn{1}{|c}{\textit{Categoria}} & 
          \multicolumn{1}{|c}{\textit{Vídeo}} & 
          \multicolumn{1}{|c}{\textit{Resolução}} & 
          \multicolumn{1}{|c|}{\textit{Nº de frames}}  \\
          \hline
          \hline
          \multirow{3}{*}{Cartoon} 
          & \textbf{sintel\_trailer} & $1024\times436$ & $ 1.253 $ \\ 
          & big\_buck\_bunny & 720p & $ 14.315 $ \\
          & elephants\_dream & $1024\times436$ & $ 15.691 $ \\
          \hline
          \multirow{3}{*}{Esportes} 
          & \textbf{football} & NTSC & $360$ \\
          & stefan & SIF & $300$ \\ 
          & tennis & SIF & $150$ \\
          \hline
          \multirow{6}{*}{Indoor} 
          & \textbf{johnny} & 720p & $600$ \\ 
          & carphone & QCIF & $382$ \\
          & deadline & CIF & $1.374$ \\
          & foreman & CIF & $300$ \\
          & hall\_monitor & CIF & $300$ \\
          & mother\_daughter & QCIF & $961$ \\
          \hline
          \multirow{4}{*}{Monitoramento} 
          & \textbf{stockholm} & 720p & $604$ \\ 
          & bridge\_close & CIF & $2.001$ \\
          & bridge\_far & CIF & $2.101$ \\
          & station & 1080p & $313$ \\
          \hline 
          \multirow{6}{*}{Natureza} 
          & \textbf{park\_joy} & 720p & $500$ \\
          & ducks\_take\_off & 720p & $500$ \\
          & garden & SIF & $115$ \\
          & in\_to\_tree & 720p & $500$ \\
          & park\_run & 720p & $504$ \\
          & waterfall & CIF & $260$ \\
          \hline
        \end{tabular}
    \legend{Fonte: O Autor.}
    \label{tbl:vidtrain}
\end{table}

A máquina utilizada para o treinamento e os testes possui um processador Intel i5 2.5 GHz e 4 cores físicos,
e 8Gb de memória RAM.
Além disso, a placa de vídeo é Nvidia Geforce GTX 1050Ti, com 4Gb de memória.

Para ilustrar como cada um dos vídeos é em geral, a figura abaixo apresenta uma imagem de 
cada vídeo, para que se possa perceber as peculiaridades inerentes a cada um dos vídeos escolhidos.
\begin{figure}[H]
    \caption{Imagens dos vídeos escolhidos para os testes.
    (a) sintel\_trailer.
    (b) football.
    (c) johnny.
    (d) stockholm.
    (e) park\_joy.}
    \begin{center}
        \begin{tabular}{r c r c}
            \vspace{0.5em}
            (a) & \raisebox{-.5\height}{\includegraphics[width=0.4\textwidth]{img/sintel.png}} & \hspace{0.5em} 
            (b) & \raisebox{-.5\height}{\includegraphics[width=0.4\textwidth]{img/football.png}} \\
            \vspace{0.5em} 
            (c) & \raisebox{-.5\height}{\includegraphics[width=0.4\textwidth]{img/johnny.png}} & \hspace{0.5em} 
            (d) & \raisebox{-.5\height}{\includegraphics[width=0.4\textwidth]{img/stockholm.png}} \\
        \end{tabular}
        \begin{tabular}{r c}
            (e) & \raisebox{-.5\height}{\includegraphics[width=0.4\textwidth]{img/parkjoy.png}} \\
        \end{tabular}
    \end{center}
    \legend{Fonte: O Autor.}
\end{figure}

Em seguida serão aprofundados os testes, bem como o treinamento utilizado para cada um deles.

\section{Treinamento}
Foi gerado um dicionário para cada classe de vídeos, e para cada variação em $K$ (tamanho do dicionário) e 
$p$ (tamanho do patch),
utilizando o algoritmo ODL, da forma que foi descrito na proposta do trabalho.

Para o treinamento foram utilizados os vídeos de cada classe, com exceção daquele
que foi escolhido para teste.
De cada um dos conjuntos de vídeos foram amostrados frames a cada $t$ segundos, variando
o valor de $t$ para providenciar pelo menos $10$ e no máximo $100$ frames para o processo 
de treinamento, aproximadamente.
A ordem de processamento dos frames foi aleatória, para evitar viés para os últimos frames. 
Cada frame foi então transformado em sequência de patches, com sobreposição.
Essa sequência foi introduzida no algoritmo ODL, que tomou no máximo $2.500$ amostras por sequência
para fazer o treinamento do dicionário.
Como dicionários iniciais foram utilizados valores randômicos com distribuição normal de 
média aproximadamente $0$.

A tabela a seguir apresenta os parâmetros de cada dicionário criado para os testes subsequentes.
Cada parametrização foi aplicada a todas as classes de vídeos.
É importante recordar que o parâmetro $p$ trata do tamanho do patch $p \times p \times 3$, 
enquanto $K$ representa o número de átomos do dicionário.
\begin{table}[h]
    \caption{Parâmetros tamanho do patch $p$ e tamanho do dicionário $K$ utilizados para treinamento e validação}
    \centering
        \begin{tabular}{|c|c c c c c |c c c c|}
          \hline
          \emph{Tamanho do patch} & $4$ & $4$ & $4$ & $4$ & $4$ & $8$ & $8$ & $8$ & $8$ \\
          \hline
          \emph{Tamanho do dicionário} & $16$ & $24$ & $32$ & $48$ & $64$ & $32$ & $64$ & $128$ & $192$ \\ 
          \hline
        \end{tabular}
    \legend{Fonte: O Autor.}
    \label{tbl:testparams}
\end{table}

Os parâmetros para teste foram escolhidos com base na implementação, também considerando 
o padrão H.264, que utiliza, na etapa de transformação, patches de $4\times4$, 
e o padrão JPEG, cujos patches são $8\times8$.
O valor de $s$, que se trata da esparsidade (\autoref{tbl:params}) foi fixo para os valores de $p$. 
Sendo assim, para $p=4$, $s=4$, e para $p=8$, $s=8$.

% INSERIR IMAGEM DE DICIONÁRIO, CITANDO K e p
\begin{figure}[H]
    \caption{Dicionários aprendidos. 
    (a) Classe cartoon, tamanho do dicionário $192$ e patches $8\times8$. 
    (b) Classe indoor, tamanho do dicionário $32$ e patches $4\times4$. }
    \begin{center}
        \begin{tabular}{r c}
            \vspace*{1em}
            (a) & \raisebox{-.5\height}{\includegraphics[width=0.8\textwidth]{img/cartoon_p8_d192.png}} \\
        \end{tabular}
        \begin{tabular}{r c}
           (b) & \raisebox{-.5\height}{\includegraphics[width=0.4\textwidth]{img/indoor_p4_d32.png}} \\
        \end{tabular}
    \end{center}
    \legend{Fonte: O Autor.}
\end{figure}

Em seguida serão apresentados os resultados alcançados com as diferentes parametrizações 
e diferentes classes de vídeos.

\section{Alterações no tamanho do dicionário, no tamanho do patch e na esparsidade}
\label{sec:parametrizacao}
Nessa seção serão apresentados e discutidos resultados alcançados na compressão e 
decompressão dos vídeos escolhidos de cada classe para os parâmetros definidos na 
tabela \ref{tbl:testparams}.

No total foram 9 parametrizações diferentes para cada uma das 5 classes de vídeos, 
totalizando 45 combinações diferentes para serem testadas.

Ao observar o algoritmo OMP (\ref{algo:omp}), verifica-se que sua complexidade teórica 
é $O(s m d)$, tal que, nesse caso, $m = K$ e $d = 3p^2$, portanto, $O(s K p^2)$.
Os resultados mostram o que a teoria espera, um aumento linear no tempo de processamento,
pois no caso considerado, foram mantidos $s$ e $d$ fixos, enquanto a variação ocorreu em $m$.
Vale ressaltar que o processamento de cada patch foi individual e utilizando a plataforma 
CUDA\reg, que paraleliza as operações.
Porém, por mais que patches possam ser executados em paralelo, seu tempo individualmente, 
no processamento do OMP, aumenta conforme o aumento do dicionário.

\begin{figure}[H]
    \caption{Tempo médio por frame para tamanho do patch $4$.}
    \begin{center}
        \includegraphics[width=0.9\textwidth]{img/graficos/p4_ds_edtime.png}
    \end{center}
    \legend{Fonte: O Autor.}
    \label{fig:timep4}
\end{figure}

Na figura acima (\ref{fig:timep4}) também pode-se constatar que a decodificação tem tempos iguais, independentes
do tamanho do dicionário.
Isso se dá pelo fato de que não é feita a multiplicação pelo método formal, mas sim tomando
somente cada um dos $s$ valores não nulos do vetor.
O mesmo pode ser constatado na figura abaixo, que apresenta os resultados alcançados com $p=8$.

\begin{figure}[H]
    \caption{Tempo médio por frame para tamanho do patch $8$.}
    \begin{center}
        \includegraphics[width=0.9\textwidth]{img/graficos/p8_ds_edtime.png}
    \end{center}
    \legend{Fonte: O Autor.}
    \label{fig:timep8}
\end{figure}

Um fato importante a ser detalhado é de que a classe esportes teve menor tempo médio por frame.
Esse fato está simplesmente ligado a resolução do vídeo utilizado por essa classe, NTSC, que é 
aproximadamente $2,63$ vezes menor que 720p.
O mesmo acontece com a classe cartoon, no qual o vídeo escolhido possui resolução menor e, portanto,
menor tempo de codificação.
Percebe-se, portanto, uma relação linear entre o tamanho do frame e o tempo de codificação.

Além disso, o vídeo de cartoon possui vários frames com partes que se repetem.
O sistema simples que não recalcula os patches que são iguais entrou em ação, fazendo com que 
o tempo médio para decodificação fosse ainda um pouco menor.

Também foi verificada a qualidade dos vídeos utilizando o PSNR médio. 
Os resultados mostram que o PSNR não se alterou significativamente para os diversos tamanhos
de dicionário, o que indica que é possível utilizar valores baixos de $K$ sem perdas significativas
na qualidade da representação.

\begin{figure}[H]
    \caption{PSNR médio em função do tamanho do dicionário.}
    \begin{center}
        \includegraphics[width=0.9\textwidth]{img/graficos/ds_psnr.png}
    \end{center}
    \legend{Fonte: O Autor.}
    \label{fig:psnr8bit}
\end{figure}

Na verdade o que se pode verificar é que existe uma variabilidade no PSNR médio devido 
a quantização.
Para melhorar esse fato, poderiam ser utilizados inteiros de 16 bits ao invés de 8 bits na 
representação comprimida, considerando que a representação perde significativamente em 
compressibilidade.
A figura abaixo mostra que o PSNR médio é bem mais estável utilizando uma representação 
de 16 bits, com exceção da classe cartoon, que manteve uma considerável variação.

\begin{figure}[H]
    \caption{PSNR médio em função do tamanho do dicionário, com quantização de 16bit.}
    \begin{center}
        \includegraphics[width=0.9\textwidth]{img/graficos/ds_psnr_16bit.png}
    \end{center}
    \legend{Fonte: O Autor.}
    \label{fig:psnr16bit}
\end{figure}

Além de alcançar maior estabilidade utilizando 16 bits na quantização, 
também é possível verificar que acontece alteração no PSNR devido ao uso 
dos 16 bits, podendo ser uma alternativa para melhoria na representação.

Pode-se verificar, ainda, com o uso de 16 bits, que o PSNR aumenta em função 
do tamanho do dicionário, de uma forma geral.
Uma exceção está nos vídeos indoor, que, para tamanho do patch $4$ e tamanho do dicionário $48$
tem um resultado de PSNR médio um pouco pior.
Porém, apesar da diferença de PSNR confrome o tamanho do dicionário, essa não é 
tão grande, o que mostra que o uso de dicionários menores pode ser bastante útil,
especialmente quando se leva em conta a velocidade de codificação.

Em seguida, foi escolhida a melhor representação do vídeo indoor, que apresenta 
pouca variação nas cenas, para avaliar as mudanças no PSNR médio em função do valor 
de esparsidade.
Também foi escolhido o vídeo de esportes, usando a mesma configuração, este pelo fato 
de que possui patches com grama, que é uma imagem com alta frequência.
Sumarizando, foram escolhidos $p=4$, $K=32$, e $s=1,2,3,4,5,6$.

\begin{figure}[H]
    \caption{PSNR médio em função da esparsidade $s$.}
    \begin{center}
        \includegraphics[width=0.6\textwidth]{img/graficos/p4d32_sv_psnr.png}
    \end{center}
    \legend{Fonte: O Autor.}
    \label{fig:psnrsvar}
\end{figure}

O que se pode perceber é que conforme o valor de $s$ aumenta, o PSNR médio também, 
mas não de forma linear.
Os pontos $s=4,5,6$ de ambos vídeos não apresentam tão importantes melhoras no 
PSNR médio na relação entre eles. 
Inclusive, para $s=6$, o vídeo indoor apresentou degradação em relação a $s=5$, 
causada pelos erros de quantização envolvidos.
Dadas essas constatações, pode-se verificar que o aumento do valor de $s$ faz com 
que a representação seja capaz de aprimorar as altas frequências, muito semelhante 
ao uso da DCT.

Por fim, foi aplicada a métrica de \emph{bitrate},
que consiste em calcular quantos bits por segundo a representação compactada 
de cada vídeo conseguiu alcançar.

A partir da codificação salva dos vídeos codificados,
foi percebido que as melhores compressões aconteceram com tamanho de patch $p=8$, 
variando pouco em relação ao tamanho do dicionário.
Além disso, é possível verificar que o PSNR médio não tem tantas mudanças em relação 
a mudança do tamanho do patch ou do dicionário, como já citado anteriormente,
o que proporciona a possibilidade de se escolher a representação mais compacta para 
comparar com o codec H.264.
Portando, foi calculado o bitrate usando o tamanho do patch em $8$ e o tamanho do dicionário
em $128$.

% Tabela do bitrate
\begin{table}[h]
    \caption{Bitrate calculado para vídeos de teste com tamanho do patch $8$, tamanho do 
    dicionário $128$ e esparsidade $8$.}
    \centering
        \begin{tabular}{|l|l|c|c|c|c|}
          \hline
          \multicolumn{1}{|c}{\textit{Classe}} & 
          \multicolumn{1}{|c}{\textit{Vídeo}} & 
          \multicolumn{1}{|c}{\textit{Nº frames}} & 
          \multicolumn{1}{|c}{\textit{FPS}} & 
          \multicolumn{1}{|c}{\textit{Tam. arquivo (bytes)}} & 
          \multicolumn{1}{|c|}{\textit{Bitrate (kbit/s)}} \\
          \hline
          \hline
          Cartoon & sintel\_trailer & $1.253$ & $24$ & $79.674.062$ & $11.922,5$ \\
          Esportes & football &  $360$ & $30$ & $21.420.945$ & $13.945,9$ \\
          Indoor & johnny  &   $600$ & $60$ & $72.782.464$ & $56.861,3$ \\
          Monitor. & stockholm & $604$ & $59,94$ & $82.818.027$ & $64.208,8$ \\
          Natureza & park\_joy & $500$ & $50$ & $80.040.734$ & $62.531,8$ \\
          \hline
        \end{tabular}
    \legend{Fonte: O Autor.}
    \label{tbl:bitrate}
\end{table}

A informação de quantos bytes a representação possui foi verificada através do salvamento
de um arquivo por teste com a codificação apresentada na proposta do trabalho.

É possível visualizar que, para vídeos com a câmera em movimento, caso dos dois últimos vídeos,
o bitrate degrada consideravelmente, chamando a atenção da necessidade de se agregar possivelmente
algum tipo de detecção de movimento.
Em especial é possível notar que o maior vídeo teve maior compressão.
Além de ser o maior vídeo, o mesmo também possui diversas partes com a câmera parada, 
o que facilita a compressão devido ao método proposto.

Fica claro que, quando se deseja tempo real na codificação, deve-se utilizar valores 
de tamanho de patch, esparsidade e tamanho de dicionário mais baixos, enquanto para que haja melhor compressão, 
devem ser utilizados valores mais altos.
O valor de esparsidade $s$ é capaz de controlar a qualidade, a compressão e até mesmo a velocidade 
da codificação, sendo então necessário considerar várias possibilidades para seus valores.

Para resumir, a tabela a seguir traz recomendações para os valores dos parâmetros do codec, 
nos casos em que o foco está em tempo real ou compressão.

\begin{table}
    \caption{Valores recomendados de parâmetros em função da aplicação desejada}
    \centering
    \begin{tabular}{|l|c|c|c|c|}
        \hline
        \multicolumn{1}{|c|}{\emph{Aplicação}} & 
        \emph{Foco} & 
        \emph{Tam. patch} & 
        \emph{Tam. dicionário} & 
        \emph{Esparsidade} \\
        \hline
        Tempo real & qualidade & 4 & 16 & 4 \\
        Tempo real & compressão & 8 & 64 & 5 \\
        Gravação & qualidade & 8 & 128 & 10 \\
        Gravação & qualidade+compressão & 8 & 128 & 8 \\
        Gravação & compressão & 8 & 128 & 4 \\
        \hline
    \end{tabular}
    \legend{Fonte: O Autor.}
\end{table}

\section{Comparação com codec H.264}
Para a comparação com o codec H.264 foi utilizado o software FFmpeg \cite{FFmpeg}, tendo como entrada
as mesmas sequências que serviram para os testes executados. 
O software permite que se gere arquivos de saída com aproximadamente um bitrate desejado.
Dessa forma, foi executado o programa para alcançar os mesmos bitrates que os apresentados 
na tabela \ref{tbl:bitrate}.
O codec H.264 permite diversas parametrizações.
Por questão de simplicidade, foi utilizada a configuração padrão, apenas forçando o bitrate desejado.
Em seguida, foi calculado o PSNR médio dos vídeos gerados com o codec H.264.

% Usar novos testes para chegar ao valores
\begin{table}[h]
    \caption{Comparação PSNR médio para mesmo bitrate.}
    \centering
        \begin{tabular}{|l|l|c|c|c|}
          \hline
          \multicolumn{1}{|c}{\textit{Classe}} & 
          \multicolumn{1}{|c}{\textit{Vídeo}} & 
          \multicolumn{1}{|c|}{\textit{Bitrate (kbit/s)}} &
          \multicolumn{1}{|c}{\textit{PSNR Proposta (dB)}} & 
          \multicolumn{1}{|c|}{\textit{PSNR H.264 (dB)}} \\
          \hline
          \hline
          Cartoon & sintel\_trailer & $11.922,5$ & $41.83$ & $54.96$ \\
          Esportes & football & $13.945,9$ & $24.96$ & $36.55$ \\
          Indoor & johnny & $56.861,3$ & $30.25$ & $37.50$ \\
          Monitoramento & stockholm & $64.208,8$ & $35.11$ & $42.96$ \\
          Natureza & park\_joy & $62.531,8$ & $23.60$ & $32.37$ \\
          \hline
        \end{tabular}
    \legend{Fonte: O Autor.}
    \label{tbl:bitrateh264}
\end{table}

Os resultados obtidos tiveram, para todos os casos, valores de PSNR médio inferiores
ao codec H.264, o que já era esperado, devido a simplicidade do codec proposto.
Porém, é possível perceber que as qualidades apresentadas são boas, o que indica que 
o codec proposto funciona, porém precisa ser aprimorado em relação a buscar gerar 
resultados mais comprimidos.
Em especial, buscar utilizar as técnicas já conhecidas dos padrões de codec pode 
ser uma via para melhorias no PSNR médio e no bitrate.

Os valores amostrados indicam que a opção pelo uso das técnicas propostas,
agregados a melhorias que possam ser executadas, podem gerar resultados ainda melhores.

\section{Resultado visual}
\label{sec:resultadovisual}
Para encerrar o capítulo de resultados, serão observados alguns resultado visuais relativos 
ao codec.

\begin{figure}[H]
    \caption{Fundo de cena do vídeo johnny, $p=4$, $K=32$, $s=5$, quantizado 8bit. 
    (a) Referência. 
    (b) Resultado com codec proposto.}
    \begin{center}
        \begin{tabular}{r c r c}
            (a) & \raisebox{-0.5 \height}{\includegraphics[width=0.4\textwidth]{img/johnnyref.png}} & \hspace{1em}
            (b) & \raisebox{-0.5 \height}{\includegraphics[width=0.4\textwidth]{img/johnnyres.png}} \\
        \end{tabular}
    \end{center}
    \legend{Fonte: O Autor.}
    \label{fig:johnnyres}
\end{figure}

Nesse primeira comparação pode-se verificar que altas frequências foram adicionadas a imagem, o que, 
em geral, se deve a erros relacionados a quantização.

\begin{figure}[H]
    \caption{Vídeo big\_buck\_bunny, $p=4$, $K=16$, $s=5$, quantizado 8bit. 
    (a) Referência. 
    (b) Resultado com codec proposto.}
    \begin{center}
        \begin{tabular}{r c r c}
            (a) & \raisebox{-0.5 \height}{\includegraphics[width=0.4\textwidth]{img/bbbref.png}} & \hspace{1em}
            (b) & \raisebox{-0.5 \height}{\includegraphics[width=0.4\textwidth]{img/bbbres.png}} \\
        \end{tabular}
    \end{center}
    \legend{Fonte: O Autor.}
    \label{fig:bbbres}
\end{figure}

Já nesse caso, o frame resultado é bem próximo ao original. 
O que se nota, apesar disso, é que em alguns pontos da imagem foram criados artefatos devido ao 
uso de patches sem sobreposição.
A imagem foi recortada para melhor visualização do efeito.
Para reduzir um pouco os efeitos, mas sem causar ofuscamento na imagem, foi utilizado um filtro 
bilateral parametrizado para não surtir tanto efeito.
Esta não é a solução ideal, dado que existem algoritmos para especificamente filtrar esses blocos,
porém na versão final do codec não foi implementada essa funcionalidade.

\chapter{Conclusão}
O trabalho apresentou uma proposta de codec utlizando métodos de compressed sensing
aliados a aprendizado de dicionários, além de realizar métricas relacionadas ao próprio codec 
e também em relação ao padrão H.264, amplamente utilizado para codificação de vídeos.

Na fase de execução de testes e geração de resultados foi possível constatar o funcionamento 
do codec para 5 tipos diferentes de classes de vídeos.
Ficou clara também a relação entre execução em tempo real, compressibilidade do vídeo e 
qualidade com os parâmetros $K$ (número de átomos do dicionário), $p$ (tamanho do bloco), 
e $s$ (esparsidade da representação).

Mudanças no valor de $K$ acarretam em pouca diferença na qualidade do vídeo, desde que 
o valor não seja muito pequeno. 
Por outro lado, o valor de $K$ altera linearmente o tempo de codificação dos frames, como 
pode ser verificado nas figuras \ref{fig:timep4} e \ref{fig:timep8}.
Também nas figuras anteriores se percebe que o tempo de decodificação não se altera.
A compressibilidade é alterada pelo valor de $K$, sendo que valores maiores correspondem 
a maior capacidade de compressão.
Resumindo, se o objetivo for maior compressão, deve-se escolher valores maiores de $K$.
Se a ideia é tempo real, valores menores são necessários.
Vale lembrar que os dicionários precisam ser previamente treinados. 
O que pode valer a pena, nesse caso, é escolher, para determinada classe, um dicionário para 
tempo real e outro para compressão, através de testes.

Quanto ao parâmetro $p$, ele produz dois distúrbios no codec.
Em primeiro lugar, ao observar $p=4$ e $p=8$, fica claro que, para tempo real, $p=4$ é a 
solução. Para compressão, $p=8$. 
Seria interessante serem executados testes com valores de $p$ maiores que $8$, 
no sentido de verificar a capacidade de compressão.
Para isso, em primeiro lugar, deve-se trabalhar em tornar mais veloz a codificação, tanto 
melhorando a implementação do algoritmo utilizado, ou buscando outras soluções.
Por exemplo, durante a execução do trabalho, não foi possível verificar o funcionamento 
paralelo do algoritmo IHT \cite{BLUMENSATHIHT}, que claramente apresenta características
interessantes para um algoritmo paralelizável.
Um detalhe importante é que o tamanho do patch não altera significativamente a qualidade 
da representação, podendo ser alcançados boa qualidade com tamanhos diferentes. 
Porém, vale ressaltar um problema relacionado com o uso de patches sem sobreposição, os 
artefatos visuais. 
Para aprimorar nesse sentido foram criados algoritmos para \emph{deblocking}, que poderiam 
ser aplicados a solução apresentada.

Já no que diz respeito ao parâmetro $s$, ficou claro que ele altera a qualidade da representação 
e também a compressibilidade.
Quanto a compressibilidade, o resultado pode ser verificado pela própria representação dos dados.
Considere um frame 720p usando $p=4$, utilizando $1$ byte para o valor e $1$ para o índice em cada 
patch, e que são $57600$ patches, $112,5$ kbytes serão utilizados aproximadamente a cada incremento
em $s$.

Por fim, as comparações com o codec H.264 mostraram que existem muitos pontos que podem ser 
aprimorados, mas também mostra que a proposta apresentada pode ser construtiva.
Em relação aos padrões já existentes, fica clara a necessidade de maior desenvolvimento em 
todas as dimensões do codec, pois o que foi apresentado ilustra a ideia principal.
Um caminho a ser seguido é combinar as metodologias já existentes para predição intra-frame 
e inter-frame com o aprendizado de dicionários, além de estruturar essa relação.
Além disso, é necessário verificar formas de implementar a camada de rede do codec baseando-se 
nos padrões já existentes.

De forma resumida, o trabalho proposto apresentou um caminho para a codificação de vídeos 
utilizando aprendizado de dicionários e técnicas de compressed sensing.


% referências
% aqui será usado o environment padrao `thebibliography'; porém, sugere-se
% seriamente o uso de BibTeX e do estilo abnt.bst (veja na página do
% UTUG)
% 
% observe também o estilo meio estranho de alguns labels; isso é
% devido ao uso do pacote `natbib', que permite fazer citações de
% autores, ano, e diversas combinações desses

\bibliographystyle{abntex2-alf}
\bibliography{biblio}

\end{document}
